{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: Abhishek Kumar Dubey\n",
    "badges: false\n",
    "categories:\n",
    "- Deep Learning\n",
    "date: '2023-04-15'\n",
    "description: Autoencoders and Variational Autoencoder \n",
    "image: CS5480_images/Acrobat_A6vKJFHXk0.png\n",
    "title: Deep Learning 9\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Autoencoders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autoencoder neural network: an unsupervised learning algorithm that applies backpropagation, setting target values to be equal to the inputs. ie it uses $y^{(i)}=x^{(i)}$\n",
    "- we go from input to bottelneck layer.\n",
    "- Tried to learn a function $h_{w,b}(x)=x$\n",
    "- Learn an approximation to identity function, so as to make output $\\hat x$ similar to $x$\n",
    "- Decoder need not be a mirror reflection of the encoder.\n",
    "- If input were completely random—say, each $x_i$ comes from an IID Gaussian independent of the other features—then very difficult\n",
    "- If there is structure in data, e.g., if some input features are correlated, then this model will be able to discover correlations\n",
    "- Often ends up learning a low-dimensional representation very similar to PCAs.\n",
    "- Denoising Auto encoder\n",
    "    - Add the noise in the input and  generate the original input, it helps noise to get removed \n",
    "    - Idea: Representation should be robust to introduction of noise:\n",
    "        - Random assignment of subset of inputs to $0$, with probability $v$\n",
    "        - Gaussian additive noise\n",
    "    - Reconstruction: $\\hat x$ computed from the corrupted input $\\hat x$\n",
    "    - Loss function compares $\\hat x$ reconstruction with the noiseless input $\\bf X$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder\n",
    "\n",
    "![](CS5480_images/notepad++_uu2Xk2QDrC.png)\n",
    "\n",
    "-  Given an input, send it to encoder, force the encoder to take it to mean and std vector, (mean 0 std 1)\n",
    "- Now we sample form the unit gaussian, and pass through the decoder, generate the image which looks similar to the original image.\n",
    "- Now due this sampling , we can't do back prop \n",
    "- Leverage neural network to learn a latent variable model. <br>\n",
    "  $p(x)=\\int p(x,z)~d z$ where $p(x,z)=p(x\\mid z)p(z)$<br>\n",
    "  $p(z)=$ something simple, $p(x\\mid z)=g(z)$ <br>\n",
    "  ![](CS5480_images/notepad++_EMKp6sM9jD.png)<br>\n",
    "- Where does $z$ come form? The classic directed model dilemma.\n",
    "- Computing the posterior $p(z \\mid x)$ is intractable.\n",
    "- We need it to train the directed model.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Bayesian spin on an autoencoder!\n",
    "- Assume our data $\\left\\{x^{(i)}\\right\\}_{i=1}^N$ is generated like this. <br><br>\n",
    "- \n",
    "\n",
    "  :::: {.columns}\n",
    "  ::: {.column width=\"40%\"}\n",
    "  ![](CS5480_images/notepad++_4dPrdemlfn.png)<br><br>\n",
    "  :::\n",
    "  ::: {.column width=\"60%\"}\n",
    "  - Intuition: $\\bf X$ is an image, $\\bf z$ gives class, orientation attributes, etc\n",
    "  - Problem : Estimate $\\theta$ without access to latent states!\n",
    "  :::\n",
    "  ::::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"60%\"}\n",
    "- Prior: Assume $p_\\theta(z)$ is a unit Gaussian.\n",
    "- Conditional: Assume $p_\\theta(x \\mid z)$ is a diagonal Gaussian, predict mean and variance with neural net\n",
    ":::\n",
    "\n",
    "::: {.column width=\"40%\"}\n",
    "![](CS5480_images/chrome_50J29Omju4.png)\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Bayes Rules the posterior is:\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"60%\"}\n",
    "$$p_\\theta(z\\mid x)=\\frac{p_\\theta(x\\mid z)p_\\theta(z)}{p_\\theta(x)}$$\n",
    "\n",
    "- Use decoder network = $p_\\theta(x\\mid z)$\n",
    "- Gaussian = $p_\\theta(z)$\n",
    "- Intractable  integral = $p_\\theta(x)$\n",
    ":::\n",
    "\n",
    "::: {.column width=\"40%\"}\n",
    "![](CS5480_images/chrome_VGlrCQ20KE.png)\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::: {.columns}\n",
    "::: {.column width=\"40%\"}\n",
    "![](CS5480_images/mspaint_esUk2j4Q7v.png)\n",
    ":::\n",
    "::: {.column width=\"60%\"}\n",
    "- Training like a normal autoencoder:\n",
    "    - Reconstruction loss at the end, regularization toward prior in the middle.\n",
    "- Mean and (diagonal) covariance of $p_\\theta(x \\mid z)$\n",
    "    - Should be close to data $x$\n",
    "- Mean and (diagonal) covariance of $q_\\phi(z \\mid x)$\n",
    "    - should be close to prior $p_\\theta(z)$\n",
    ":::\n",
    "::::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders : The Math\n",
    "\n",
    "- Maximum Likelihood of dataset $\\left\\{x^{\\left(i\\right)}\\right\\}_{i=1}^N$\n",
    "\n",
    "  $$\\begin{align*}\n",
    "      \\theta^{*}&=\\arg\\operatorname*{max}_{\\theta}\\prod_{i=1}^{N}p_{\\theta}(x^{(i)})\\\\\n",
    "      &=\\arg\\operatorname*{max}_{\\theta}\\sum_{i=1}^{N}\\log p_{\\theta}(x^{(i)})\\\\\n",
    "  \\end{align*}$$\n",
    "\n",
    "- Marginalize joint distribution \n",
    "  $$p_{\\theta}(x^{(i)})=\\int p_{\\theta}(x^{(i)},z)d z = \\int{p_{\\theta}(x^{(i)}\\mid z)p_{\\theta}(z)d z}$$\n",
    "    - which is intractible integral"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "    \\mathrm{log}\\,p_{\\theta}(x^{(i)})&= \\mathbf{E}_{z \\sim q_{\\phi}(z|x^{(i)})}\\left[\\log p_{\\theta}(x^{(i)})\\right] \\quad (p_{\\theta}(x^{i})\\text{ does not depend on } z) \\\\\n",
    "    &= \\mathbf{E}_z \\left[\\log\\frac{p_{\\theta}(x^{(i)}\\mid z)p_{\\theta}(z)}{p_{\\theta}(z\\mid x^{(i)})}\\right] \\quad \\text{ Bayes' Rule }\\\\\n",
    "    &= \\mathbf{E}_z \\left[\\log\\frac{p_{\\theta}(x^{(i)}\\mid z)p_{\\theta}(z)}{p_{\\theta}(z\\mid x^{(i)})}\\frac{q_{\\phi}(z\\mid x^{(i)})}{q_{\\phi}(z\\mid x^{(i)})}\\right] \\text{ Multiply by constant }\\\\\n",
    "    &= \\mathbf{E}_{z}\\left[\\log p_{\\theta}(x^{(i)}\\mid z)\\right]-\\mathbf{E}_{z}\\left[\\log\\frac{q_{\\phi}(z\\mid x^{(i)})}{p_{\\theta}(z)}\\right]+\\mathbf{E}_{z}\\left[\\log\\frac{q_{\\phi}(z\\mid x^{(i)})}{p_{\\theta}(z\\mid x^{(i)})}\\right]\\\\\n",
    "    &= \\underbrace{\\mathrm{\\bf{E}}_{z}\\left[\\log p_{\\theta}(x^{(i)}\\mid z)\\right]-D_{K L}(q_{\\phi}(z\\mid x^{(i)})\\mid\\mid p_{\\theta}(z))}_{\\mathcal{L}\\big(x^{(i)},\\theta,\\phi\\big) \\text{ELBOW}} + \\underbrace{D_{K L}({q_{\\phi}}(z\\mid x^{(i)})\\mid\\mid p_{\\theta}(z\\mid x^{(i)}))}_{\\ge 0} \n",
    "\\end{align*}$$\n",
    "\n",
    "- Variational lower bound (elbow): <br>\n",
    "  $\\mathrm{log}\\,p_{\\theta}(x^{(i)})\\ge \\mathcal {L}(x^{(i)},\\theta,\\phi)$\n",
    "- Training: Maximize lower bound <br>\n",
    "  $\\displaystyle {\\theta^{*},\\phi^{*}}=\\arg\\operatorname*{max}_{\\theta,\\phi}\\sum_{i=1}^{N}\\mathcal{L}(x^{(i)},\\theta,\\phi)$\n",
    "- $\\log p\\theta(x^{(i)}\\mid z)$ : Here we do sampling with reparametrization trick, Reconstruct input data\n",
    "- $D_{K L}(q_{\\phi}(z\\mid x^{(i)})\\mid\\mid p_{\\theta}(z))$ : Latent space should follow prior, Everything is Gaussian closed form solution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoders: Inference\n",
    "\n",
    "- The VAE approach: introduced an inference model $q_\\phi(z \\mid x)$ that learns to approximates the intractable posterior $p_\\theta(z \\mid x)$ by optimizing the variational lower bound:\n",
    "  $$\\mathcal{L}(\\theta,\\phi,x)=-D_{\\mathrm{KL}}\\left(q_{\\phi}(z\\mid x)\\|\\,p_{\\theta}(z)\\right)+\\mathbb{E}_{q_{\\phi}(z|x)}\\left[\\log p_{\\theta}(x\\mid z)\\right]$$\n",
    "- we parametrize $q_\\phi(z \\mid x)$ with another neural network:\n",
    "\n",
    "  :::: {.columns}\n",
    "  \n",
    "  ::: {.column width=\"50%\"}\n",
    "  ![](CS5480_images/Acrobat_iCbuPmblNP.png)\n",
    "  :::\n",
    "  \n",
    "  ::: {.column width=\"50%\"}\n",
    "  ![](CS5480_images/Acrobat_k8ErR94LSE.png)\n",
    "  :::\n",
    "  \n",
    "  ::::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparametrization Trick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problem with respect to the VLB: updating $\\phi$\n",
    "  $$\\begin{align*}\n",
    "    \\mathcal{L}_{\\mathrm{VAE}}&=\\mathbb{E}_{q_\\phi(z|x)}\\left[\\log\\frac{p_{\\theta}(z,x)}{q_{\\phi}(z|x)}\\right]\\\\\n",
    "    &=-D_{\\mathrm{KL}}(q_{\\phi}(z|x)||p_{\\theta}(z))+\\mathbb{E}_{q_{\\phi}(z|x)}[\\log p_{\\theta}(x|z)]\n",
    "  \\end{align*}$$\n",
    "- $Z{\\sim}q_{\\phi}{\\left(Z|X\\right)}$ : need to differentiate through the sampling process w.r.t $\\phi$ (encoder is probablistic)\n",
    "- Let's consider $z$ to be real and $q_{\\phi}(z\\mid x)=\\mathcal {N}(z;\\mu_{z}(x),\\sigma_{z}(x))$\n",
    "- Parametrize $z$ as $z=\\mu_{z}(x)+\\sigma_{z}(x)\\epsilon_{z}$ where $\\epsilon_{z}={\\mathcal{N}}(0,1)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- variational inference: A concept where we  replace one distribution with another approximation.\n",
    "- What VAE's can do\n",
    "    - change in the latent space and get the different image, like different pose, or rotation.\n",
    "    - VAE's have more control on this as compared to GAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence between Gaussians\n",
    "\n",
    "The Kullback Leibler divergence between a Gaussian\n",
    "distribution $p$ with mean $\\mu_1$ and variance $\\sigma_1^2$ and a Gaussian distribution $q$ with mean $\\mu_2$  and variance $\\sigma_2^2$ is given by:\n",
    "$$\\mathrm{KL}(p,q)=\\log{\\frac{\\sigma_{2}}{\\sigma_{1}}}+{\\frac{\\sigma_{1}^{2}+(\\mu_{1}-\\mu_{2})^{2}}{2\\sigma_{2}^{2}}}-{\\frac{1}{2}}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Backprop\n",
    "\n",
    "- Due to a reparametrization trick, we can simultaneously train both the generative model $p_\\theta(x \\mid z)$ and the inference model $q_\\phi(z \\mid x)$ by optimizing the variational bound using gradient back propagation.<br>\n",
    "Objective Function: \n",
    "$$\\mathcal{L(\\theta,\\phi,x)=-D_{\\mathrm{KL}}\\left(q_{\\phi}(z\\mid x)||\\,p_{\\theta}(z)\\right)+\\mathbb{E}_{q_{\\phi}(z|x)}\\left[\\log p_{\\theta}(x\\mid z)\\right]}$$\n",
    "<br><br>\n",
    "![](CS5480_images/Acrobat_A6vKJFHXk0.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of VAEs\n",
    "\n",
    "- Conditional VAE\n",
    "- Semi supervised VAEs\n",
    "- Importance-weighted VAEs\n",
    "- Recurrent VAEs\n",
    "- VAE + GAN\n",
    "- Disentangled VAEs\n",
    "\n",
    "Recent Developments in Deep Generative Models<br><br>\n",
    "![](CS5480_images/Acrobat_kpv9mHYS2C.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GANs give sharper image, VAEs give blurry image  reason is that we sample from a distribution \n",
    "- So there are a variant where we combine both VAE and GAN\n",
    "- Disentangled VAEs\n",
    "    - knowing a true generative process is very important which VAEs does\n",
    "    - How to learn VAE so that the Latent space dimension correspond to some semantic.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following resources were referred in this notes:\n",
    "\n",
    "- [lilianweng](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "$\\tiny  {\\textcolor{#808080}{\\boxed{\\text{Reference: Dr. Vineeth, IIT Hyderabad }}}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0e5e69b8442e8f020791fad6bfcef3777f0e89e0f1a2517b6b628b2eaf0fe66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
