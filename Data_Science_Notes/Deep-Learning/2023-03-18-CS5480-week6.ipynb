{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: Abhishek Kumar Dubey\n",
    "badges: false\n",
    "categories:\n",
    "- Deep Learning\n",
    "date: '2023-03-18'\n",
    "description: residual neural network,explainable AI\n",
    "image: CS5480_images/VoiceAccess_56w2Jughz5.png\n",
    "title: Deep Learning 6\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do you know the deeper the model better it performs.\n",
    "- Adding layer improves the performance.\n",
    "- If we continue stacking deeper layers on a plane convolutional network.The training loss keeps decreasing.But the testing loss does not decrease as much.\n",
    "- Deeper the network, gradients vanish quickly, thereby slowing the rate of change in initial layers. <br><br>\n",
    "  ![](CS5480_images/VoiceAccess_OLY3E5z45G.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reidual Nets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](CS5480_images/VoiceAccess_56w2Jughz5.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The deeper model should be able to perform at least as well as the shallower model.\n",
    "- Solution is to use the network layer to fit a residual mapping instead of directly trying to fit a desired underlying nothing.\n",
    "- use skip connection. Such a block is called residual block.\n",
    "- Bypass some layers.\n",
    "- Stack residual blocks, every residual block has 2, 3 x 3 convolution layers.\n",
    "- No fully connected layer at the end.\n",
    "- additional convolutional layer at the beginning\n",
    "- Periodically double the filter.down sample reaching stride of two.\n",
    "- Alex net had fully connected network at last.\n",
    "- For deeper network use bottleneck layer to improve efficiency.\n",
    "- Short circuit path provides a path for the gradient to flow deeper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Able to train very deep neural network\n",
    "- deeper layer networks now achieve lower training error as expected.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network in network.\n",
    "\n",
    "- Between every convolution, there has MLP in between.\n",
    "- these micro network within each convolutional layer helps to compute more abstract feature for local batches.\n",
    "- micron network uses multilayer perceptron fully connected That is 1 x 1  convolutional layer\n",
    "- this network was not so famous\n",
    "\n",
    "Wide residual network.\n",
    "\n",
    "- it argues that residuals are important factor not the depth.\n",
    "- use wide residual block of F x K filters instead of F filter in each layer.\n",
    "- 50 layer wide residual network outperforms 152 layer original residual network.\n",
    "- Increasing width at instead of depth is more computationally efficient because it helps in parallelization of the computation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Deep Networks with Stochastic Depth\n",
    "\n",
    "- It reduces vanishing gradient and training time through short network during training.\n",
    "- Randomly drop subset of layer during each training pass.\n",
    "- It's like dropout, but drops out  the residual block.\n",
    "- In every Iteration  randomly drop one residual block.\n",
    "\n",
    "Dens net.\n",
    "\n",
    "- Dense  blocks where each layer is connected to every layer in feet forward fashion.\n",
    "- Simply connect every layer with every layer. Let the neural network figure out.\n",
    "- Alleviates Vanishing gradient, strengthens feature propagation,Encourages Feature Reuse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.alert .alert-dismissible .alert-info}\n",
    "Top five means check if prediction is among the top five.\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding and Visualizing CNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Features are Generic \n",
    "\n",
    "- CNN features are generic, so we can reuse the CNN feature for  the small problem.\n",
    "- We can reuse the feature.That led to the notion of transfer learning.\n",
    "- Initially train a CNN or any new network.On large database like Image net. Now use the network, for different problem.It is called transfer learning.\n",
    "- Depending on the data, decide how many layer of the neural network we want to fine tune.\n",
    "- This works because features are generic in earlier network.\n",
    "- Extend to more number of losses just by fine tuning.\n",
    "- Extend to new task. Extend from object classification to scene classification.\n",
    "- Also can be used to extend to new datasets, if the data set is similar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding convolutional neural network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize patches that maximally activate neurons.\n",
    "- visualize the weights.For example, by looking at the filter, we can say whether its edge detector.\n",
    "- visualize the representation space. using t-SNE,\n",
    "- Occlusion experiment.\n",
    "- Deconvolution based approaches.\n",
    "- Optimization over image approaches."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial layer of neural network Weight looks like gabor-like filters.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_94HnFdJpvG.png)\n",
    "\n",
    "Occlusion experiment. \n",
    "\n",
    "- Here we black out some of the area of the image and study the effect of this, on the output.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_UtPs9plrjC.png)\n",
    "\n",
    "DeConv approach.\n",
    "\n",
    "- feed image to the network.\n",
    "- Pick a layer set the gradient there to be all zero, except for one some neuron of interest.\n",
    "- Back propagate to the image.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_kG4DK7uppb.png)\n",
    "- In guided bank propagation, we guide the gradient.So that negative gradient doesn't flow.An image looks little better.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_3BjmLGNuyD.png)\n",
    "- In case of guided back propagation, we first zero out all those activation, which was negative just before rectified linear unit in case of forward pass.\n",
    "- Then we zero out all those gradients which are negative while doing backward pass.\n",
    "- this is explained in below picture:.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_Ve2wDPTSwQ.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimization to image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- can we find an image that maximizes some class score <br><br>\n",
    "  ![](CS5480_images/VoiceAccess_JgckJOT9eD.png)\n",
    "- Score of a class c before softmax $\\arg \\max_I S_c(I)-\\lambda \\vert| I \\vert | ^2_2$\n",
    "\n",
    "\n",
    "\n",
    "I start with black image are you using gradient descent on that image we maximize the score on output neuron\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. feed in zero\n",
    "2. Set the gradient of all vectors zero except the one which we are interested in and perform the back propagation.\n",
    "3. do the small input update\n",
    "4. go back to step 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](CS5480_images/VoiceAccess_M2LnjzYMpM.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualize the data gradient <br><br>\n",
    "  ![](CS5480_images/VoiceAccess_c6LcbMI4lN.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now we can use grab cut using the same approach for segmentation.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_B4tJeGqYxK.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we can use this approach even for the object detection.\n",
    "- we can minimize this code: \n",
    "  $$\\mathbf{x}^{*}=\\operatorname*{argmin}_{\\mathbf{x}\\in\\mathbb{R}^{H}\\times W\\times C}\\ell(\\Phi(\\mathbf{x}),\\Phi_{0})+\\lambda\\mathcal{R}(\\mathbf{x})$$\n",
    "  where\n",
    "  $$\\ell(\\Phi({\\bf x}),\\Phi_{0})=\\|\\Phi({\\bf x})-\\Phi_{0}\\|^{2}$$\n",
    "\n",
    "  ![](CS5480_images/VoiceAccess_f4pURXrnrV.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Mapping (CAM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in this method we train a linear regression model for each and every class at the output layer\n",
    "- we take the global average pooling from the layer which comes before the classification layer.\n",
    "- now from this average pooling we construct a linear regression for each class.\n",
    "- once we obtain the weight of each class we multiply the weight of each linear regression with the feature which we used for global leverage pooling.\n",
    "- then we project this image what we obtain after multiplication to the original image to obtain class activation map. <br><br>\n",
    "  ![](CS5480_images/VoiceAccess_pYoJj8w6KL.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad CAM (and Guided Grad CAM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the class activation map requires to train a linear regression model can we avoid this.\n",
    "- this issue is addressed by grad CAM.\n",
    "- we use the weight which is already there in the network and we do the global average pulling of rectified convolutional layer,  we multiply this with the weight of the fully connected layer and we do the same process as we did in class activation map to obtain the Heat map.<br><br>\n",
    "  ![](CS5480_images/VoiceAccess_fDl7XreUJh.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad CAM for Image Captioning\n",
    "\n",
    "![](CS5480_images/VoiceAccess_umQTVcf9zZ.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other methods\n",
    "\n",
    "- Grad CAM++ \n",
    "- Integrated Gradients \n",
    "- SmoothGrad \n",
    "- LIME \n",
    "- LRP \n",
    "- DeepSHAP \n",
    "- DeepLIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "$\\tiny  {\\textcolor{#808080}{\\boxed{\\text{Reference: Dr. Vineeth, IIT Hyderabad }}}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0e5e69b8442e8f020791fad6bfcef3777f0e89e0f1a2517b6b628b2eaf0fe66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
