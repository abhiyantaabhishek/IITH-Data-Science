{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: Abhishek Kumar Dubey\n",
    "badges: false\n",
    "categories:\n",
    "- Deep Learning\n",
    "date: '2023-02-04'\n",
    "description: Regularization and Generalization.\n",
    "image: CS5480_images/Teams_fVDfgzhc3E.png\n",
    "title: Deep Learning 3\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why do we go for first derivative in gradient descent why not second derivative \n",
    "\n",
    "second derive is called hassian matrix\n",
    "\n",
    "why not use Hassian instead of jaccobian \n",
    "\n",
    "because it is expensive to compute, also it was proved that SGD works better than this, \n",
    "\n",
    "SGD is noisy which is an advantage, and it helps us generalize better. SGD is the true success for generalization of the deep learning "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between Machine Learning and Optimization\n",
    "\n",
    "- Generalization, In general optimization we do not focus on generalization. \n",
    "-  In DL we are interested in the data which will come, not in the data which is already there. In DL we are interested in the generalization error\n",
    "- In mainstream optimization, minimizing J is itself the goal; whereas in deep learning, minimizing J so as to minimize a generalizable out-of-sample performance measure is the goal\n",
    "- Empirical Risk Minimization (ERM):\n",
    "  $$\\mathbb{E}_{\\mathbf{x,y}\\approx{\\widehat{p}}_{d a t a}(\\mathbf{x,y})}(J(\\theta;\\mathbf{x},y))={\\frac{1}{m}}\\sum_{i=1}^{m}J(\\theta;\\mathbf{x}_{i},y_{i})$$\n",
    "\n",
    "- However, ERM can lead to overfitting. Avoiding overfitting is regularization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning and Generalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple idea to keep monitoring the cost function, and not let it become too consistently low; stop at an earlier iteration<br>\n",
    "  ![](CS5480_images/Teams_fVDfgzhc3E.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some time validation loss stops improving and we can do early stopping.\n",
    "\n",
    "### When to stop\n",
    "\n",
    "- Train n epochs; lower learning rate; train m epochs : But it's bad idea, can't assume one-size-fits-all approach\n",
    "- Error-change criterion:\n",
    "    - Stop when error isn’t dropping over a window of, say, 10 epochs\n",
    "    - Train for a fixed number of epochs after criterion is reached (possibly with lower learning rate)\n",
    "- Weight-change criterion:\n",
    "    - Compare weights at epochs t-10 and t and test:\n",
    "      $\\Pi\\mathrm{d}\\times_{i}\\left|\\left|W_{i}^{t}\\,-\\,W_{i}^{t-10}\\right|\\right|\\,<\\,\\rho$\n",
    "    - Don’t base on length of overall weight change vector\n",
    "    - Possibly express as a percentage of the weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay\n",
    "\n",
    "- L1 regularization\n",
    "- L2 regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DropOut\n",
    "\n",
    "- Another standard approach to regularization in ML: Model Averaging\n",
    "- DropOut → a very interesting way to perform model averaging in deep learning.\n",
    "\n",
    "- Training Phase: For each hidden layer, for each training sample, for each iteration, ignore (zero out) a random fraction, p, of nodes (and corresponding activations)\n",
    "- Test Phase: Use all activations, but reduce them by a factor p (to account for the missing activations during training)\n",
    "  ![](CS5480_images//Teams_KqkeL6M2fL.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With $H$ hidden units, each of which can be dropped, we have $2^H$ possible models\n",
    "- Each of the $2^{H−1}$ models that include hidden unit h must share the same weights for the unit\n",
    "    - serves as a form of regularization\n",
    "    - makes the models cooperate\n",
    "- Including all hidden units at test with a scaling of $0.5$ is equivalent to computing the geometric mean of all $2^H$ models\n",
    "- It's like ensamble without doing it\n",
    "- Here we are randomly dropping so that no neuron becomes specific to a task, but it learns to do all the task.\n",
    "- DropConnect: An Extension<br>\n",
    "  ![](CS5480_images//Teams_81Mmd1u1CF.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using noise is another form of regularization; has shown some impressive results recently. Could be:\n",
    "\n",
    "- Data Noise\n",
    "    \n",
    "    - Has been there for a while: add noise to data while training\n",
    "    - Minimization of sum-of-squares error with zero-mean gaussian noise(added to training data) is equivalent to minimization of sum-of-squares error without noise with an added regularized term\n",
    "    - Very similar to data augmentation that we will see later\n",
    "- Label Noise\n",
    "- Gradient Noise\n",
    "- Regularization through Label Noise\n",
    "    - Disturb each training sample with the probability\n",
    "- Regularization through Gradient Noise\n",
    "    - Simple idea: add noise to gradient\n",
    "      $$g_{t}  \\leftarrow g_{t} +\\mathcal{N}(0,\\sigma_{t}^{2})$$\n",
    "\n",
    "    - Annealed Gaussian noise by decaying the variance\n",
    "      $$\\sigma_{t}^{2}\\,=\\,\\frac{\\eta}{(1\\,+\\,t)^{\\gamma}}$$\n",
    "    - Showed significant improvement in performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation Methods  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize/standardize the inputs\n",
    "\n",
    "- Convergence is faster if average input over the training set is close to zero. look at 8Le Cun et al, Efficient Backprop, 1998 and find answer\n",
    "- Scaled to have the same covariance - speeds learning\n",
    "    - Ideally, value of covariance should be matched with output of activation function (e.g. sigmoid)\n",
    "        - Initially we want to be in lierar reason, we can achieve \n",
    "        - After normalization, if the variance of the data is 2 we want the activation fucntion to have a linear range between 0 and 2\n",
    "- PCA\n",
    "    - Decorrelate the inputs\n",
    "    - Imagine one input is always twice the other, i.e. $z_2 = 2z_1$. Output $y$ will be constant on lines $w_2 + \\frac{1}{2}w_1=$ const. No use making weight changes on these lines.\n",
    "      ![](CS5480_images//Teams_BoYNEbdtR0.png)\n",
    "\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "- Change in distributions of data inputs is a problem because the model needs to continuously adapt to the new distribution, called covariate shift\n",
    "- This is typically handled using domain adaptation\n",
    "- Even while training minibatch distribution can change\n",
    "- What if this happens in a subnetwork in DL? → called internal covariate shift. How to handle?\n",
    "\n",
    "\n",
    "- Batch nor accelerate training and also regularize the network  \n",
    "- BN layer usually inserted before non-linearity layer (after FC or convolutional layer)\n",
    "- Allows higher learning rates. \n",
    "- Reduces the strong dependence on initialization\n",
    "- Acts as a form of regularization too\n",
    "- Take average of last 10 minibatch of gamma and beta and use in inferencing \n",
    "\n",
    "- Algo\n",
    "    - $\\mu_{B}\\leftarrow{\\frac{1}{m}}\\sum_{i=1}^{m}x_{i}$\n",
    "    - $\\sigma_{B}^{2}\\leftarrow\\frac{1}{m}\\sum_{i=1}^{m}(x_{i}-\\mu_{B})^{2}$\n",
    "    - $\\widehat{x}_{i}\\leftarrow\\frac{x_{i}-\\mu_{B}}{\\sqrt{\\sigma_{B}^{2}+\\epsilon}}$\n",
    "    - $y_{i}\\leftarrow\\gamma\\widehat{\\alpha}_{i}\\leftarrow\\beta\\equiv\\mathrm{BN}_{\\gamma,\\beta}(x_{i})$\n",
    "\n",
    "\n",
    "### Shuffling Inputs\n",
    "\n",
    "- Random sample data and do SGD\n",
    "- Choose examples with maximum information content\n",
    "    - Shuffle the training set so that successive training examples never (rarely) belong to the same class.\n",
    "    - Present input examples that produce a large error more frequently than examples that produce a small error. \n",
    "        - Helps take large steps in the gradient descent\n",
    "\n",
    "### Curriculum Learning\n",
    "\n",
    "- Old idea, proposed by Elman in 1993\n",
    "- Humans and animals learn much better when examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones\n",
    "- Start small, learn easier aspects of the task or easier sub-tasks, and then gradually increase the difficulty level\n",
    "- By choosing examples and their order, one can guide training and remarkably increase learning speed\n",
    "- Introduces the concept of a teacher who:\n",
    "    - has prior knowledge about the training data to decide on a sequence of concepts that can more easily be learned when presented in that order\n",
    "    - monitoring ‘learner’s progress to decide when to move on to new material from the curriculum\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "- Data jittering\n",
    "- Rotations\n",
    "- Color changes\n",
    "- Noise injection\n",
    "- Mirroring\n",
    "- Helps increase data; is useful when training data provided is less\n",
    "- Also acts as a regularizer (by avoiding overfitting to provided data)\n",
    "- MixUP: if we have data $x_1, y_1$ and $x_2,y_2$, we can interpolate between $x_1, x_2$ and also for $y_1,y_2$ in this way we can create more data, and also it creates more labes, but that is ok, and it help in the genelarization of the models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Choices / Initialization method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Activation Functions\n",
    "- Loss Functions : should be differentiable \n",
    "- Learning Rates : adaptive learning rates\n",
    "- All of them decrease it when weight vector “oscillates”, and increase it when the weight vector follows a relatively steady direction\n",
    "- Worthwhile picking a different learning rate for each weight (e.g. based on curvature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assuming a binary classification problem, what do you choose the target labels to be? +1 and -1?\n",
    "- What if these are the sigmoid’s asymptotes?\n",
    "    - Weights will be increased continuously to very high values to match the target\n",
    "    - Weights multiplied by small sigmoid derivative → small weight updates → Stuck!\n",
    "- Choose target values at the point of the maximum second derivative on the sigmoid so as to avoid saturating the output units."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we want activation to be in the linear region.\n",
    "\n",
    "- To be chosen randomly, but in such a way that the activation function is in its linear region\n",
    "    - Both large and small weights can cause very low gradients (in case of sigmoid activation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Xavier’s initialization \n",
    "  $$\\mathrm{uniform}\\left(-{\\frac{\\sqrt{6}}{\\sqrt{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}},\\;{\\frac{\\sqrt{6}}{\\sqrt{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}}\\right)$$\n",
    "- Caffe implements a simpler version of Xavier’s initialization as:\n",
    "   $$\\mathrm{uniform}\\left(-{\\frac{2}{{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}},\\;{\\frac{2}{{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}}\\right)$$\n",
    "- He’s initialization \n",
    "  $$\\mathrm{uniform}\\left(-{\\frac{4}{{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}},\\;{\\frac{4}{{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}}\\right)$$\n",
    "\n",
    "Proof outline of  Xavier’s initialization <br>\n",
    "We know <br>\n",
    "  $$Y= w_1x_1+w_2x_2 + \\dots + w_nx_n$$\n",
    "then \n",
    "$$\\begin{align*}\n",
    "  \\mathrm{Var}(Y)&=\\sum_i\\mathrm{Var}(w_ix_i)\\\\\n",
    "  &=\\sum_i \\left( \\underbrace{\\mathbb{E}[x_i]^2\\mathrm{Var}(w_i)}_{\\;\\;0,\\text{ Since mean of input is 0}}  +\\underbrace{ \\mathbb{E}[w_i]^2\\mathrm{Var}(x_i)}_{\\;\\;0,\\text{ Since weight is normalized to 0}} +\\mathrm{Var}(w_i)\\mathrm{Var}(x_i) \\right) \\\\\n",
    "  &= \\sum_i  \\mathrm{Var}(w_i)\\mathrm{Var}(x_i) \\\\\n",
    "  &= n\\times \\mathrm{Var}(w_i)\\mathrm{Var}(x_i)\n",
    "\\end{align*}$$\n",
    "\n",
    "Now from above equation, if we want $\\mathrm{Var}(Y)$ to be equal to $\\mathrm{Var}(x_i)$ then $\\mathrm{Var}(w_i)$ should be equal to $\\frac{1}{n}$, here $n$ is fan in, similarly we can get something similar when can consider from backprop prospective and we get   $\\frac{1}{n}$, here $n$ is fan out,\n",
    "Putting the two together we want \n",
    "$$\\mathrm{Var}(w_i) = \\frac{2}{{\\mathrm{fan}_{\\mathrm{in}}+\\mathrm{fan}_{\\mathrm{out}}}}$$\n",
    "Which happens to be Caffe weight initialization method.\n",
    "\n",
    "Now if we consider uniform distribution to be in range of $[-\\theta, \\theta]$ then <br>\n",
    "$$\\mathrm{Var} = \\frac{(\\theta-(-\\theta))^2}{12} = \\frac{\\theta^2}{3}$$\n",
    "This is the term which introduces $\\sqrt{6}$ in  Xavier’s initialization \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Some standard choices for training deep networks: SGD + Nesterov momentum, SGD with Adagrad/RMSProp/Adam\n",
    "- ReLUs, Leaky ReLUs and MaxOut are the best bets for activation functions\n",
    "- Batch Normalization layers are here to stay (at least, for now)\n",
    "- DropOut is an excellent regularizer\n",
    "- Data Augmentation is a must in vision applications\n",
    "- Weight Initialization is very important while training a new network\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision Basics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can think of a (grayscale) image as a function $f: \\mathcal{R}^2 \\rightarrow \\mathcal{R}$ giving the intensity at position $(x, y)$\n",
    "- A digital image is a discrete (sampled, quantized) version of this function\n",
    "- As with any function, we can apply operators to an image <br>\n",
    "  ![](CS5480_images/Teams_ewdyHST5WR.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing Operations\n",
    "\n",
    "- Point: the output value at a specific coordinate is dependent only on the input value at that same coordinate.\n",
    "- Local: the output value at a specific coordinate is dependent on the input values in the neighborhood of that same coordinate.\n",
    "- Global: the output value at a specific coordinate is dependent on all the values in the input image. eg ( fourier, wavelet)\n",
    "\n",
    "Simple Point Operations: Image Enhancement\n",
    "\n",
    "- Reversing the contrast new_pixel = max old_pixel + min\n",
    "- Contrast stretching\n",
    "\n",
    "Noise Reduction\n",
    "\n",
    "- Noise Reduction using 2D Moving Average <br><br>\n",
    "  ![](CS5480_images//Acrobat_ETFnrX7rAR.png)<br><br>\n",
    "\n",
    "Linear Filtering\n",
    "\n",
    "- One simple version: linear filtering\n",
    "    - Replace each pixel by a linear combination (a weighted sum) of its neighbors\n",
    "- The prescription for the linear combination is called the “kernel” (or “mask”, “filter”)<br><br>\n",
    "  ![](CS5480_images//Acrobat_xmaJwzmjtS.png)<br><br>\n",
    "\n",
    "Linear Filtering: Cross correlation\n",
    "\n",
    "- Say the averaging window size is $2k+1 \\times  2k+1$:\n",
    "\n",
    "  $$G[i,j]=\\underbrace{\\frac{1}{(2k+1)^{2}}}_{\\text{Uniform weight to each pixel} } \\times \\overbrace{ \\sum_{u=-k}^{k}\\sum_{v=-k}^{k}F[i+u,j+v]}^{\\text{loop over all pixels in neighborhood}} $$\n",
    "\n",
    "- Now generalize to allow different weights depending on neighboring pixel’s relative position:\n",
    "  $$G[i,j]=\\sum_{u=-k}^{k}\\sum_{v=-k}^{k}\\underbrace{H[u,v]}_{\\text{Non-uniform weight}} F[i+u,j+v]$$\n",
    "\n",
    "- This is called cross correlation , denoted by $G=H\\otimes F$\n",
    "- Filtering an image: replace each pixel with a linear combination of its neighbors\n",
    "- Can think of as a “dot product” between local neighborhood and kernel for each pixel\n",
    "- The entries of the weight kernel or “mask” H[u,v] are called __filter co-efficients.__\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Filtering: Correlation Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolution operator\n",
    "  $$G[i,j] =\\sum_{u=-k}^{k}\\sum_{v=-k}^{k}H[u,v]F[i-u,j-v]$$\n",
    "  and $H$ is then called the impulse response function.\n",
    "- Equivalent to flip the filter in both dimensions (bottom to top, right to left) and apply cross correlation.\n",
    "  $$G=H*F$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "$\\tiny  {\\textcolor{#808080}{\\boxed{\\text{Reference: Dr. Vineeth, IIT Hyderabad }}}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0e5e69b8442e8f020791fad6bfcef3777f0e89e0f1a2517b6b628b2eaf0fe66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
