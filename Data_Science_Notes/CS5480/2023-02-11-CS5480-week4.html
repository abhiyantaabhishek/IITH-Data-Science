<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Abhishek Kumar Dubey">
<meta name="dcterms.date" content="2023-02-11">
<meta name="description" content="Filtering, correlation and convolution.">

<title>Deep Learning 4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../Data_Science_Notes/CS5480/2023-03-04-CS5480-week5.html" rel="next">
<link href="../../Data_Science_Notes/CS5480/2023-02-04-CS5480-week3.html" rel="prev">
<link href="../../logo.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-5ZQX02R26E"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-5ZQX02R26E', { 'anonymize_ip': true});
</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Deep Learning 4">
<meta property="og:description" content="Filtering, correlation and convolution.">
<meta property="og:image" content="http://localhost:4200/Data_Science_Notes/CS5480/CS5480_images/Acrobat_fJKIgb7Ffx.png">
<meta property="og:image:height" content="282">
<meta property="og:image:width" content="628">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text"><i class="fa-solid fa-house" aria-label="house"></i> Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../Data_Science_Notes/index.html" aria-current="page">
 <span class="menu-text"><i class="fa-solid fa-book-open-reader" aria-label="book-open-reader"></i> Data Science Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Data_Science_Hacks/index.html">
 <span class="menu-text"><i class="fa-solid fa-user-ninja" aria-label="user-ninja"></i> Data Science Hacks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Data_Science_Projects/index.html">
 <span class="menu-text"><i class="fa-solid fa-file-powerpoint" aria-label="file-powerpoint"></i> Data Science Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text"><i class="fa-solid fa-address-card" aria-label="address-card"></i> About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/abhiyantaabhishek"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/abhishek-kumar-dubey-585a86179/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Deep Learning 4</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">Deep Learning 4</h1>
                  <div>
        <div class="description">
          Filtering, correlation and convolution.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Deep Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Abhishek Kumar Dubey </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 11, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../Data_Science_Notes/index.html" class="sidebar-item-text sidebar-link">Data Science Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">CS5480</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5480/2023-01-07-CS5480-week1.html" class="sidebar-item-text sidebar-link">Deep Learning 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5480/2023-01-21-CS5480-week2.html" class="sidebar-item-text sidebar-link">Deep Learning 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5480/2023-02-04-CS5480-week3.html" class="sidebar-item-text sidebar-link">Deep Learning 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5480/2023-02-11-CS5480-week4.html" class="sidebar-item-text sidebar-link active">Deep Learning 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5480/2023-03-04-CS5480-week5.html" class="sidebar-item-text sidebar-link">Deep Learning 5</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5480/2023-03-18-CS5480-week6.html" class="sidebar-item-text sidebar-link">Deep Learning 6</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">CS5590</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-08-06-CS5590-week1.html" class="sidebar-item-text sidebar-link">Machine Learning 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-08-20-CS5590-week2.html" class="sidebar-item-text sidebar-link">Machine Learning 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-08-27-CS5590-week3.html" class="sidebar-item-text sidebar-link">Machine Learning 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-09-10-CS5590-week4.html" class="sidebar-item-text sidebar-link">Machine Learning 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-09-24-CS5590-week5.html" class="sidebar-item-text sidebar-link">Machine Learning 5</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-10-08-CS5590-week6.html" class="sidebar-item-text sidebar-link">Machine Learning 6</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-10-15-CS5590-week7.html" class="sidebar-item-text sidebar-link">Machine Learning 7</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-10-29-CS5590-week8.html" class="sidebar-item-text sidebar-link">Machine Learning 8</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS5590/2022-11-05-CS5590-week9.html" class="sidebar-item-text sidebar-link">Machine Learning 9</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">CS6660</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-09-03-CS6660-week3.html" class="sidebar-item-text sidebar-link">Linear Algebra 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-09-17-CS6660-week4_2.html" class="sidebar-item-text sidebar-link">Linear Algebra 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-10-01-CS6660-week6.html" class="sidebar-item-text sidebar-link">Linear Algebra 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-08-06-CS6660-week1.html" class="sidebar-item-text sidebar-link">Probability Theory 1</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-08-13-CS6660-week2.html" class="sidebar-item-text sidebar-link">Probability Theory 2</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-09-17-CS6660-week4_1.html" class="sidebar-item-text sidebar-link">Probability Theory 3</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-09-24-CS6660-week5.html" class="sidebar-item-text sidebar-link">Probability Theory 4</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Data_Science_Notes/CS6660/2022-10-15-CS6660-week7.html" class="sidebar-item-text sidebar-link">Probability Theory 5</a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#image-filtering" id="toc-image-filtering" class="nav-link active" data-scroll-target="#image-filtering"><span class="toc-section-number">1</span>  Image Filtering</a></li>
  <li><a href="#gaussian-filter" id="toc-gaussian-filter" class="nav-link" data-scroll-target="#gaussian-filter"><span class="toc-section-number">2</span>  Gaussian Filter</a></li>
  <li><a href="#effect-of-simple-kernels-on-image" id="toc-effect-of-simple-kernels-on-image" class="nav-link" data-scroll-target="#effect-of-simple-kernels-on-image"><span class="toc-section-number">3</span>  Effect of simple kernels on image</a></li>
  <li><a href="#linear-filtering-correlation-example" id="toc-linear-filtering-correlation-example" class="nav-link" data-scroll-target="#linear-filtering-correlation-example"><span class="toc-section-number">4</span>  Linear Filtering: Correlation Example</a></li>
  <li><a href="#convolution" id="toc-convolution" class="nav-link" data-scroll-target="#convolution"><span class="toc-section-number">5</span>  Convolution</a></li>
  <li><a href="#correlation-vs-convolution" id="toc-correlation-vs-convolution" class="nav-link" data-scroll-target="#correlation-vs-convolution"><span class="toc-section-number">6</span>  Correlation vs Convolution</a></li>
  <li><a href="#boundary-effects" id="toc-boundary-effects" class="nav-link" data-scroll-target="#boundary-effects"><span class="toc-section-number">7</span>  Boundary Effects</a></li>
  <li><a href="#correlation-vs-convolution-1" id="toc-correlation-vs-convolution-1" class="nav-link" data-scroll-target="#correlation-vs-convolution-1"><span class="toc-section-number">8</span>  Correlation vs Convolution</a></li>
  <li><a href="#convolution-a-linear-operator" id="toc-convolution-a-linear-operator" class="nav-link" data-scroll-target="#convolution-a-linear-operator"><span class="toc-section-number">9</span>  Convolution: A Linear Operator</a></li>
  <li><a href="#separable-filters" id="toc-separable-filters" class="nav-link" data-scroll-target="#separable-filters"><span class="toc-section-number">10</span>  Separable Filters</a></li>
  <li><a href="#image-filtering-edge-detection" id="toc-image-filtering-edge-detection" class="nav-link" data-scroll-target="#image-filtering-edge-detection"><span class="toc-section-number">11</span>  Image Filtering: Edge Detection</a></li>
  <li><a href="#derivatives-with-convolution" id="toc-derivatives-with-convolution" class="nav-link" data-scroll-target="#derivatives-with-convolution"><span class="toc-section-number">12</span>  Derivatives with convolution</a></li>
  <li><a href="#image-gradient" id="toc-image-gradient" class="nav-link" data-scroll-target="#image-gradient"><span class="toc-section-number">13</span>  Image gradient</a></li>
  <li><a href="#effects-of-noise" id="toc-effects-of-noise" class="nav-link" data-scroll-target="#effects-of-noise"><span class="toc-section-number">14</span>  Effects of Noise</a></li>
  <li><a href="#going-beyond-edges" id="toc-going-beyond-edges" class="nav-link" data-scroll-target="#going-beyond-edges"><span class="toc-section-number">15</span>  Going Beyond Edges</a></li>
  <li><a href="#more-motivation" id="toc-more-motivation" class="nav-link" data-scroll-target="#more-motivation"><span class="toc-section-number">16</span>  More motivation</a></li>
  <li><a href="#what-point-to-choose-for-feature-extraction" id="toc-what-point-to-choose-for-feature-extraction" class="nav-link" data-scroll-target="#what-point-to-choose-for-feature-extraction"><span class="toc-section-number">17</span>  What point to choose for feature extraction</a></li>
  <li><a href="#how-to-select-an-interest-point" id="toc-how-to-select-an-interest-point" class="nav-link" data-scroll-target="#how-to-select-an-interest-point"><span class="toc-section-number">18</span>  How to select an interest point</a></li>
  <li><a href="#using-eigenvalues" id="toc-using-eigenvalues" class="nav-link" data-scroll-target="#using-eigenvalues"><span class="toc-section-number">19</span>  Using eigenvalues</a></li>
  <li><a href="#harris-corner-detector" id="toc-harris-corner-detector" class="nav-link" data-scroll-target="#harris-corner-detector"><span class="toc-section-number">20</span>  Harris corner detector</a></li>
  <li><a href="#a-lot-of-other-interest-point-detectors" id="toc-a-lot-of-other-interest-point-detectors" class="nav-link" data-scroll-target="#a-lot-of-other-interest-point-detectors"><span class="toc-section-number">21</span>  A lot of other interest point detectors</a></li>
  <li><a href="#sift" id="toc-sift" class="nav-link" data-scroll-target="#sift"><span class="toc-section-number">22</span>  SIFT</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="image-filtering" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="image-filtering"><span class="header-section-number">1</span> Image Filtering</h2>
<p>Modify the pixels in an image based on some function of a local neighborhood of each pixel</p>
<ul>
<li>One simple version: linear filtering
<ul>
<li>Replace each pixel by a linear combination (a weighted sum) of its neighbors</li>
</ul></li>
<li>The prescription for the linear combination is called the “kernel” (or “mask”, “</li>
</ul>
<p>Linear Filtering: Cross correlation - simple averge <span class="math display">G[i,j]=\underbrace{\frac{1}{(2k+1)^{2}}}_{\text{Uniform weight to each pixel} } \times \overbrace{ \sum_{u=-k}^{k}\sum_{v=-k}^{k}F[i+u,j+v]}^{\text{loop over all pixels in neighborhood}} </span> - weighted average, <span class="math display">G[i,j]=\sum_{u=-k}^{k}\sum_{v=-k}^{k}\underbrace{H[u,v]}_{\text{Non-uniform weight}} F[i+u,j+v]</span></p>
<ul>
<li>what we get in <span class="math inline">G</span> depends on how we choose <span class="math inline">H</span></li>
<li>different <span class="math inline">H</span> is required for different features</li>
<li>THis kind of linear filter is called cross corelation</li>
<li>it is a measure of correlation between <span class="math inline">H</span> and <span class="math inline">F</span>, it can be also viewed as local operation</li>
<li><span class="math inline">H</span> is called kernel as well</li>
</ul>
<p>Smoothing by Averaging Computer Vision</p>
<ul>
<li>take <span class="math inline">5 \times 5</span> or <span class="math inline">3 \times 3</span> kernal and apply on image</li>
<li><span class="math inline">5 \times 5</span> will blur more as compared to <span class="math inline">3 \times 3</span></li>
</ul>
</section>
<section id="gaussian-filter" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="gaussian-filter"><span class="header-section-number">2</span> Gaussian Filter</h2>
<p>What if we want nearest neighboring pixels to have the most influence on the output? - Use Gaussian filter <br><br> <img src="CS5480_images//Acrobat_fJKIgb7Ffx.png" class="img-fluid"><br><br> - Removes high frequency components from the image (“low pass filter”). More on this later. - With Gaussian filter, we can preserve more structure, in mean (average) filter there is blockyness, but in Gaussian filter there is a fading kind of affect, no blockyness. - Smoothing with a Gaussian <br><br> <img src="CS5480_images//Acrobat_R9L6puubpD.png" class="img-fluid"><br><br> - Mean vs Gaussian<br> In below pic left is mean, right is Gaussian:<br><br> <img src="CS5480_images//Acrobat_EaiHqIHeFd.png" class="img-fluid"><br><br></p>
<p>Size of kernel or mask:</p>
<ul>
<li>Gaussian function has infinite support, but discrete filters use finite kernels.<br><br> <img src="CS5480_images//Acrobat_Bv8uLOlUeV.png" class="img-fluid"><br></li>
</ul>
<p>What is the result of filtering the impulse signal (image) F with the arbitrary kernel H?</p>
<ul>
<li><p>it double filpps the image</p></li>
<li><p>for convolution we dobuble fipp the kernal and then do dot product</p></li>
</ul>
</section>
<section id="effect-of-simple-kernels-on-image" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="effect-of-simple-kernels-on-image"><span class="header-section-number">3</span> Effect of simple kernels on image</h2>
<ul>
<li>Does nothing <span class="math display">\left\lbrack \begin{array}{ccc}
0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0
\end{array}\right\rbrack</span></li>
<li>Blurs <span class="math display">\frac{1}{9}\left\lbrack \begin{array}{ccc}
1 &amp; 1 &amp; 1\\
1 &amp; 1 &amp; 1\\
1 &amp; 1 &amp; 1
\end{array}\right\rbrack</span></li>
<li>Shifts left by one pixel with correlation <span class="math display">\left\lbrack \begin{array}{ccc}
0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 0
\end{array}\right\rbrack</span></li>
</ul>
</section>
<section id="linear-filtering-correlation-example" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="linear-filtering-correlation-example"><span class="header-section-number">4</span> Linear Filtering: Correlation Example</h2>
<p>What is the result of filtering the impulse signal (image) <span class="math inline">F</span> with the arbitrary kernel <span class="math inline">H</span>?</p>
<ul>
<li>It double flips the kernel as shown below <br><br> <img src="CS5480_images//Acrobat_qqLzTio3r5.png" class="img-fluid"><br></li>
</ul>
</section>
<section id="convolution" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="convolution"><span class="header-section-number">5</span> Convolution</h2>
<ul>
<li>Convolution operator <span class="math display">G[i,j]=\sum_{u=-k}^{k}\sum_{v=-k}^{k}H[u,v]F[i-u,j-v]</span> and <span class="math inline">H</span> is then called the impulse response function.</li>
<li>Equivalent to flip the filter in both dimensions (bottom to top, right to left) and apply cross correlation. Notice minus sign in the above equation <span class="math inline">(F[i-u,j-v])</span><br><br> <img src="CS5480_images//Acrobat_wiFH6WY42a.png" class="img-fluid"><br></li>
<li>Denoted by<br> <span class="math display">G=H*F</span></li>
</ul>
</section>
<section id="correlation-vs-convolution" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="correlation-vs-convolution"><span class="header-section-number">6</span> Correlation vs Convolution</h2>
<ul>
<li><p>Correlation :<br> <span class="math inline">G=H\otimes{\cal F}</span><br> <span class="math inline">G[i,j]=\sum_{u=-k}^{k}\sum_{v=-k}^{k}H[u,v]F[i+u,j+v]</span></p></li>
<li><p>Convolution :<br> <span class="math inline">G=H*F</span><br> <span class="math inline">G[i,j]=\sum_{u=-k}^{k}\sum_{v=-k}^{k}H[u,v]F[i-u,j-v]</span></p></li>
<li><p>For a Gaussian or box filter, how will the outputs differ (among correlation and convolution )?</p>
<ul>
<li>it will not as filter is symmetric</li>
</ul></li>
<li><p>For impulse image</p>
<ul>
<li>we saw above</li>
</ul></li>
</ul>
</section>
<section id="boundary-effects" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="boundary-effects"><span class="header-section-number">7</span> Boundary Effects</h2>
<ul>
<li>valid conv, we agree ouput will be smaller, we don’t touch the image</li>
<li>padded conv, we pad the boundary and the conv,
<ul>
<li>zero, wrap, clamp. mirror</li>
</ul></li>
</ul>
</section>
<section id="correlation-vs-convolution-1" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="correlation-vs-convolution-1"><span class="header-section-number">8</span> Correlation vs Convolution</h2>
<ul>
<li><p>Both correlation and convolution are linear shift invariant (LSI) operators , which obey both the superposition principle (Linearity) <span class="math display">h\circ(f_{0}+f_{1})=h\circ f_{o}+h\circ f_{1}</span> and the shift invariance principle <br> <span class="math display">\text{If  \;\;}g(i,j)=f(i+k,j+l)\leftrightarrow(h\circ g)(i,j)=(h\circ f)(i+k,j+l)</span></p>
<p>which means that shifting a signal commutes with applying the operator.</p></li>
<li><p>Is the same as saying that the effect of the operator is the same everywhere.</p></li>
<li><p>What’s the difference?</p>
<ul>
<li>Commutativity?
<ul>
<li>Convolution is commutative, but correlation is not.</li>
</ul></li>
<li>Associativity?
<ul>
<li>Convolution is associative, but correlation is not.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="convolution-a-linear-operator" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="convolution-a-linear-operator"><span class="header-section-number">9</span> Convolution: A Linear Operator</h2>
<ul>
<li>Commutative: <span class="math inline">a * b = b * a</span>
<ul>
<li>Conceptually no difference between filter and signal</li>
</ul></li>
<li>Associative: <span class="math inline">a * (b * c) = (a * b) * c</span>
<ul>
<li>Often apply several filters one after another: <span class="math inline">(((a * b1) * b2) * b3)</span></li>
<li>This is equivalent to applying one filter: <span class="math inline">a * (b1 * b2 * b3)</span></li>
</ul></li>
<li>Distributes over addition: <span class="math inline">a * (b + c) = (a * b) + (a * c)</span></li>
<li>Scalars factor out: <span class="math inline">ka * b = a * kb = k (a * b)</span></li>
<li>Identity: unit impulse <span class="math inline">e = [\dots, 0, 0, 1, 0, 0, \dots], a * e = a</span></li>
</ul>
</section>
<section id="separable-filters" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="separable-filters"><span class="header-section-number">10</span> Separable Filters</h2>
<ul>
<li>The process of performing a convolution requires <span class="math inline">K ^2</span> operations per pixel, where <span class="math inline">K</span> is the size (width or height) of the convolution kernel.</li>
<li>In many cases, this operation can be speed up by first performing a <span class="math inline">1D</span> horizontal convolution followed by a <span class="math inline">1D</span> vertical convolution, requiring <span class="math inline">2K</span> operations.</li>
<li>If this is possible, then the convolution kernel is called <strong>separable</strong></li>
<li>And it is the outer product of two kernels <span class="math inline">K = vh^T</span></li>
<li>How can we tell if a given kernel K is indeed separable?
<ul>
<li>Look at the singular value decomposition (SVD) , and if only one singular value is non zero, then it is separable <span class="math display">K=\mathbf{U}\Sigma\mathbf{V}^{T}=\sum_{i}\sigma_{i}u_{i}v_{i}^{T}</span> with <span class="math inline">\Sigma=\mathrm{diag}(\sigma_{i})</span><br> <span class="math inline">{\sqrt{\sigma_{1}}}\mathbf{u}_{1}</span> and <span class="math inline">{\sqrt{\sigma_{1}}}V_{1}^{T}</span> are the vertical and horizontal kernels.</li>
</ul></li>
</ul>
</section>
<section id="image-filtering-edge-detection" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="image-filtering-edge-detection"><span class="header-section-number">11</span> Image Filtering: Edge Detection</h2>
<ul>
<li>Map image from 2d array of pixels to a set of curves or line segments or contours .</li>
<li>More compact than pixels.</li>
<li>Look for strong gradients, post process.</li>
<li>Edges look like steep cliffs</li>
<li>An edge is a place of rapid change in the image intensity function</li>
</ul>
<p>An edge is a place of rapid change in the image intensity function<br><br> <img src="CS5480_images//Acrobat_iS6cO4gT2u.png" class="img-fluid"><br></p>
</section>
<section id="derivatives-with-convolution" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="derivatives-with-convolution"><span class="header-section-number">12</span> Derivatives with convolution</h2>
<ul>
<li><p>For 2D function, f(x,y), the partial derivative is: <span class="math display">\frac{\partial f(x,y)}{\partial x}=\operatorname*{lim}_{\varepsilon\to0}\frac{f(x+\varepsilon,y)-f(x,y)}{\varepsilon}</span></p></li>
<li><p>For discrete data, we can approximate using finite differences: <span class="math display">{\frac{\partial f(x,y)}{\partial x}}\approx{\frac{f(x+1,y)-f(x,y)}{1}}</span></p></li>
<li><p>To implement above as convolution, what would be the associated filter?</p></li>
</ul>
<p>Sobel Edge Detection Filter</p>
</section>
<section id="image-gradient" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="image-gradient"><span class="header-section-number">13</span> Image gradient</h2>
<ul>
<li><p>The gradient of an image: <span class="math display">{\nabla}f=\left[{\frac{\partial f}{\partial x}},{\frac{\partial f}{\partial y}}\right]</span></p></li>
<li><p>The gradient points in the direction of most rapid change in intensity <br><br> <img src="CS5480_images/Acrobat_xRYjpwe3Sa.png" class="img-fluid"> <br></p></li>
<li><p>The gradient direction orientation of edge normal) is given by: <span class="math display">\theta=\tan^{-1}\left(\frac{\partial f}{\partial y}\bigg/\frac{\partial f}{\partial x}\right)</span></p></li>
</ul>
</section>
<section id="effects-of-noise" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="effects-of-noise"><span class="header-section-number">14</span> Effects of Noise</h2>
<p>Consider a single row or column of a noisy image</p>
<ul>
<li>Plotting intensity as a function of position gives a signal <br><br> <img src="CS5480_images/Acrobat_Oim6GeG6f1.png" class="img-fluid"><br><br></li>
<li>We are not able to find the edge.So we need to smoothen it first.We can use blurring here for proper smoothing.Once smoothing is done, we can apply, gradient operation. Mathematically <span class="math inline">\displaystyle\frac{\partial }{\partial x}( h*f)</span> <br><br> <img src="CS5480_images/Acrobat_OL0SowqWcz.png" class="img-fluid"><br><br></li>
<li>Notice.Nothing is in convolution operation here.So instead of doing convolution on the image we can First, find the gradient of the convolution filter.And keep it and now, convolve this on the image.As convolution follows associative property, so it will produce the same result as earlier.Mathematically, it can be express as: <span class="math inline">\displaystyle\left(\frac{\partial }{\partial x} h\right)*f</span> <br><br> <img src="CS5480_images/Acrobat_irSVddifsE.png" class="img-fluid"></li>
</ul>
</section>
<section id="going-beyond-edges" class="level2" data-number="15">
<h2 data-number="15" class="anchored" data-anchor-id="going-beyond-edges"><span class="header-section-number">15</span> Going Beyond Edges</h2>
<ul>
<li><p>How to combine these two images to form a panorama?<br><br> <img src="CS5480_images/Acrobat_eiGQvLoH3z.png" class="img-fluid"><br></p></li>
<li><p>The answer is feature extraction and matching, Image alignment</p></li>
<li><p>Detection : Identify the interest</p></li>
<li><p>Description : Extract vector feature descriptor around each interest point</p></li>
<li><p>Matching : Determine correspondence between descriptors in two<br><br> <img src="CS5480_images/Acrobat_Tfz420a13i.png" class="img-fluid"><br></p></li>
<li><p>to find 6 values of rotaition matrix we nee only 3 pair points.</p></li>
</ul>
</section>
<section id="more-motivation" class="level2" data-number="16">
<h2 data-number="16" class="anchored" data-anchor-id="more-motivation"><span class="header-section-number">16</span> More motivation</h2>
<ul>
<li>Feature points are used for:
<ul>
<li>Image alignment (e.g., mosaics)</li>
<li>3D reconstruction</li>
<li>Motion tracking</li>
<li>Object recognition</li>
<li>Indexing and database retrieval</li>
<li>Robot navigation</li>
</ul></li>
</ul>
</section>
<section id="what-point-to-choose-for-feature-extraction" class="level2" data-number="17">
<h2 data-number="17" class="anchored" data-anchor-id="what-point-to-choose-for-feature-extraction"><span class="header-section-number">17</span> What point to choose for feature extraction</h2>
<p>Want uniqueness</p>
<ul>
<li><p>Look for image regions that are unusual: lead to unambiguous matches in other images</p></li>
<li><p>How to define “unusual”?</p></li>
</ul>
<p>Local measure of uniqueness</p>
<ul>
<li><p>Suppose we only consider a small window of pixels</p>
<ul>
<li>What defines whether a feature is a good or bad - candidate? <br><br> <img src="CS5480_images/Acrobat_T7hkKKM1xh.png" class="img-fluid"><br></li>
<li>How does the window change when we shift it?</li>
<li>Shifting the window in any direction causes a big change<br><br> <img src="CS5480_images/Acrobat_maeHAmLNEl.png" class="img-fluid"><br></li>
</ul></li>
</ul>
<p>A simple matching criteria</p>
<ul>
<li>Consider the below image:<br><br> <img src="CS5480_images/Acrobat_2ZSntn4wcL.png" class="img-fluid"><br><br>
<ul>
<li>Consider shifting the window <span class="math inline">W</span> by <span class="math inline">(u,v)</span></li>
<li>compare each pixel before and after by summing up the squared differences (SSD)</li>
<li>We can notice that if the window moves on the edge, there will not be any significant squared differences (SSD) here.But if the window moves on the corner then there will be some squared differences (SSD).</li>
<li>The squared distance is given as below: <span class="math display">E(u,v)=\sum_{(x,y)\in W}\left[I(x+v,y+v)-I(x,y)\right]^{2}</span></li>
<li>Compare two image patches using (weighted) summed square difference (also, called auto correlation function <span class="math display">E_{A C}(\Delta\mathbf{u})=\sum_{\cdot}{\mathbf{}}w(\mathbf{p}_{i})[I_{0}(\mathbf{p}_{i}+\Delta u)-I_{0}(\mathbf{p}_{i})]^{2}</span> <img src="CS5480_images/Acrobat_tE3olrWBXr.png" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="how-to-select-an-interest-point" class="level2" data-number="18">
<h2 data-number="18" class="anchored" data-anchor-id="how-to-select-an-interest-point"><span class="header-section-number">18</span> How to select an interest point</h2>
<ul>
<li>Small motion assumption</li>
<li>Using a Taylor Series expansion <span class="math display">I_{0}({\bf p}_{i}+\Delta{\bf u})\approx I_{0}({\bf p}_{i})+\nabla I_{0}({\bf p}_{i})\Delta{\bf u}</span> where <span class="math display">\nabla I_{0}(\mathbf{p}_{i})=\left({\frac{\partial I_{0}}{\partial x}},{\frac{\partial I_{0}}{\partial y}}\right)(\mathbf{p}_{i})</span></li>
<li>the image gradient. We can approximate the autocorrelation as <span class="math display">
\begin{align*}
  E_{A C}(\Delta\mathbf{u})&amp;=\sum_{\cdot}{\mathbf{}}w(\mathbf{p}_{i})[I_{0}(\mathbf{p}_{i}+\Delta u)-I_{0}(\mathbf{p}_{i})]^{2}\\
  &amp;\approx\sum_{\cdot}{\mathbf{}}w(\mathbf{p}_{i})[I_{0}({\bf p}_{i})+\nabla I_{0}({\bf p}_{i})\Delta{\bf u}-I_{0}(\mathbf{p}_{i})]^{2}\\
  &amp;=\sum_{\cdot}{\mathbf{}}w(\mathbf{p}_{i})[\nabla I_{0}({\bf p}_{i})\Delta{\bf u}]^{2}\\
  &amp;=\Delta \mathbf u^T \mathbf A\Delta \mathbf u
\end{align*}
</span></li>
<li>Gradient can be computed with the filtering techniques we saw, e.g., derivatives of Gaussians.</li>
<li>The autocorrelation is <span class="math display">E_{A C}(\Delta\mathbf{u}) = \Delta \mathbf u^T \mathbf A\Delta \mathbf u</span> with <span class="math display">\mathbf{A}=\sum_{u}\sum_{\nu}w(u,v)\left[{\begin{array}{l l}{I_{x}^{2}}&amp;{I_{x}J_{y}}\\ {I_{y}I_{x}}&amp;{I_{y}^{2}}\end{array}}\right]=w*\left[{\begin{array}{l l}{I_{x}^{2}}&amp;{I_{x}I_{y}}\\ {I_{y}I_{x}}&amp;{I_{y}^{2}}\end{array}}\right]</span> where we have replaced the weighted summations with discrete convolutions with the weighting kernel <span class="math inline">w</span>.</li>
</ul>
</section>
<section id="using-eigenvalues" class="level2" data-number="19">
<h2 data-number="19" class="anchored" data-anchor-id="using-eigenvalues"><span class="header-section-number">19</span> Using eigenvalues</h2>
<ul>
<li><p>The eigenvalues of <span class="math inline">\mathbf A</span> reveal the amount of intensity change in the two principal orthogonal gradient directions in the window. <span class="math display">\mathbf{A}=\mathbf{U}\left[\begin{array}{c c}{{\lambda_{0}}}&amp;{{0}}\\ {{0}}&amp;{{\lambda_{1}}}\end{array}\right]\mathbf{U}^T</span> with <span class="math display">\mathbf{A}\mathbf{u}_{i}=\lambda_{i}\mathbf{u}_{i}</span></p></li>
<li><p>In case of matrix:</p>
<p><img src="CS5480_images/Acrobat_kAgoElQQY7.png" class="img-fluid"></p></li>
<li><p>An example, here <span class="math inline">\lambda</span> is an eigen value</p>
<p><img src="CS5480_images/Acrobat_yCe1sdTyUz.png" class="img-fluid"></p></li>
<li><p>Classification of image points using eigenvalues of <span class="math inline">\mathbf A</span></p>
<p><img src="CS5480_images/Acrobat_ZY9uM5q7ES.png" class="img-fluid"></p></li>
<li><p>Type of responses</p>
<p><img src="CS5480_images/Acrobat_QajpWmL1qv.png" class="img-fluid"></p></li>
<li><p>But here we still need to calculate the eigenvalues. There is a method where we can compare the eigenvalues without even calculating it.</p></li>
<li><p>We know that the trace of a matrix is the summation of the eigenvalues and the determinant of the matrix is the multiplication of the eigenvalues. We will use the same property.</p></li>
</ul>
</section>
<section id="harris-corner-detector" class="level2" data-number="20">
<h2 data-number="20" class="anchored" data-anchor-id="harris-corner-detector"><span class="header-section-number">20</span> Harris corner detector</h2>
<ul>
<li>First compute the gradient at each point of the image.</li>
<li>Compute <span class="math inline">\mathbf A</span> for each image window to get its cornerness scores</li>
<li>Compute the eigenvalues/compute the following function <span class="math inline">M_c</span> <span class="math display">M_{c}=\lambda_{1}\lambda_{2}-\kappa\left(\lambda_{1}+\lambda_{2}\right)^{2}=\operatorname*{det}(A)-\kappa\ \mathrm{trace}^{2}(A)</span></li>
<li>Find points whose surrounding window gave large corner response (<span class="math inline">M_c &gt;</span> threshold).</li>
<li>Take the points of local maxima, i.e., perform non maximum suppression.</li>
</ul>
</section>
<section id="a-lot-of-other-interest-point-detectors" class="level2" data-number="21">
<h2 data-number="21" class="anchored" data-anchor-id="a-lot-of-other-interest-point-detectors"><span class="header-section-number">21</span> A lot of other interest point detectors</h2>
<ul>
<li>Hessian</li>
<li>Lowe:DoG</li>
<li>Lindeberg: scale selection</li>
<li>Mikolajczyk&amp; Schmid : Hessian/Harris Laplacian/Affine</li>
<li>Tuyttelaars &amp; Van Gool: EBR and IBR</li>
<li>Matas: MSER</li>
<li>Kadir&amp; Brady: Salient Regions</li>
<li>SpeededUp Robust Features (SURF) of Bay et al.</li>
</ul>
</section>
<section id="sift" class="level2" data-number="22">
<h2 data-number="22" class="anchored" data-anchor-id="sift"><span class="header-section-number">22</span> SIFT</h2>
<ul>
<li><p>Step 1: Scales-pace extrema Detection: Detect interesting points (invariant to scale and orientation) using DOG.</p></li>
<li><p>Step 2:Keypoint Localization: Determine location and scale at each candidate location, and select them based on stability.</p></li>
<li><p>Step 3: Orientation Estimation: Use local image gradients to assigned orientation to each localized key point . Preserve theta, scale and location for each feature.</p></li>
<li><p>Step 4:Keypoint Descriptor: Extract local image gradients at selected scale around keypoint and form a representation invariant to local shape distortion and representation invariant to local shape distortion and illumination them.</p></li>
<li><p>SIFT: Scale space Extrema Detection</p>
<p><img src="CS5480_images/Acrobat_WJCt9NdOwQ.png" class="img-fluid"></p></li>
<li><p>Constructing scale space</p>
<p><img src="CS5480_images/Acrobat_GUXndO3PJF.png" class="img-fluid"></p>
<p><span class="math display">D(x,y,\sigma)=L(x,y,k\sigma)-L(x,y,\sigma)</span> where <span class="math display">L(x,y,\sigma)=G(x,y,\sigma)*I(x,y)</span></p>
<p><img src="CS5480_images/Acrobat_InyGPDX2qG.png" class="img-fluid"></p></li>
<li><p>Determine the location and scale of keypoints to sub-pixel and sub-scale accuracy by fitting a 3D quadratic polynomial:</p>
<ul>
<li>Key point location: <span class="math inline">X_i = (x_i,y_i,\sigma_i)</span><br> Note: We are finding key points for each and every scale. If there is a corner at one scale, tt can look like an edge, at another scale.</li>
<li>offset : <span class="math inline">\Delta X = (x-x_i,y-y_i,\sigma-\sigma_i)</span><br> Map the image back to the original location.</li>
<li>Sub-Pixel, Sub-scale, estimated location: <span class="math inline">X_i=X_i+\Delta X</span><br><br> <img src="CS5480_images/Acrobat_R3Bz8DKp9t.png" class="img-fluid"></li>
</ul></li>
</ul>
<p>SIFT: Keypoint Localization</p>
<ul>
<li>Use Taylor expansion to locally approximate <span class="math inline">D(x,y, \sigma )</span> (i.e., DoG function) and estimate <span class="math inline">\Delta X</span> <span class="math display">D(\Delta X)=D(X_{i})+{\frac{\partial D^{T}(X_{i})}{\partial X}}\Delta X+{\frac{1}{2}}\Delta X^{T}\,{\frac{\partial^2 D(X_{i})}{\partial X^2}}\Delta X</span></li>
<li>Find the extrema of <span class="math inline">D( \Delta X)</span>: <span class="math display">\frac{\partial D(X_{i})}{\partial X}+\frac{\partial ^{2}D(X_{i})}{\partial X^{2}}\Delta X=0</span> From above we get <span class="math display">\Delta X=-\frac{\displaystyle{\partial}^{2}D^{-1}(X_{i})}{\displaystyle{\partial}X^{2}}\frac{\partial D(X_{i})}{\displaystyle{\partial}X}</span></li>
<li><span class="math inline">\Delta X</span> can be computed by solving a 3x3 linear system <span class="math display">\displaystyle
\begin{bmatrix}
  \displaystyle\frac{\partial^2 D}{\partial \sigma^2} &amp;\displaystyle \frac{\partial^2 D}{\partial \sigma y} &amp;\displaystyle \frac{\partial^2 D}{\partial \sigma x}\\
  \displaystyle\frac{\partial^2 D}{\partial \sigma y} &amp;\displaystyle \frac{\partial^2 D}{\partial  y^2} &amp;\displaystyle \frac{\partial^2 D}{y x} \\
  \displaystyle\frac{\partial^2 D}{\partial \sigma x} &amp;\displaystyle \frac{\partial^2 D}{\partial  yx} &amp;\displaystyle \frac{\partial^2 D}{ \partial x^2}
\end{bmatrix}
\begin{bmatrix}
  \Delta \sigma\\
  \Delta y\\
  \Delta x\\
\end{bmatrix}=-
\begin{bmatrix}
\displaystyle \frac{\partial D}{ \partial \sigma} \\
\displaystyle \frac{\partial D}{ \partial y}  \\
\displaystyle \frac{\partial D}{ \partial x}
\end{bmatrix}
</span> where <span class="math display">\begin{align*}
  {\frac{\partial D}{\partial\sigma}}&amp;={\frac{D_{k+1}^{i,j}-D_{k-1}^{i,j}}{2}}\\
  \frac{{\partial}^{2}D}{{\partial}\sigma^{2}}&amp;=\frac{D_{k-1}^{i,j}-2D_{k}^{i,j}+D_{k+1}^{i,j}}{1}\\
  \frac{\partial^{2}D}{\partial\sigma y}\!&amp;=\!\frac{({D}_{k+1}^{i+1,j}-{D}_{k-1}^{i+1,j})\!-\!({D}_{k+1}^{i-1,j}-{D}_{k-1}^{i-1,j})}{4}\\
\end{align*}</span> if <span class="math inline">\Delta X&gt;0.5</span> in any dimension, repeat.</li>
<li>Next, reject the low contrast points and the points that lie on the edge</li>
<li>Low contrast points elimination:
<ul>
<li>if <span class="math inline">|D(X_{i}+\Delta X)|&lt;0.03</span> reject keypoint.
<ul>
<li>assumes that image values have been normalized in <span class="math inline">[0,1]</span></li>
</ul></li>
</ul></li>
<li>Edge elimination
<ul>
<li><p>Similar to Harris corner detector!</p></li>
<li><p>SIFT instead uses Hessian <span class="math display">\mathbf{H}={\left[\begin{array}{l l}{D_{x x}}&amp;{D_{x y}}\\ {D_{x y}}&amp;{D_{y y}}\end{array}\right]}</span> <span class="math display">\begin{align*}
  \operatorname{Tr}(\mathbf{H})&amp;=D_{x x}+D_{y y}=\alpha+\beta,\\
  \operatorname{Det}({\bf H})&amp;=D_{x x}D_{y y}-(D_{x y})^{2}=\alpha\beta.
\end{align*}</span> Hence <span class="math display">{\frac{\operatorname{Tr}(\mathbf{H})^{2}}{\operatorname{Det}(\mathbf{H})}}={\frac{(\alpha+\beta)^{2}}{\alpha\beta}}={\frac{(r\beta+\beta)^{2}}{r\beta^{2}}}={\frac{(r+1)^{2}}{r}},</span> Reject key point if <span class="math display">\frac{\mathrm{Tr}({\bf H})^{2}}{\mathrm{Det}({\bf H})}&lt;\frac{(r+1)^{2}}{r}</span> (SIFT uses <span class="math inline">r = 10</span>) (<span class="math inline">r=\frac{\alpha}{\beta}</span>)</p>
<p><img src="CS5480_images/Acrobat_xIzbcVfEtJ.png" class="img-fluid"></p></li>
</ul></li>
</ul>
<p>SIFT: Orientation Assignment</p>
<ul>
<li><p>Use scale of point to choose correct image: <span class="math display">L(x,y)=G(x,y,\sigma)*I(x,y)</span></p></li>
<li><p>Compute gradient magnitude and orientation using finite differences: <span class="math display">\begin{align*}
  m\bigl(x,y\bigr)&amp;=\sqrt{\bigl(L(x+1,y)-L\bigl(x-1,y\bigr)\bigr)^{2}+\bigl(L(x,y+1)-L\bigl(x,y-1\bigr)\bigr)^{2}}\\
  \theta(x,y)&amp;=\tan^{-1}\left(\frac{\left(L(x,y+1)-L(x,y-1)\right)}{\left(L(x+1,_{,}y)-L(x-1,_{,}y)\right)}\right)
\end{align*}</span></p></li>
<li><p>Use this to compute final descriptor.</p></li>
<li><p>Create histogram of gradient directions, within a region around the keypoint, at selected scale: <span class="math display">L(x,y,\sigma)=G(x,y,\sigma){*}\,J(x,y)</span> and <span class="math display">m(x,y)={\sqrt{(L(x+1,y)-L(x-1,y))^{2}+(L(x,y+1)-L(x,y-1))^{2}}}</span> and <span class="math display">\theta(x,y)=a\tan2{\big(}(L(x,y+1)-L(x,y-1){\big)}/(L(x+1,y)-L(x-1,y){\big)})</span></p>
<p><img src="CS5480_images/Acrobat_MThJ0iJaj2.png" class="img-fluid"></p></li>
<li><p>Histogram entries are weighted by <span class="math inline">( i )</span> gradient magnitude and <span class="math inline">(ii)</span> a Gaussian function with <span class="math inline">\sigma</span> equal to <span class="math inline">1.5</span> times the scale of the keypoint</p></li>
</ul>
<p>SIFT: Feature descriptor</p>
<ul>
<li><p>Compute the gradient at each pixel in a <span class="math inline">16 \times 16</span> window around the detected keypoint, using the appropriate level of the Gaussian pyramid at which the keypoint was detected.</p></li>
<li><p>Downweight gradients by a Gaussian fall off function (blue circle) to reduce the influence of gradients far from the center.</p></li>
<li><p>In each 4 x 4 quadrant, compute a gradient orientation histogram using 8 orientation histogram bins.</p>
<p><img src="CS5480_images/Acrobat_LVo3Y4bw6c.png" class="img-fluid"></p></li>
<li><p>The resulting 128 nonnegative values form a raw version of the SIFT descriptor vector.</p></li>
<li><p>To reduce the effects of contrast or gain (additive variations arealready removed by the gradient), the 128 D vector is normalized tounit length.</p></li>
<li><p>Great engineering effort!</p></li>
<li><p>Extraordinarily robust matching technique</p>
<ul>
<li>Changes in viewpoint: up to about 60 degree out of plane rotation</li>
<li>Changes in illumination: sometimes even day vs.&nbsp;night</li>
<li>Fast and efficientcan run in real time</li>
<li>Lots of code available<br><br></li>
</ul></li>
</ul>
<p>Review</p>
<p><img src="CS5480_images/Acrobat_ts4bKZdd8E.png" class="img-fluid"></p>
<p>SURF = Speeded Up Robust Features</p>
<ul>
<li>Uses box filters instead of Gaussians to approximate Laplacians</li>
<li>Uses wavelets to get keypoint orientations</li>
<li>Few more changes (including indescriptor generation)</li>
<li>Leads to 3x speedup over SIFT</li>
</ul>
<p>More on image features: LBP Computer Vision</p>
<ul>
<li><p>LBP = Local Binary Patterns</p>
<p><img src="CS5480_images/Acrobat_gVW7Ns7tmi.png" class="img-fluid"></p></li>
</ul>
<p><br><br><br> <span class="math inline">\tiny {\textcolor{#808080}{\boxed{\text{Reference: Dr. Vineeth, IIT Hyderabad }}}}</span></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="abhiyantaabhishek/IITH-Data-Science" data-repo-id="R_kgDOILoB8A" data-category="Announcements" data-category-id="DIC_kwDOILoB8M4CSJcL" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../Data_Science_Notes/CS5480/2023-02-04-CS5480-week3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Deep Learning 3</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../Data_Science_Notes/CS5480/2023-03-04-CS5480-week5.html" class="pagination-link">
        <span class="nav-page-text">Deep Learning 5</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022, Abhishek Kumar Dubey</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/abhiyantaabhishek">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/abhishek-kumar-dubey-585a86179/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>