{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "author: Abhishek Kumar Dubey\n",
        "badges: True\n",
        "categories:\n",
        "- LiDAR, Video\n",
        "date: '2023-08-14'\n",
        "description: 3D Object Detection for Self-Driving Cars Using Video and LiDAR, An Ablation Study\n",
        "title: 3D Object Detection for Self-Driving Cars Using Video and LiDAR, An Ablation Study \n",
        "toc: true\n",
        "bibliography: references.bib\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-caution title=\"Citation\"}\n",
        "@DBLP:journals/sensors/SalmaneVKMDCSV23\n",
        "\n",
        "[Paper link](https://www.mdpi.com/1424-8220/23/6/3223)\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- A 3D bounding box is represented by seven parameters [@DBLP:conf/cvpr/QiLWSG18]: $(x,y,z,h,w,l,\\theta)$ These parameters consist of the object's central coordinates $(x,y,z)$, its dimensions (height, width, and length), and its orientation angle $\\theta$. \n",
        "- @DBLP:conf/cvpr/Chen0SJ20  introduced a one-stage stereo-based 3D detection system that simultaneously estimates depth and identifies 3D objects using an end-to-end learning approach. They assert that their method surpasses earlier stereo-based 3D detectors and even rivals certain LiDAR-based techniques on the KITTI 3D object detection leaderboard.\n",
        "- @DBLP:conf/iros/LiKW20, addressed the issue of significant variability in depth estimation accuracy when using a video sensor. They introduce CG-Stereo, a confidence-guided stereo 3D object detection system. This pipeline employs distinct decoders for foreground and background pixels during the depth estimation process and utilizes confidence estimation from the depth estimation network as a form of soft attention in the 3D object detection. The authors contend that their method surpasses all leading stereo-based 3D detectors on the KITTI benchmark.\n",
        "- Another compelling approach found in scholarly work involves integrating LiDAR with a stereo camera. Such techniques leverage LiDAR's ability to enhance the visual data captured by the camera by introducing concepts of dimension and distance pertaining to various objects within the environment. Specifically, the method outlined by @DBLP:conf/cvpr/WangCGHCW19 capitalizes on the capability to recreate a 3D setting from stereo camera images. This allows for the derivation of a depth map from the stereo camera data, which is then augmented with measurements from the LiDAR sensor, such as height, width, length, and orientation angle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
