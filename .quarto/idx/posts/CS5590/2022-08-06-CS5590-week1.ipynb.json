{"title":"Machine Learning 1","markdown":{"yaml":{"author":"Abhishek Kumar Dubey","badges":false,"categories":["Machine Learning"],"date":"2022-08-06","description":"Training Error, Generalization Error","image":"CS5590_images/MATLAB_ljcLgT0iTJ.png","title":"Machine Learning 1","toc":true},"headingText":"Types of ML","containsRefs":false,"markdown":"\n\n\n\n\n- Supervised Learning\n    - classification, regression\n- Unsupervised learning\n- Other settings of ML\n    - Reinforcement learning\n    - Semi-supervised learning\n    - Active learning,Transfer learning,Structured learning\n- Dimensionality Reduction (unsupervised Learning)\n    - Large sample size is required for high dimensional data\n    - Query accuracy and efficiency degrade rapidly as the dimension increases\n    - strategies:\n        - Feature reduction, Feature selection, Manifold learning, Kernel learning\n        \n![](CS5590_images/MATLAB_z9KdPL77lT.png)\n\n## IID Assumption\n- Identically independently distributed : This is the assumption that the training data and testing data comes from the same distribution\n\n## Types of Models\n\n- Induction : Model Learns by Induction, ( creating it's own rules for example, if we do extensive research while buying mobile, we create set rules, it is called induction).\n- Transductions: Model learns from references ( for example, if we ask our friends about mobile and we buy according to their suggestion, it is called Transduction).\n- Online : data could be a stream, data keeps coming over time.\n- Offline: data is already acquired and trained offline.\n- Generative: Learns the distribution, the model learns joint probability distribution.\n- Discriminative:Learns to discriminate without learning distribution.\n- Parametric : The model have parameters like $\\mu$ and $\\sigma$\n- Non parametric: The model doesn't have parameters, as in K nearest neighbor (KNN)\n\n## Classifier evaluation\n\n![](CS5590_images/MATLAB_ljcLgT0iTJ.png)\n\n- Training Error\n    - Not very useful\n    - Relatively easy to obtain low error\n    - $E_{\\mathrm{train}} =\\frac{1}{n}\\sum_{i=1}^n \\mathrm{error}\\left(f_D \\left(X_i \\right),y_i \\right)$\n- Generalization Error\n    - Measure of how well do we do on unseen data\n    - $E_{\\mathrm{gen}} =\\int \\mathrm{error}\\left(f_D \\left(X\\right),y\\right)p\\left(y,X\\right)\\mathrm{dX}$\n\n## Stratified sampling\n- First stratify instances by class, then randomly select instances from each class proportionally\n- It ensures that the proportion of each class remains same in training and validation set.\n\n## Model Selection\n- Re-Substitution : not useful as it suggests to re- substitute the train data for validation as well\n- K - Fold cross-validation : Divide the data in K fold using stratified sampling, and the select some set for training and some for validation in each iteration.\n- Leave-one-out\n    - N-fold cross-validation\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"css":["../../styles.css"],"html-math-method":"katex","highlight-style":"tango","output-file":"2022-08-06-CS5590-week1.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.251","comments":{"giscus":{"repo":"abhiyantaabhishek/IITH-Data-Science","category":"Announcements"}},"toc-location":"right","theme":"cosmo","title-block-banner":true,"author":"Abhishek Kumar Dubey","badges":false,"categories":["Machine Learning"],"date":"2022-08-06","description":"Training Error, Generalization Error","image":"CS5590_images/MATLAB_ljcLgT0iTJ.png","title":"Machine Learning 1"},"extensions":{"book":{"multiFile":true}}}}}