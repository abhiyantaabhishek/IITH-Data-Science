<!DOCTYPE html>
<html lang="en"><head>
<link href="../logo.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Abhishek Kumar Dubey   cs22mds15010">
  <meta name="dcterms.date" content="2023-04-29">
  <title>Point cloud based 3d object detection</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css">
  <link rel="stylesheet" href="styles.css">
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-5ZQX02R26E"></script>

  <script type="text/javascript">

  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-5ZQX02R26E', { 'anonymize_ip': true});
  </script>
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Point cloud based 3d object detection">
<meta property="og:description" content="IMPLEMENTATION">
<meta property="og:image" content="http://localhost:4200/Data_Science_Projects/images/007402.png">
<meta property="og:image:height" content="375">
<meta property="og:image:width" content="1242">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="images/FirstPage_background.png" data-background-opacity="0.6" data-background-size="contain" class="quarto-title-block center">
  <h1 class="title">Point cloud based 3d object detection</h1>
  <p class="subtitle">Y. Zhou and O. Tuzel,Voxelnet, IEEE Conference on CVPR, pp.&nbsp;4490-4499, 2018.</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Abhishek Kumar Dubey <br> cs22mds15010 
</div>
</div>
</div>

  <p class="date">2023-04-29</p>
</section>
<section id="last-presentation-summray" class="slide level2">
<h2>Last Presentation summray :</h2>
<h3 id="voxelnet-architecture" class="anchored">VoxelNet Architecture</h3>
<div class="columns">
<div class="column" style="width:70%;">
<p><img data-src="images/Acrobat_ZOIOLjvhTa.png"></p>
</div><div class="column" style="width:30%;">
<p>The VoxelNet consists of three functional blocks</p>
<ol type="1">
<li>Feature learning network</li>
<li>Convolutional middle layers</li>
<li>Region proposal network</li>
</ol>
</div>
</div>
</section>
<section id="last-presentation-summray-1" class="slide level2">
<h2>Last Presentation summray :</h2>
<h3 id="feature-learning-network" class="anchored">Feature Learning Network</h3>
<div class="columns">
<div class="column" style="width:60%;">
<h3 id="voxel-partition" class="anchored">Voxel Partition</h3>
<ul>
<li>The 3D voxel grid is of size <span class="math inline">\(D'=D/v_D, H'=H/v_H, W'=W/v_W\)</span> where <span class="math inline">\(v_D,v_H,v_W\)</span> defines the voxel size accordingly , where <span class="math inline">\(D, H, W\)</span> are point clouds across <span class="math inline">\(Z, Y, X\)</span> axes respectively.</li>
<li>Point density in LiDAR point clouds is variable, resulting in varying numbers of points within each voxel.</li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="images/Acrobat_ffA1dvD6zy.png"></p>
</div>
</div>
</section>
<section id="last-presentation-summray-2" class="slide level2">
<h2>Last Presentation summray :</h2>
<h3 id="convolutional-middle-layers" class="anchored">Convolutional Middle Layers</h3>
<ul>
<li>The convolutional middle layers aggregate voxel-wise features within a <strong>progressively expanding receptive field, adding more context to the shape description</strong></li>
<li>Depending on the task this layer’ details can vary.</li>
</ul>
<p><br><br> <img data-src="images/chrome_jVqU0WaxpR.png"></p>
</section>
<section id="last-presentation-summray-3" class="slide level2">
<h2>Last Presentation summray :</h2>
<h3 id="region-proposal-network" class="anchored">Region Proposal Network</h3>
<ul>
<li>RPN is combined with the feature learning network and convolutional middle layers to form an <strong>end-to-end trainable pipeline</strong>.<br> <img data-src="images/Acrobat_gayrjAQFrA.png"><br></li>
<li>The first layer of each block downsamples the feature map by half.</li>
<li>The output of each block is upsampled to a fixed size and concatenated to construct a high-resolution feature map.</li>
</ul>
</section>
<section id="last-presentation-summray-4" class="slide level2">
<h2>Last Presentation summray :</h2>
<h3 id="loss-function" class="anchored">Loss Function</h3>
<ul>
<li>Consider ground truth <span class="math inline">\((x_{c}^{g},y_{c}^{g},z_{c}^{g},l^{g},w^{g},h^{g},\theta^{g}),\)</span> where <span class="math inline">\(x_{c}^{g},y_{c}^{g},z_{c}^{g}\)</span> represent the center location, <span class="math inline">\(l^{g},w^{g},h^{g}\)</span> are length, width, height of the box,<span class="math inline">\({\theta}^{g}\)</span> is the yaw rotation.Consider Anchor <span class="math inline">\((x_{c}^{a},y_{c}^{a},z_{c}^{a},l^{a},w^{a},h^{a},\theta^{a})\)</span> A vector <span class="math inline">\(\mathbf{u}^{*}\in\mathbb{R}^{7}\)</span> containing below 7 elements are calculated as below: <span class="math display">\[\begin{align*}
    &amp;\Delta x={\frac{x_{c}^{g}-x_{c}^{a}}{d^{a}}},\Delta y={\frac{y_{c}^{g}-y_{c}^{a}}{d^{a}}},\Delta z={\frac{z_{c}^{g}-z_{c}^{a}}{h^{a}}},\\
    &amp;\Delta l=\log(\frac{l^{g}}{l^{a}}),\Delta w=\log(\frac{w^{g}}{w^{a}}),\Delta h=\log(\frac{h^{g}}{h^{a}}), \tag{1} \\
    &amp;\Delta\theta=\theta^{g}-\theta^{a}
\end{align*}\]</span> Where <span class="math inline">\(\;d^{a}\,=\,\sqrt{(l^{a})^{2}+(w^{a})^{2}}\)</span></li>
</ul>
</section>
<section id="section" class="slide level2">
<h2></h2>
<p>Loss Function cont …</p>
<ul>
<li>Now we find loss as shown below <span class="math display">\[\begin{align*}
   L&amp;=\alpha{\frac{1}{N_{\mathrm{pos}}}}\sum_{i}L_{\mathrm{cls}}(p_{i}^{\mathrm{pos}},1)\\
   &amp;+\beta{\frac{1}{N_{\mathrm{neg}}}}\sum_{j}L_{\mathrm{cls}}(p_{j}^{\mathrm{neg}},0)\\
   &amp;+\frac{1}{N_{\mathrm{pos}}}\sum_{i}L_{\mathrm{reg}}({\bf u}_{i},{\bf u}_{i}^{*}) \tag{2}
\end{align*}\]</span></li>
<li>where <span class="math inline">\(p_{i}^{\mathrm{pos}}\)</span> and <span class="math inline">\(p_{j}^{\mathrm{neg}}\)</span> represent the softmax output for positive anchor <span class="math inline">\(a_{i}^{\mathrm{pos}}\)</span> and negative anchor <span class="math inline">\(a_{j}^{\mathrm{neg}}\)</span> respectively,</li>
<li><span class="math inline">\(\mathbf{u}_{i}\ \in\ \mathbb{R}^{7}\)</span> and <span class="math inline">\(\mathbf{u}_{i}^{*}\ \in\ \mathbb{R}^{7}\)</span> are the regression output and ground truth for positive anchor <span class="math inline">\(a_{i}^{\mathrm{pos}}\)</span></li>
</ul>
</section>
<section id="implementation" class="slide level2">
<h2>Implementation :</h2>
<h3 id="network-details" class="anchored">Network Details</h3>
<ul>
<li><span class="math inline">\(v_{D}\,=\,0.4,v_{H}\,=\,0.2,v_{W}\,=\,0.2\)</span></li>
<li><span class="math inline">\(D^{\prime}\;=\;10,\;H^{\prime}\;=\;400,\;W^{\prime}\;=\;352\)</span></li>
<li>The maximum number of randomly sampled points in each non-empty voxel <span class="math inline">\(T\,=\,35\)</span></li>
<li>For <span class="math inline">\(\mathrm{VFE}-1(7, 32)\)</span> and and <span class="math inline">\(\mathrm{VFE}-2(32, 128)\)</span> was used.</li>
<li>The final <span class="math inline">\(\mathrm{FCN}\)</span> maps <span class="math inline">\(\mathrm{VFE}\)</span> output to <span class="math inline">\(\mathbb{R}^{128}\)</span></li>
<li>Thus the feature learning net generates a sparse tensor of shape <span class="math inline">\(128\times10\times400\times352\)</span></li>
</ul>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<p>Network Details, Car Detection cont …</p>

<img data-src="images/Acrobat_9Ud4aJ0aiX.png" class="r-stretch"></section>
<section id="implementation-1" class="slide level2">
<h2>Implementation :</h2>
<h3 id="data-set-details" class="anchored">Data set details</h3>
<ul>
<li>KITTI 3D object detection dataset is used,which contains 7,481 training images/point clouds and 7,518 test images/point clouds</li>
<li>The data has three categories : Car, Pedestrian, and Cyclist, for each class data is divided in the three difficulty levels : easy, moderate, and hard</li>
</ul>
<div class="columns">
<div class="column" style="width:40%;">
<p>Training Dataset<br> length : 3712</p>
<table>
<thead>
<tr class="header">
<th>category</th>
<th>number</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pedestrian</td>
<td>2207</td>
</tr>
<tr class="even">
<td>Cyclist</td>
<td>734</td>
</tr>
<tr class="odd">
<td>Car</td>
<td>14357</td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:60%;">
<p>Validation Dataset<br> length: 3769</p>
<table>
<thead>
<tr class="header">
<th>category</th>
<th>number</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pedestrian</td>
<td>2280</td>
</tr>
<tr class="even">
<td>Cyclist</td>
<td>893</td>
</tr>
<tr class="odd">
<td>Car</td>
<td>14385</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="implementation-2" class="slide level2">
<h2>Implementation :</h2>
<h3 id="training" class="anchored">Training</h3>
<ul>
<li>Above model was implemented using the below environment:
<ul>
<li>PyTorch: 1.7.0</li>
<li>CUDA Runtime 10.2</li>
<li>Python: 3.7.16</li>
<li>CuDNN 7.6.5</li>
<li>TorchVision: 0.8.1</li>
<li>MMEngine: 0.7.2</li>
<li>MMDetection3D: 1.1.0rc3</li>
</ul></li>
<li>A similar network with different parameters, was used for Pedestrian and Cyclist Detection
<ul>
<li>2 anchors, smaller anchors, small stride to capture fine details etc.</li>
</ul></li>
</ul>
</section>
<section id="implementation-3" class="slide level2">
<h2>Implementation :</h2>
<h3 id="training-1" class="anchored">Training</h3>
<ul>
<li>The training was done with the exact same hyper parameter as suggested by the authors:
<ul>
<li>During training, stochastic gradient descent (SGD) with learning rate 0.01 was used for the first 150 epochs and decreased the learning rate to 0.001 for the last 10 epochs.</li>
</ul></li>
<li>Data Augmentation
<ul>
<li>perturbation independently to each ground truth 3D bounding box together with those LiDAR points within the box.</li>
<li>Global scaling.</li>
</ul></li>
</ul>
</section>
<section id="implementation-evaluation" class="slide level2">
<h2>Implementation : Evaluation</h2>
<ul>
<li>Author follows official KITTI evaluation protocol, which is the most appropriate method to capture object detection performance.</li>
<li>As we can’t find True negative in case of object detection so we do not report confusion matrix.</li>
<li>For the same reason we can’t find ROC curve, Hence for object detection evaluation we go for Precision-Recall curve, the curve doesn’t involve True negative so it is possible to compute.</li>
<li>We first generate prediction using model and find class label then find IOU, precision, recall</li>
<li>Find the area under precision recall curve. which is known as the Average precision.</li>
<li>There are many method to find the area under this PR curve, for eg. AP11, AP40.</li>
</ul>
</section>
<section id="implementation-results" class="slide level2">
<h2>Implementation : Results</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>From Implementation</p>
<table>
<thead>
<tr class="header">
<th>Car</th>
<th>Easy</th>
<th>Moderate</th>
<th>Hard</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BEV</td>
<td>87.50</td>
<td>83.80</td>
<td>77.37</td>
<td></td>
</tr>
<tr class="even">
<td>3D</td>
<td>80.96</td>
<td>64.45</td>
<td>61.75</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Ped</th>
<th>Easy</th>
<th>Moderate</th>
<th>Hard</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BEV</td>
<td>66.94</td>
<td>60.16</td>
<td>57.79</td>
<td></td>
</tr>
<tr class="even">
<td>3D</td>
<td>56.36</td>
<td>54.44</td>
<td>49.56</td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th>Cyc</th>
<th>Easy</th>
<th>Moderate</th>
<th>Hard</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BEV</td>
<td>73.34</td>
<td>51.23</td>
<td>51.24</td>
<td></td>
</tr>
<tr class="even">
<td>3D</td>
<td>66.23</td>
<td>46.32</td>
<td>46.23</td>
<td></td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:50%;">
<p>From Paper</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Car</th>
<th>Easy</th>
<th>Moderate</th>
<th>Hard</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>BEV</td>
<td>89.60</td>
<td>84.81</td>
<td>78.57</td>
</tr>
<tr class="even">
<td></td>
<td>3D</td>
<td>81.97</td>
<td>65.46</td>
<td>62.85</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th>Ped</th>
<th>Easy</th>
<th>Moderate</th>
<th>Hard</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>BEV</td>
<td>65.95</td>
<td>61.05</td>
<td>56.98</td>
</tr>
<tr class="even">
<td></td>
<td>3D</td>
<td>57.86</td>
<td>53.42</td>
<td>48.87</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th>Cyc</th>
<th>Easy</th>
<th>Moderate</th>
<th>Hard</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>BEV</td>
<td>74.41</td>
<td>52.18</td>
<td>50.49</td>
</tr>
<tr class="even">
<td></td>
<td>3D</td>
<td>67.17</td>
<td>47.65</td>
<td>45.11</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="novelty" class="slide level2">
<h2>Novelty</h2>
<p>Following Novelty were proposed:</p>
<ul>
<li>We do not need to predict separately for positive and negative.</li>
<li>VFE can be improved with the help of another encoder ( eg. transformer )</li>
<li>One universal network instead of two.</li>
<li>Extend VoxelNet for joint LiDAR, Radar and image-based end-to-end 3D detection.</li>
<li>Previous time frames can be taken into account improve the detection.</li>
</ul>
<p>Among all these, the below 3 was implemented, others can be implemented</p>
<ul>
<li>We do not need to predict separately for positive and negative.</li>
<li>One universal network instead of two.</li>
<li>VFE can be improved with the help of another encoder ( point pillar )</li>
</ul>
</section>
<section id="novelty-1" class="slide level2">
<h2>1. Novelty</h2>
<ul>
<li>The Original voxel net has two separate head for predicting Negative and Positive class classification score,</li>
<li>It was changed to have just one output for classification head and cross entropy loss was used.</li>
<li>Finally I changed the cross entropy loss to focal loss<a href="#/footnotes" class="footnote-ref" id="fnref1" role="doc-noteref" data-footnote-href="#/fn1" onclick=""><sup>1</sup></a>, While doing hyper parameter tuning, I observed that the cyclist class was not performing well, as we can notice this class has only 734 sample in the training data, which is much lesser compared to other class,</li>
<li>It was found that for gamma = 2.0 and alpha = 0.25 the model performs the best. <span class="math display">\[FL(p_t)=-\alpha(1-p_t)^\gamma\log (p_t)\]</span> Here <span class="math inline">\(p_t\)</span> is the target class, <span class="math inline">\(\gamma=2.0\)</span> and <span class="math inline">\(\alpha=0.25\)</span></li>
</ul>
<aside></aside></section>
<section id="novelty-2" class="slide level2">
<h2>2. Novelty</h2>
<ul>
<li>It was found that instead of training two network one for car, and another for pedestrian and cyclist, it is possible to train just one network if we carefully adjust stride in the network.</li>
<li>Following Point pillars network<a href="#/footnotes" class="footnote-ref" id="fnref2" role="doc-noteref" data-footnote-href="#/fn2" onclick=""><sup>2</sup></a>, I adjusted the stride of the network to 2 for back bone layer, and anchor size as well, and found that the the model was performing good on just one common network architecture.</li>
<li>It can also be noticed that yolo has 1000s of class and just one network for the classes. Yolo does it by careful selection of anchor box.</li>
</ul>
<aside></aside></section>
<section id="novelty-3" class="slide level2">
<h2>3. Novelty</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>For the voxel encoder part we again follow point pillars network</li>
<li>We borrow only encoder form point pillars not the whole network.</li>
<li>point pillars uses SSD as feature extractor we use RPN as suggested by voxelnet.</li>
<li>Point pillar encodes voxel very differently and more efficiently as compared to voxelnet</li>
</ul>
</div><div class="column" style="width:60%;">
<p><img data-src="images/chrome_W2rYqD4tqm.png"></p>
<div style="font-size: 50%;">
<p>Courtesy: <a href="https://becominghuman.ai/pointpillars-3d-point-clouds-bounding-box-detection-and-tracking-pointnet-pointnet-lasernet-67e26116de5a">medium</a></p>
</div>
</div>
</div>
</section>
<section id="implementation-4" class="slide level2">
<h2>Implementation</h2>
<div class="columns">
<div class="column" style="width:70%;">
<p><img data-src="images/Acrobat_8nIjIYkFMb.png"></p>
</div><div class="column" style="width:30%;">
<ul>
<li>consider <span class="math inline">\(l\)</span> a point in the point cloud with coordinates of <span class="math inline">\(x,y,z\)</span> and reflectance <span class="math inline">\(r\)</span>.</li>
</ul>
</div>
</div>
<ul>
<li>Now discretize the point cloud into evenly spaced <span class="math inline">\(x,y\)</span> plane creating a set of pillars <span class="math inline">\(\mathcal P\)</span>, <span class="math inline">\(|\mathcal P|=B\)</span></li>
<li>There is no hyper parameter in <span class="math inline">\(z\)</span> dimension</li>
<li>Now find <span class="math inline">\(x_c, y_c, z_c, x_p,y_p\)</span> where the <span class="math inline">\(c\)</span> subscript denotes distance to the arithmetic mean of all points in the pillar and the <span class="math inline">\(p\)</span> subscript denotes the offset from the pillar <span class="math inline">\(x, y\)</span> center.</li>
<li>Now the lidar point is 9 dimensional <span class="math inline">\(D=9\)</span></li>
</ul>
</section>
<section id="implementation-5" class="slide level2">
<h2>Implementation</h2>
<p>Point pillar network mentioned <span class="math inline">\(D=9\)</span> but in reality while implementing we need to include reflectance as well so it is actually <span class="math inline">\(10\)</span>. - Next, we use a simplified version of PointNet to generate a <span class="math inline">\((C, P,N)\)</span> sized tensor. - This is followed by a max operation over the channels to create an output tensor of size <span class="math inline">\((C, P)\)</span> <img data-src="images/chrome_JcI6AbcymW.png"></p>
</section>
<section id="implementation-6" class="slide level2">
<h2>Implementation</h2>
<ul>
<li><p>The point piller is just a simple version of point net</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>PillarFeatureNet(</span>
<span id="cb1-2"><a href="#cb1-2"></a>  (pfn_layers): ModuleList(</span>
<span id="cb1-3"><a href="#cb1-3"></a>    (<span class="dv">0</span>): PFNLayer(</span>
<span id="cb1-4"><a href="#cb1-4"></a>      (norm): BatchNorm1d(<span class="dv">64</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-5"><a href="#cb1-5"></a>      (linear): Linear(in_features<span class="op">=</span><span class="dv">10</span>, out_features<span class="op">=</span><span class="dv">64</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-6"><a href="#cb1-6"></a>    )</span>
<span id="cb1-7"><a href="#cb1-7"></a>  )</span>
<span id="cb1-8"><a href="#cb1-8"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>After encoding we get 64 dimensional feature which we feed to the back bone, as the encoding shape is different the back bone was modified to accommodate this change.</p></li>
<li><p>Our Back bone has 3 layers same as the voxelnet but we used 2D backbone due the nature of the encoded feature.</p></li>
<li><p>Once encoded, the features are scattered back to the original pillar locations to create a pseudo-image of size <span class="math inline">\((C,H,W)\)</span> where <span class="math inline">\(H\)</span> and <span class="math inline">\(W\)</span> indicate the height and width of the canvas.</p></li>
</ul>
</section>
<section id="implementation-7" class="slide level2">
<h2>Implementation</h2>
<p>Detail of back bone</p>

<img data-src="images/POWERPNT_yjVxjKIFZ4.png" class="r-stretch"></section>
<section id="implementation-8" class="slide level2">
<h2>Implementation</h2>
<ul>
<li>Block 1</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>    (<span class="dv">0</span>): Sequential(</span>
<span id="cb2-2"><a href="#cb2-2"></a>      (<span class="dv">0</span>): Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a>      (<span class="dv">1</span>): BatchNorm2d(<span class="dv">64</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a>      (<span class="dv">2</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-5"><a href="#cb2-5"></a>      (<span class="dv">3</span>): Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-6"><a href="#cb2-6"></a>      (<span class="dv">4</span>): BatchNorm2d(<span class="dv">64</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-7"><a href="#cb2-7"></a>      (<span class="dv">5</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a href="#cb2-8"></a>      (<span class="dv">6</span>): Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-9"><a href="#cb2-9"></a>      (<span class="dv">7</span>): BatchNorm2d(<span class="dv">64</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-10"><a href="#cb2-10"></a>      (<span class="dv">8</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-11"><a href="#cb2-11"></a>      (<span class="dv">9</span>): Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-12"><a href="#cb2-12"></a>      (<span class="dv">10</span>): BatchNorm2d(<span class="dv">64</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-13"><a href="#cb2-13"></a>      (<span class="dv">11</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-14"><a href="#cb2-14"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Block 2</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>    (<span class="dv">1</span>): Sequential(</span>
<span id="cb3-2"><a href="#cb3-2"></a>      (<span class="dv">0</span>): Conv2d(<span class="dv">64</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a>      (<span class="dv">1</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-4"><a href="#cb3-4"></a>      (<span class="dv">2</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-5"><a href="#cb3-5"></a>      (<span class="dv">3</span>): Conv2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-6"><a href="#cb3-6"></a>      (<span class="dv">4</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-7"><a href="#cb3-7"></a>      (<span class="dv">5</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-8"><a href="#cb3-8"></a>      (<span class="dv">6</span>): Conv2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-9"><a href="#cb3-9"></a>      (<span class="dv">7</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-10"><a href="#cb3-10"></a>      (<span class="dv">8</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-11"><a href="#cb3-11"></a>      (<span class="dv">9</span>): Conv2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-12"><a href="#cb3-12"></a>      (<span class="dv">10</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-13"><a href="#cb3-13"></a>      (<span class="dv">11</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-14"><a href="#cb3-14"></a>      (<span class="dv">12</span>): Conv2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-15"><a href="#cb3-15"></a>      (<span class="dv">13</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-16"><a href="#cb3-16"></a>      (<span class="dv">14</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-17"><a href="#cb3-17"></a>      (<span class="dv">15</span>): Conv2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-18"><a href="#cb3-18"></a>      (<span class="dv">16</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-19"><a href="#cb3-19"></a>      (<span class="dv">17</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-20"><a href="#cb3-20"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Block 3</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>    (<span class="dv">2</span>): Sequential(</span>
<span id="cb4-2"><a href="#cb4-2"></a>      (<span class="dv">0</span>): Conv2d(<span class="dv">128</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>      (<span class="dv">1</span>): BatchNorm2d(<span class="dv">256</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-4"><a href="#cb4-4"></a>      (<span class="dv">2</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-5"><a href="#cb4-5"></a>      (<span class="dv">3</span>): Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-6"><a href="#cb4-6"></a>      (<span class="dv">4</span>): BatchNorm2d(<span class="dv">256</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-7"><a href="#cb4-7"></a>      (<span class="dv">5</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-8"><a href="#cb4-8"></a>      (<span class="dv">6</span>): Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-9"><a href="#cb4-9"></a>      (<span class="dv">7</span>): BatchNorm2d(<span class="dv">256</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-10"><a href="#cb4-10"></a>      (<span class="dv">8</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-11"><a href="#cb4-11"></a>      (<span class="dv">9</span>): Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-12"><a href="#cb4-12"></a>      (<span class="dv">10</span>): BatchNorm2d(<span class="dv">256</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-13"><a href="#cb4-13"></a>      (<span class="dv">11</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-14"><a href="#cb4-14"></a>      (<span class="dv">12</span>): Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-15"><a href="#cb4-15"></a>      (<span class="dv">13</span>): BatchNorm2d(<span class="dv">256</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-16"><a href="#cb4-16"></a>      (<span class="dv">14</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-17"><a href="#cb4-17"></a>      (<span class="dv">15</span>): Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), padding<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-18"><a href="#cb4-18"></a>      (<span class="dv">16</span>): BatchNorm2d(<span class="dv">256</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-19"><a href="#cb4-19"></a>      (<span class="dv">17</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-20"><a href="#cb4-20"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="implementation-9" class="slide level2">
<h2>Implementation</h2>
<p>Detail of back bone</p>
<ul>
<li>For our specific implementation the image size at each block was as follows:
<ul>
<li>Block 1 <code>in: [1, 64, 496, 432], out: [1, 64, 248, 216]</code></li>
<li>Block 2 <code>in: [1, 64, 248, 216], out: [1, 128, 124, 108]</code></li>
<li>Block 3 <code>in: [1, 128, 124, 108],out: [1, 256, 62, 54]</code></li>
</ul></li>
<li>All these 3 block are fed to neck. The neck is very similar to Voxel net :</li>
</ul>
</section>
<section id="implementation-10" class="slide level2">
<h2>Implementation</h2>
<ul>
<li>Neck concatenate all the 3 and produced a tensor with shape [1, 384, 248, 216] and this was fed to the loss calculation.</li>
<li>we find focal loss, for class prediction, after class head ( class head similar to voxel net)</li>
<li>we find bounding box loss after the class head.</li>
</ul>
</section>
<section id="implementation-11" class="slide level2">
<h2>Implementation</h2>
<h3 id="neck" class="anchored">Neck</h3>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>    (<span class="dv">0</span>): Sequential(</span>
<span id="cb5-2"><a href="#cb5-2"></a>      (<span class="dv">0</span>): ConvTranspose2d(<span class="dv">64</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), stride<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-3"><a href="#cb5-3"></a>      (<span class="dv">1</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-4"><a href="#cb5-4"></a>      (<span class="dv">2</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-5"><a href="#cb5-5"></a>    )</span>
<span id="cb5-6"><a href="#cb5-6"></a>    (<span class="dv">1</span>): Sequential(</span>
<span id="cb5-7"><a href="#cb5-7"></a>      (<span class="dv">0</span>): ConvTranspose2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), stride<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-8"><a href="#cb5-8"></a>      (<span class="dv">1</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-9"><a href="#cb5-9"></a>      (<span class="dv">2</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-10"><a href="#cb5-10"></a>    )</span>
<span id="cb5-11"><a href="#cb5-11"></a>    (<span class="dv">2</span>): Sequential(</span>
<span id="cb5-12"><a href="#cb5-12"></a>      (<span class="dv">0</span>): ConvTranspose2d(<span class="dv">256</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>), stride<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-13"><a href="#cb5-13"></a>      (<span class="dv">1</span>): BatchNorm2d(<span class="dv">128</span>, eps<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.01</span>, affine<span class="op">=</span><span class="va">True</span>, track_running_stats<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-14"><a href="#cb5-14"></a>      (<span class="dv">2</span>): ReLU(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-15"><a href="#cb5-15"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="experiments" class="slide level2">
<h2>Experiments</h2>

<img data-src="images/Code_mZ4BlvEcw3.png" class="r-stretch"></section>
<section id="experiments-1" class="slide level2">
<h2>Experiments</h2>

<img data-src="images/Code_bzpSd5S747.png" class="r-stretch"></section>
<section id="experiments-2" class="slide level2">
<h2>Experiments</h2>

<img data-src="images/Code_3jguzGHXJl.png" class="r-stretch"></section>
<section id="experiments-3" class="slide level2">
<h2>Experiments</h2>

<img data-src="images/Code_VRuh7ylhGX.png" class="r-stretch"></section>
<section id="experiments-4" class="slide level2">
<h2>Experiments</h2>

<img data-src="images/Code_yVGFxInDz1.png" class="r-stretch"></section>
<section id="results-quantitative" class="slide level2">
<h2>Results : Quantitative</h2>

<img data-src="images/EXCEL_0r5dQBNuZJ.png" class="r-stretch"></section>
<section id="results-qualitative" class="slide level2">
<h2>Results : Qualitative</h2>
<p><img data-src="images/001733.png"> <img data-src="images/007065.png"> <img data-src="images/001666.png"> <img data-src="images/007402.png"> <img data-src="images/002079.png"> <img data-src="images/007067.png"> <img data-src="images/007403.png"> <img data-src="images/001817.png"> <img data-src="images/002058.png"> <img data-src="images/001931.png"> <img data-src="images/002424.png"> <img data-src="images/001774.png"> <img data-src="images/001979.png"> <img data-src="images/001740.png"> <img data-src="images/002035.png"> <img data-src="images/002153.png"> <img data-src="images/007232.png"> <img data-src="images/002232.png"> <img data-src="images/002348.png"> <img data-src="images/002362.png"> <img data-src="images/002418.png"> <img data-src="images/002612.png"> <img data-src="images/003677.png"></p>
</section>
<section id="referenced-papers" class="slide level2">
<h2>Referenced papers</h2>
<ul>
<li><a href="https://arxiv.org/pdf/1904.01649.pdf">MVX-Net: Multimodal VoxelNet for 3D Object Detection</a><a href="#/footnotes" class="footnote-ref" id="fnref3" role="doc-noteref" data-footnote-href="#/fn3" onclick=""><sup>3</sup></a></li>
<li><a href="https://arxiv.org/pdf/2106.01178.pdf">ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View General-Purpose 3D Object Detection</a><a href="#/footnotes" class="footnote-ref" id="fnref4" role="doc-noteref" data-footnote-href="#/fn4" onclick=""><sup>4</sup></a></li>
<li><a href="https://arxiv.org/pdf/1904.01649.pdf">MVX-Net: Multimodal VoxelNet for 3D Object Detection</a><a href="#/footnotes" class="footnote-ref" id="fnref5" role="doc-noteref" data-footnote-href="#/fn5" onclick=""><sup>5</sup></a></li>
<li><a href="https://arxiv.org/pdf/2104.00678.pdf">Group-Free 3D Object Detection via Transformers</a><a href="#/footnotes" class="footnote-ref" id="fnref6" role="doc-noteref" data-footnote-href="#/fn6" onclick=""><sup>6</sup></a></li>
<li><a href="https://arxiv.org/pdf/1910.06528.pdf">End-to-End Multi-View Fusion for 3D Object Detection in LiDAR Point Clouds (Dynamic Voxelization)</a><a href="#/footnotes" class="footnote-ref" id="fnref7" role="doc-noteref" data-footnote-href="#/fn7" onclick=""><sup>7</sup></a></li>
<li><a href="https://arxiv.org/abs/1612.00593">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a><a href="#/footnotes" class="footnote-ref" id="fnref8" role="doc-noteref" data-footnote-href="#/fn8" onclick=""><sup>8</sup></a></li>
<li><a href="https://arxiv.org/abs/1812.05784">PointPillars: Fast Encoders for Object Detection from Point Clouds</a><a href="#/footnotes" class="footnote-ref" id="fnref9" role="doc-noteref" data-footnote-href="#/fn9" onclick=""><sup>9</sup></a></li>
</ul>
<aside></aside></section>
<section id="conclusion" class="slide level2">
<h2>Conclusion</h2>
<ul>
<li>In this work we show that the performance of voxelnet can be improved by designing an improved version of voxel encoder.</li>
<li>The performance of the network highly depends on the input data encoding.</li>
<li>we also show that the one classification head is sufficient, and only one network is sufficient.</li>
</ul>
</section>
<section id="mathcalthanks" class="title-slide slide level1 center">
<h1><span class="math display">\[\mathcal{THANKS!}\]</span></h1>


<img src="images/logo.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>IIT Hyderabad</p>
</div>
</section>

<section id="footnotes" class="footnotes footnotes-end-of-document smaller scrollable" role="doc-endnotes"><h2>Footnotes</h2>

<ol>
<li id="fn1"><p>Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Dollár</p></li>
<li id="fn2"><p>alex, sourabh, holger, lubing, jiong.yang, oscar</p></li>
<li id="fn3"><p>MVX-Net: Multimodal VoxelNet for 3D Object Detection Vishwanath A. Sindagi, Yin Zhou, Oncel Tuzel arXiv:1904.01649 </p></li>
<li id="fn4"><p>ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View General-Purpose 3D Object Detection Danila Rukhovich, Anna Vorontsova, Anton Konushin arXiv:2106.01178</p></li>
<li id="fn5"><p>MVX-Net: Multimodal VoxelNet for 3D Object Detection Vishwanath A. Sindagi, Yin Zhou, Oncel Tuzel arXiv:1904.01649 </p></li>
<li id="fn6"><p>Group-Free 3D Object Detection via Transformers Ze Liu, Zheng Zhang, Yue Cao, Han Hu, Xin Tong arXiv:2104.00678</p></li>
<li id="fn7"><p>End-to-End Multi-View Fusion for 3D Object Detection in LiDAR Point Clouds Yin Zhou, Pei Sun, Yu Zhang, Dragomir Anguelov, Jiyang Gao, Tom Ouyang, James Guo, Jiquan Ngiam, Vijay Vasudevan arXiv:1910.06528</p></li>
<li id="fn8"><p>PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas arXiv:1612.00593</p></li>
<li id="fn9"><p>PointPillars: Fast Encoders for Object Detection from Point Clouds Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, Oscar Beijbom arXiv:1812.05784</p></li>
</ol>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const icon = "";
      const anchorJS = new window.AnchorJS();
      anchorJS.options = {
        placement: 'right',
        icon: icon
      };
      anchorJS.add('.anchored');
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>