{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: Abhishek Kumar Dubey\n",
    "badges: true\n",
    "categories:\n",
    "- Machine Learning\n",
    "date: '2022-10-15'\n",
    "description: Classifier System Design,Introduction to Learning Theory\n",
    "image: CS5590_images/Acrobat_DOQ241iPvG.png\n",
    "title: Machine Learning 7\n",
    "toc: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numeric\n",
    "    - Zero mean, unit variance: $x’= (x-\\mu)/ \\sigma$\n",
    "    - In interval $[0,1]: x'=(x -\\min)/(\\max - \\min)$\n",
    "- Categorical\n",
    "    - Encoded as number in such a way that there is no sense of ordering, for e.g. if there are 3 classes apple, orange and banana, and encoded as $1,2,3$ respectively, it appears as apple comes first than orange, which is not correct. So the correct way to encode is one hot encoding.\n",
    "    - Also here only equality testing is meaningful. \n",
    "- Ordinal\n",
    "    - Encoded as numbers to preserve ordering\n",
    "    - $\\le, \\ge$ operations meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Images\n",
    "\t- Pixel values, Segment and extract features, Handcrafted features: HOG, SIFT,etc\n",
    "\t- Deep learned features!\n",
    "- Text\n",
    "\t- Bag of words, Ngrams\n",
    "\t- Deep learned features!\n",
    "- Speech\n",
    "\t- Mel Frequency Cepstral Coefficients (MFCCs), Other frequency based features\n",
    "\t- Deep learned features!\n",
    "- Time varying sensor Data\n",
    "\t- Statistical and moment based features (mean, variance) etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Structured input/Structured output\n",
    "\t- One fix: Attribute = root-to-leaf paths\n",
    "- Missing data\n",
    "\t- Fix: Fill in the value, Introduce special label, remove instance, remove attribute, Use classifiers that can handle missing values\n",
    "- Outliers\n",
    "\t- Fix: Remove, Threshold, Visualize!\n",
    "- Data assumptions\n",
    "\t- Generated how? Sources?\n",
    "\t- Smooth? Linear? Noise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all classifiers attempt to reduce global quantities such as the error rate, not taking the data distribution into consideration.\n",
    "\n",
    "As a result, examples from the overwhelming class are well classified whereas examples from the minority class tend to be misclassified.\n",
    "\n",
    "- Are all classifiers sensitive to class imbalance?\n",
    "    - Decision Tree:Very sensitive to class imbalances. This is because the algorithm works globally, not paying attention to specific data points.\n",
    "    - Multi Layer perceptrons (MLPs): are less prone to the class imbalance problem. This is because of their flexibility: their solution gets adjusted by each data point in a bottom up manner as well as by the overall data set in a top down manner.\n",
    "    - Support Vector Machines (SVMs) SVMs are even less prone to the class imbalance problem than MLPs because they are only concerned with a few support vectors, the data points located close to the boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collect more data!\n",
    "- Change your performance metric:\n",
    "\t- Confusion Matrix, Precision Recall, F1 score, etc.\n",
    "- Resample dataset\n",
    "- Generate synthetic samples\n",
    "- Try penalized models\n",
    "- Try a different perspective anomaly/change detection\n",
    "<br><br>\n",
    "- At the data Level: Re Sampling\n",
    "\t- Oversampling (Random or Directed)\n",
    "\t- Under-sampling (Random or Directed), (not good for model performance)\n",
    "\t- Active Sampling\n",
    "- At the Algorithmic Level:\n",
    "\t- Adjusting the Costs\n",
    "\t- Adjusting the decision threshold / probabilistic estimate at the tree leaf\n",
    "<br><br>\n",
    "- Under-sampling (random and directed) is not effective and can even hurt performance.\n",
    "- Random oversampling helps quite dramatically. Directed oversampling makes a bit of a difference by helping slightly more.\n",
    "- Cost adjusting is about as effective as Directed oversampling. Generally, however, it is found to be slightly more useful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE = Synthetic Minority Oversampling Technique\n",
    "\n",
    "- For each minority example $k$, compute nearest minority class examples $(i,j,l,n,m)$\n",
    "- Synthetically generate event $k_1$ such that $k_1$ lies between $k$ and $i$\n",
    "- Randomly chose an example out of $5$ closest points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Large Datasets\n",
    "\n",
    "- At large data scales, the performance of different algorithms converge such that performance differences virtually disappear.\n",
    "- Given a large enough data set, the algorithm you'd want to use is the one that is computationally less expensive.\n",
    "- It's only at smaller data scales that the performance differences between algorithms matter.\n",
    "- CPUs vs GPUs\n",
    "\t- Deep learning has greatly benefited from GPUs\n",
    "- Map Reduce/ Hadoop , Apache Spark, Vowpal Wabbit frameworks\n",
    "\t- Many learning algorithms amenable to partitioning of computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Components of generalization error\n",
    "- Bias: how much the average model over all training sets differ from the true model?\n",
    "\t- Error due to inaccurate assumptions/simplifications made by the model\n",
    "- Variance: how much models estimated from different training sets differ from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE in terms of bias and variance<br><br>\n",
    "  $$\\color{blue} \\text{MSE}=\\color{red} \\underbrace{\\text{Bias}^2}_{\\text{error due to incorrect assumption}} + \\color{green} \\underbrace{\\text{Variance}}_{\\text{error due to variance in training}} + \\color{purple} \\underbrace{\\text{Noise}}_{\\text{Unavoidable error}} \\tag{1}$$\n",
    "  <br><br>\n",
    "\n",
    "  Suppose the ultimate true function is $f$, the one which we ideally want to learn. Our target is $t$. Relation between $t$ and $f$ is as follows \n",
    "  $$t=f+\\epsilon$$\n",
    "  where $\\epsilon$ is noise and it's expected value is considered to be zero i.e. $\\mathbf{E}[\\epsilon]=0$\n",
    "  <br>\n",
    "  We consider $y_i$ to be predicted output by a Neural Network then MSE is given as\n",
    "  $$\\mathrm{MSE}=\\frac{1}{N}\\sum_{i=1}^n {\\left(t_i -y_i \\right)}^2$$\n",
    "  Find expectation of MSE\n",
    "  $$\\begin{align*}{}\n",
    "  \\mathit{\\mathbf{E}}\\left\\lbrack \\mathrm{MSE}\\right\\rbrack &=\\mathit{\\mathbf{E}}\\left\\lbrack \\frac{1}{N}\\sum_{i=1}^n {\\left(t_i -y_i \\right)}^2 \\right\\rbrack \\\\\n",
    "  &=\\frac{1}{N}\\sum_{i=1}^n \\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -y_i \\right)}^2 \\right\\rbrack \n",
    "  \\end{align*}$$\n",
    "  Now we examine $\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -y_i \\right)}^2 \\right\\rbrack$\n",
    "  $$\\begin{align*}{}\n",
    "  \\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -y_i \\right)}^2 \\right\\rbrack &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\left(t_i -f_i \\right)+\\left(f_i -y_i \\right)\\right)}^2 \\right\\rbrack \\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -f_i \\right)}^2 +{\\left(f_i -y_i \\right)}^2 -2\\left(t_i -f_i \\right)\\left(f_i -y_i \\right)\\right\\rbrack \\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -f_i \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack 2\\left(t_i -f_i \\right)\\left(f_i -y_i \\right)\\right\\rbrack \\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -f_i \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack -2\\left(\\mathit{\\mathbf{E}}\\left\\lbrack t_i f_i \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack t_i y_i \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack f_i^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack \\right)\\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -f_i \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack -2\\left(f_i^2 -\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack -f_i^2 +\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack \\right)\\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -f_i \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack \n",
    "  \\end{align*}$$\n",
    "  Above we used the fact that\n",
    "    - $\\mathit{\\mathbf{E}}\\left\\lbrack t_i f_i \\right\\rbrack =f_i^2 \\;\\mathrm{Since}\\;f\\;\\mathrm{is}\\;\\mathrm{deterministic}\\;\\mathrm{and}\\;\\mathit{\\mathbf{E}}\\left\\lbrack t_i \\right\\rbrack =f_i$\n",
    "    - $:\\mathit{\\mathbf{E}}\\left\\lbrack f_i^2 \\right\\rbrack =f^2 \\;\\mathrm{Since}\\;f\\;\\mathrm{is}\\;\\mathrm{deterministic}$\n",
    "    - $:\\mathit{\\mathbf{E}}\\left\\lbrack t_i y_i \\right\\rbrack =\\mathit{\\mathbf{E}}\\left\\lbrack \\left(f_i +\\epsilon \\right)y_i \\right\\rbrack =\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack \\epsilon y_i \\right\\rbrack =\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack +0=\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack$, Here $\\mathit{\\mathbf{E}}\\left\\lbrack \\epsilon y_i \\right\\rbrack$ is zero because the noise in the infinite test set over which we take the expectation is probabilistically independent of the NN prediction\n",
    "  \n",
    "  So we got:\n",
    "  $$\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -y_i \\right)}^2 \\right\\rbrack =\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -f_i \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack \\tag{2}$$\n",
    "  _Thus the MSE can be decomposed in expectation into the variance of the noise and the MSE between the true function and the predicted values_\n",
    "\n",
    "  We can apply same trick on last term of equation $(2)$\n",
    "\n",
    "  $$\\begin{align*}{}\n",
    "  \\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)+\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)\\right)}^2 \\right\\rbrack \\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 +{\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)}^2 -2\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)\\right\\rbrack \\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)}^2 \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack 2\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)\\right\\rbrack \\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)}^2 \\right\\rbrack -2\\left(\\mathit{\\mathbf{E}}\\left\\lbrack f_i \\times \\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack f_i y_i \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack \\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\times y_i \\right\\rbrack \\right)\\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)}^2 \\right\\rbrack -2\\left(\\mathit{\\mathbf{E}}\\left\\lbrack f_i \\right\\rbrack \\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -\\mathit{\\mathbf{E}}\\left\\lbrack f_i \\right\\rbrack \\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -{\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 +{\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 \\right)\\\\\n",
    "  &=\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack \\right)}^2 \\right\\rbrack +\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(\\mathit{\\mathbf{E}}\\left\\lbrack y_i \\right\\rbrack -y_i \\right)}^2 \\right\\rbrack \\\\\n",
    "  \\mathit{\\mathbf{E}}\\left\\lbrack {\\left(f_i -y_i \\right)}^2 \\right\\rbrack &={\\mathrm{bias}}^2 +\\mathrm{Var}\\left(y_i \\right)\n",
    "  \\end{align*}$$\n",
    "\n",
    "  Now we can write equation $(2)$ as \n",
    "  $$\\mathit{\\mathbf{E}}\\left\\lbrack {\\left(t_i -y_i \\right)}^2 \\right\\rbrack =\\mathrm{Var}\\left(\\mathrm{Noise}\\right)+{\\mathrm{bias}}^2 +\\mathrm{Var}\\left(y_i \\right)$$\n",
    "  Hence proved!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From equation $(1)$ we can see that when MSE is constant and if we try to reduce the variance Bias has to increase and vice versa.\n",
    "\n",
    "- Models with too few parameters are inaccurate because of a __large bias__ bias (not enough flexibility).\n",
    "- Models with too many parameters are inaccurate because of a __large variance__ (too much sensitivity to the sample).\n",
    "- __Underfitting__: Model is too “simple” to represent all the relevant class characteristics\n",
    "\t- High bias and low variance\n",
    "\t- High training error and high test error\n",
    "- __Overfitting__: Model is too “complex” and fits irrelevant characteristics (noise) in the data\n",
    "\t- Low bias and high variance\n",
    "\t- Low training error and high test error\n",
    "\n",
    ":::{.callout-tip}\n",
    "In case of classification, variance dominates bias. Very roughly, this is because we only need to make a discrete decision\n",
    "rather than get an exact value.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create multiple training set using bootstrap replicates.\n",
    "- Apply learning algorithm on each replicates to obtain hypothesis.\n",
    "- compute predicted value for each hypothesis on the data which did not appear on the bootstrap replicate the hypothesis was trained on.\n",
    "- compute the average prediction \n",
    "- Estimate bias \n",
    "- Estimate variance.\n",
    "- Assume noise is 0\n",
    "    - If we have multiple data points with the same $x$ value, then we can estimate the noise not generally available in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to reduce variance of classifier\n",
    "\t- Choose a simpler classifier\n",
    "\t- Regularize the parameters\n",
    "\t- Get more training data\n",
    "- Training Error and Cross Validation\n",
    "\t- Suppose we use the training error to estimate the difference between the true model prediction and the learned model prediction.\n",
    "\t- The training error is _downward biased_: on average it _underestimates_ the generalization error.\n",
    "\t- Cross validation is nearly unbiased; it _slightly_ _overestimates_ the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN\n",
    "\t- Choose higher $k$\n",
    "- Decision Trees\n",
    "\t- Pruning\n",
    "- Naïve Bayes\n",
    "\t- Parametric models automatically act as regularizers\n",
    "- SVMs\n",
    "\t- Control $c$ value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "- If the wight value is high the model is likely to over fit, so we want weight to be small. Consider a dataset in $2$-D, Hiving large variance across $y$-axis, now consider a model which overfits to these data, to do so $W$ has to be larger because for very small change in $x,\\;y$ will have to change by very high amount (due to such data distribution) which can be achieved only if $W$ is large. It is shown in the below pic.\n",
    "  \n",
    "  ![](CS5590_images/mspaint_AEgund0GVg.png)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick a model\n",
    "- pick a criteria to optimize (aka objective function)\n",
    "- develop a learning algorithm (aka Find $W$ and $b$ that minimizes the loss)\n",
    "- Generally, we don’t want huge weights\n",
    "\t- If weights are large, a small change in a feature can result in a large change in the prediction\n",
    "\t- Also, can give too much weight to any one feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization in Model based ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A regularizer is an additional criteria to the loss function to make sure that we don’t overfit\n",
    "- It’s called a regularizer since it tries to keep the parameters more normal/regular\n",
    "- It is a bias (inductive bias) on the model that forces the learning to prefer certain types (smaller) of weights over others (larger).\n",
    "  $$\\argmin_{w,b} \\sum_{i=1}^n \\mathrm{loss}\\left(y,y^{\\prime } \\right)+\\lambda \\times \\boxed{\\mathrm{regulizer}\\left(w,b\\right)}$$\n",
    "- Type of norm regularizer\n",
    "  - 1-norm ( sum of weights )\n",
    "    $$r(w,b)=\\sum_{w_j} \\left\\lvert w_j \\right\\rvert $$\n",
    "  - 2-norm ( sum of squared weights )\n",
    "    $$r(w,b)=\\sum_{w_j} \\sqrt{\\left\\lvert w_j \\right\\rvert^2} $$    \n",
    "  - $p$-norm ( sum of squared weights )\n",
    "    $$r(w,b)=\\sum_{w_j} \\sqrt[p]{\\left\\lvert w_j \\right\\rvert^p}=\\left\\lVert w\\right\\rVert ^p$$   \n",
    "\n",
    "  :::{.callout-tip}\n",
    "  \n",
    "  - Smaller values of $p, (p < 2)$ encourage sparser vectors<br>\n",
    "  - Larger values of $p$ discourage large weights more.\n",
    "  - All $p$ norms penalize larger weights.\n",
    "  - $p < 2$ tends to create sparse i.e. lots of $0$ weights\n",
    "\n",
    "      ![](CS5590_images/Acrobat_DOQ241iPvG.png)\n",
    "\n",
    "  :::    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1 is popular because it tends to result in sparse solutions (i.e. lots of zero weights)\n",
    "- However, it is not differentiable, so it only works for gradient descent solvers\n",
    "- L2 is also popular because for some loss functions, it can be solved directly (no gradient descent required, though often iterative solvers still)\n",
    "- Lp is less popular since they don’t tend to shrink the weights enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Learning Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimality of Bayes Decision Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Let $X$ be a random variable over a space $\\Omega$\n",
    "- Two category decision problem:<br>\n",
    "  $H_1:X \\in \\omega_1$<br>\n",
    "  $H_2:X \\in \\omega_2$<br>\n",
    "- optimal decision is <br>\n",
    "  - Chose $H_1$ when $p(x \\mid \\omega_1)p(\\omega_1)\\ge p(x \\mid \\omega_2)p(\\omega_2)$\n",
    "  - Chose $H_2$ when $p(x \\mid \\omega_1)p(\\omega_1) < p(x \\mid \\omega_2)p(\\omega_2)$\n",
    "- Consider the partition of reason $\\Omega$ as shown below, $\\mathcal{R}_1,\\mathcal{R}_2,\\Omega_1,\\Omega_2$ are partitions of $\\Omega$. Every thing outside of $\\mathcal{R}_1$ is $\\mathcal{R}_2$ and everything outside of $\\Omega_1$ is $\\Omega_2$<br><br> \n",
    "  ![](CS5590_images/ApplicationFrameHost_r01wS0Cy4S.png)\n",
    "  ![](CS5590_images/ApplicationFrameHost_bShObAKBRQ.png)\n",
    "  ![](CS5590_images/ApplicationFrameHost_lGXEWFz8BX.png)\n",
    "  ![](CS5590_images/ApplicationFrameHost_NxoXTrbauD.png)\n",
    "\n",
    "\n",
    "Consider  arbitrary decision rule:\n",
    "- partition $\\Omega$ into two disjoint regions: $\\mathcal{R}_1$ and $\\mathcal{R}_2$<br>\n",
    "  choose $H_1$ if $X \\in \\mathcal{R}_1$<br>\n",
    "  choose $H_2$ if $X \\in \\mathcal{R}_2$<br>\n",
    "\n",
    "Consider bayesian  decision rule:\n",
    "\n",
    "- partition $\\Omega$ into two disjoint regions: $\\Omega_1$ and $\\Omega_2$<br>\n",
    "  choose $H_1$ if $X \\in \\Omega_1$<br>\n",
    "  choose $H_2$ if $X \\in \\Omega_2$<br>\n",
    "- where <br>\n",
    "  $\\Omega_1 = \\{x \\in \\Omega : p(x \\mid \\omega_1)p(\\omega_1)\\ge p(x \\mid \\omega_2)p(\\omega_2)\\}$<br>\n",
    "  $\\Omega_2 = \\{x \\in \\Omega : p(x \\mid \\omega_1)p(\\omega_1)< p(x \\mid \\omega_2)p(\\omega_2)\\}$\n",
    "\n",
    "Now,<br>\n",
    "For the arbitrary decision rule:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(\\text{error})&=p(X\\in \\mathcal{R}_1,\\omega_2)+p(X\\in \\mathcal{R}_2,\\omega_1) \\\\\n",
    "&= p(X\\in \\mathcal{R}_1\\mid \\omega_2)p(\\omega_2)+p(X\\in \\mathcal{R}_2\\mid \\omega_1)p(\\omega_1) \\\\\n",
    "&= \\int_{\\mathcal{R}_1} p(x\\mid \\omega_2)p(\\omega_2)dx + \\int_{\\mathcal{R}_2} p(x\\mid \\omega_1)p(\\omega_1)dx \\\\\n",
    "\\end{align*}$$\n",
    "\n",
    "Similarly we can write for Bayesian decision rule:\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(\\text{error}_\\text{Bayes})&=p(X\\in \\Omega_1,\\omega_2)+p(X\\in \\Omega_2,\\omega_1) \\\\\n",
    "&= p(X\\in \\Omega_1\\mid \\omega_2)p(\\omega_2)+p(X\\in \\Omega_2\\mid \\omega_1)p(\\omega_1) \\\\\n",
    "&= \\int_{\\Omega_1} p(x\\mid \\omega_2)p(\\omega_2)dx + \\int_{\\Omega_2} p(x\\mid \\omega_1)p(\\omega_1)dx \\\\\n",
    "\\end{align*}$$  \n",
    "\n",
    "Let \n",
    "$$\\Delta(\\text{error})=p(\\text{error})-p(\\text{error}_\\text{Bayes}) \\tag{2}$$\n",
    "<br>\n",
    "If we can prove that $\\Delta(\\text{error})$ is always positive, it means $p(\\text{error}_\\text{Bayes})$ is the optimal error (least error we can get).\n",
    "\n",
    "- With reference of the above figure we can write:<br>\n",
    "  $\\mathcal{R}_1=(\\mathcal{R}_1\\cap \\Omega_1)\\cup (\\mathcal{R}_1 \\cap \\Omega_2)$<br>\n",
    "  $\\mathcal{R}_2=(\\mathcal{R}_2\\cap \\Omega_1)\\cup (\\mathcal{R}_2 \\cap \\Omega_2)$<br>  \n",
    "\n",
    "  $\\Omega_1=( \\Omega_1 \\cap \\mathcal{R}_1)\\cup (\\Omega_1 \\cap \\mathcal{R}_2)$<br>\n",
    "  $\\Omega_2=( \\Omega_2 \\cap \\mathcal{R}_1)\\cup (\\Omega_2 \\cap \\mathcal{R}_2)$<br>  \n",
    "- From above points we can write:<br>\n",
    "  $$\\mathcal{R}_1-\\Omega_1 = (\\mathcal{R}_1 \\cap \\Omega_2)-(\\Omega_1 \\cap \\mathcal{R}_2) \\tag{3}$$\n",
    "  $$\\mathcal{R}_2-\\Omega_2=(\\mathcal{R}_2\\cap \\Omega_1)-( \\Omega_2 \\cap \\mathcal{R}_1) \\tag{4}$$\n",
    "\n",
    "substituting values in   equation $(2)$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\Delta(\\text{error})&=\\int_{\\mathcal{R}_1} p(x\\mid \\omega_2)p(\\omega_2)dx + \\int_{\\mathcal{R}_2} p(x\\mid \\omega_1)p(\\omega_1)dx - \\int_{\\Omega_1} p(x\\mid \\omega_2)p(\\omega_2)dx - \\int_{\\Omega_2} p(x\\mid \\omega_1)p(\\omega_1)dx \\\\\n",
    "&=p(\\omega_2)\\left [\\int_{\\mathcal{R}_1} p(x\\mid \\omega_2)dx- \\int_{\\Omega_1} p(x\\mid \\omega_2)dx \\right ]  + p(\\omega_1)\\left [\\int_{\\mathcal{R}_2} p(x\\mid \\omega_1)dx  - \\int_{\\Omega_2} p(x\\mid \\omega_1)dx \\right] \\\\\n",
    "&=p(\\omega_2)\\left [\\int_{ (\\mathcal{R}_1 \\cap \\Omega_2)} p(x\\mid \\omega_2)dx- \\int_{(\\Omega_1 \\cap \\mathcal{R}_2)} p(x\\mid \\omega_2)dx \\right ]  + p(\\omega_1)\\left [\\int_{(\\mathcal{R}_2\\cap \\Omega_1)} p(x\\mid \\omega_1)dx  - \\int_{( \\Omega_2 \\cap \\mathcal{R}_1)} p(x\\mid \\omega_1)dx \\right] \\;\\;\\text{Using eq } (3) \\text{ and } (4)\\\\\n",
    "&=\\left\\lbrack \\int_{({\\mathcal{R}}_1 \\cap \\Omega_2 )} p(x\\mid \\omega_2 )p(\\omega_2 )dx-\\int_{({\\mathcal{R}}_1 \\cap \\Omega_2 )} p(x\\mid \\omega_1 )p(\\omega_1 )dx\\right\\rbrack +\\left\\lbrack \\int_{(\\Omega_1 \\cap {\\mathcal{R}}_2 )} p(x\\mid \\omega_1 )p(\\omega_1 )dx-\\int_{(\\Omega_1 \\cap {\\mathcal{R}}_2 )} p(x\\mid \\omega_2 )p(\\omega_2 )dx\\right\\rbrack\\\\\n",
    "&=\\underbrace{\\int_{({\\mathcal{R}}_1 \\cap \\Omega_2 )} \\left\\lbrack p(x\\mid \\omega_2 )p(\\omega_2 )-p(x\\mid \\omega_1 )p(\\omega_1 )\\right\\rbrack dx}_{\\ge0}  +  \\underbrace{\\int_{(\\Omega_1 \\cap {\\mathcal{R}}_2 )} \\left\\lbrack p(x\\mid \\omega_1 )p(\\omega_1 )-p(x\\mid \\omega_2 )p(\\omega_2 )\\right\\rbrack dx}_{\\ge0} \\\\\n",
    "\\Delta(\\text{error})&\\ge 0\n",
    "\\end{align*}$$\n",
    "\n",
    "In above two terms are zero due to below reason\n",
    "  $$\\begin{align*}\n",
    "  \\Omega_1 = \\{x \\in \\Omega : p(x \\mid \\omega_1)p(\\omega_1)\\ge p(x \\mid \\omega_2)p(\\omega_2)\\} \\Rightarrow \\int_{(\\Omega_1 \\cap {\\mathcal{R}}_2 )} \\left\\lbrack p(x\\mid \\omega_1 )p(\\omega_1 )-p(x\\mid \\omega_2 )p(\\omega_2 )\\right\\rbrack dx \\ge 0 \\\\\n",
    "  \\Omega_2 = \\{x \\in \\Omega : p(x \\mid \\omega_1)p(\\omega_1)< p(x \\mid \\omega_2)p(\\omega_2)\\} \\Rightarrow \\int_{({\\mathcal{R}}_1 \\cap \\Omega_2 )} \\left\\lbrack p(x\\mid \\omega_2 )p(\\omega_2 )-p(x\\mid \\omega_1 )p(\\omega_1 )\\right\\rbrack dx \\ge 0\n",
    "  \\end{align*}$$\n",
    "\n",
    "  $$\\begin{align*}\n",
    "  &&\\Delta(\\text{error})&\\ge0\\\\\n",
    "  &\\Rightarrow &p(\\text{error})-p(\\text{error}_\\text{Bayes}) &\\ge 0 \\\\\n",
    "  &\\Rightarrow &p(\\text{error}) &\\ge p(\\text{error}_\\text{Bayes})\n",
    "  \\end{align*}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards formalizing ‘learning’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basic process of learning\n",
    "- Observe a phenomenon\n",
    "- Construct a model from observations\n",
    "- Use that model to make decisions/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A statistical machinery for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenomenon of interest:\n",
    "\n",
    "- Input space: $X$; Output space: $Y$\n",
    "- There is an unknown distribution $D$ over $(X,Y)$\n",
    "- The learner observes $m$ examples $(x_1 ,y_1,\\dots, x_m ,y_m )$ drawn from $D$\n",
    "\n",
    "Construct a model:\n",
    "\n",
    "- Let $F$ be a collection of models, where each $f: X \\rightarrow Y$ predicts $y$ given $x$\n",
    "- From $m$ observations, select a model $f_m$  in $F$ which predicts well.\n",
    "- Generalization error of $f$:\n",
    "  $$\\mathrm{err}(f):=\\mathbb{P}_{(x,y)\\sim D}\\left[f(x)\\ne y\\right]$$\n",
    "- We can say that we have learned a phenomenon if \n",
    "  $$\\mathrm{err}(f_m)-\\mathrm{err}(f^*)\\le \\epsilon \\quad f^*:=\\argmin_{f \\in F}\\mathrm{err}(f)$$\n",
    "  for any tolerance level $\\epsilon$ of our choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "$\\tiny  {\\textcolor{#808080}{\\boxed{\\text{Reference: Dr. Vineeth, IIT Hyderabad }}}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
