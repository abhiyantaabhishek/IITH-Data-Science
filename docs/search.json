[
  {
    "objectID": "posts/CS6660/2022-08-06-CS6660-week1.html",
    "href": "posts/CS6660/2022-08-06-CS6660-week1.html",
    "title": "Probability Theory CS6660 week 1",
    "section": "",
    "text": "The union E\\cup F\\; of events E and F always means E OR F , The intersection E\\cap F of events E and F always means E AND F\n\n\n\n\n\n\nTip\n\n\n\nThe union \\bigcup_i E_{i\\;} of events E_{i\\;\\;} always means at least one of the E_i’s, The intersection \\bigcap_i E_i of events E_{i\\;} always means each of the E_i’s\n\n\n\n\n\nThe complement of an event is E^c =\\bar{E} =E^* :=\\Omega -E\n\n\n\n\ncommutativity:  \\begin{array}{l} E\\cup F=F\\cup E\\\\ E\\cap F=F\\cap E \\end{array}\nAssociativity:  \\begin{array}{l} E\\cup \\left(F\\cup G\\right)=\\left(E\\cup F\\right)\\cup G=E\\cup F\\cup G\\\\ E\\cap \\left(F\\cap G\\right)=\\left(E\\cap F\\right)\\cap G=E\\cap F\\cap G \\end{array}\nDistributivity:  \\begin{array}{l} \\left(E\\cup F\\right)\\cap G=\\left(E\\cap G\\right)\\cup \\left(F\\cap G\\right)\\\\ \\left(E\\cap F\\right)\\cup G=\\left(E\\cup G\\right)\\cap \\left(F\\cup G\\right)\\; \\end{array}\nDe Morgan’s Law:  \\begin{array}{l} {\\left(E\\cup F\\right)}^c =E^{c\\;} \\cap F^{c\\;} \\\\ {\\left(E\\cap F\\right)}^{c\\;} =E^c \\cup F^c \\end{array} Similarly \\begin{array}{l} {\\left({\\bigcup_{\\;\\;} }_i E_{i\\;} \\right)}^c ={\\bigcap_{\\;} }_i E_{i\\;}^{c\\;} \\\\ {\\left({\\bigcap_{\\;} }_i E_{i\\;} \\right)}^{c\\;} ={\\bigcup_{\\;} }_i E_i^{c\\;} \\end{array}\n\n\n\n\nThe probability P on a sample space \\Omega assigns numbers to events \\Omega of in such a way that 1. The probability of any event is non-negative : P\\left\\lbrace E\\right\\rbrace \\ge 0 2. The probability if the sample space is one : P\\left\\lbrace \\Omega \\;\\right\\rbrace =1 3. For any finitely or countably infinitely many manually exclusive events E_{1,} E_2 ,\\ldotp \\ldotp \\ldotp , P\\left\\lbrace {\\bigcup_{i\\;} E_{i\\;} }_{\\;} \\right\\rbrace =\\sum_i P\\left\\lbrace E_i \\right\\rbrace \\;\n\n\n\nInclusion-exclusion principle:  - For any events E and F, P\\left\\lbrace E\\cup F\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace +P\\left\\lbrace F\\right\\rbrace -P\\left\\lbrace E\\cap F\\right\\rbrace  - For any events E, F and G: P\\left\\lbrace E\\cup F\\cup G\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace +P\\left\\lbrace F\\right\\rbrace +P\\left\\lbrace G\\right\\rbrace -P\\left\\lbrace E\\cap F\\right\\rbrace -P\\left\\lbrace E\\cap G\\right\\rbrace -P\\left\\lbrace F\\cap G\\right\\rbrace +P\\left\\lbrace E\\cap F\\cap G\\right\\rbrace - Generally: p\\left\\lbrace E_1 \\cup E_2 \\cup E_3 \\cup \\ldotp \\ldotp \\ldotp \\cup E_n \\right\\rbrace =\\sum_{1\\le i\\le n} P\\left\\lbrace E_i \\right\\rbrace -\\sum_{1\\le i_1 \\le i_2 \\le n} P\\left\\lbrace E_{i_1 } \\cap E_{i_2 } \\right\\rbrace +\\sum_{1\\le i_1 \\le i_2 \\le i_{3\\;} \\le n} \\left\\lbrace P\\left\\lbrace E_{i_1 } \\cap E_{i_2 } \\cap E_{i_3 } \\right\\rbrace \\right\\rbrace -\\ldotp \\ldotp \\ldotp \\;+{\\left(-1\\right)}^{n+1} P\\left\\lbrace E_1 \\cap E_2 \\cap E_3 \\right\\rbrace\n\n\n\n\nFor any events E_1 ,E_2 ,\\ldotp \\ldotp \\ldotp E_n P\\left\\lbrace \\bigcup_{i=1}^n E_i \\right\\rbrace \\le \\sum_{i=1}^n P\\left\\lbrace E_i \\right\\rbrace \n\n\n\n\nOut of n people, what is the probability that there are no coinciding birthdays? |\\Omega |={365}^n |E|=365\\ldotp 364\\ldotp \\ldotp \\ldotp \\left(365-n+1\\right)=\\frac{365!}{\\left(365-n\\right)!}  P\\left\\lbrace E\\right\\rbrace =\\frac{|E|}{|\\Omega |}=\\frac{365!}{\\left(365-n\\right)!{365}^n }\n\n\n\nLet F be an Event with P\\left\\lbrace F\\right\\rbrace >0 . then the conditional probability E of given F is defined as: P\\left\\lbrace E|F\\right\\rbrace :=\\frac{P\\left\\lbrace E\\cap F\\right\\rbrace }{P\\left\\lbrace F\\right\\rbrace } \n\n\n\n\n\n\nNote\n\n\n\nConditional Probability can be interpreted as:“In what proportion of case in F will also E occur?” or “How does the probability of both E and F compare to the probability of F only?”\n\n\n conditional probability is a proper probability and it satisfies the axioms:\n\nThe conditional probability of any event is non-negative :P\\left\\lbrace E|F\\right\\rbrace \\ge 0\nThe conditional probability if the sample space is one :P\\left\\lbrace \\Omega |F\\;\\right\\rbrace =1\nFor any finitely or countably infinitely many manually exclusive events E_{1,} E_2 ,\\ldotp \\ldotp \\ldotp , P\\left\\lbrace {\\bigcup_{i\\;} E_{i\\;} |F}_{\\;} \\right\\rbrace =\\sum_i P\\left\\lbrace E_i |F\\right\\rbrace \\;\n\n\n\n\n\nP\\left\\lbrace E^c |F\\right\\rbrace =1-P\\left\\lbrace E|F\\right\\rbrace\nP\\left\\lbrace \\phi |F\\right\\rbrace =0\nP\\left\\lbrace E|F\\right\\rbrace =1-P\\left\\lbrace E^c |F\\right\\rbrace \\le 1\nP\\left\\lbrace \\left(E\\cup G\\right)|F\\right\\rbrace =P\\left\\lbrace E|F\\right\\rbrace +P\\left\\lbrace G|F\\right\\rbrace -P\\left\\lbrace E\\cap F|F\\right\\rbrace proof: \\begin{array}{l} P\\left\\lbrace \\left(E\\cup G\\right)|F\\right\\rbrace =\\frac{P\\left\\lbrace \\left(E\\cup G\\right)\\cap F\\right\\rbrace }{P\\left\\lbrace F\\right\\rbrace }=\\frac{P\\left\\lbrace \\left(E\\cap F\\right)\\cup \\left(G\\cap F\\right)\\right\\rbrace }{P\\left\\lbrace F\\right\\rbrace }\\\\ =\\frac{P\\left(E\\cap F\\right)+P\\left(G\\cap F\\right)-P\\left\\lbrace \\left(E\\cap F\\right)\\cap \\;\\left(G\\cap F\\right)\\right\\rbrace }{P\\left\\lbrace F\\right\\rbrace }=\\frac{P\\left(E\\cap F\\right)+P\\left(G\\cap F\\right)-P\\left\\lbrace E\\cap G\\cap F\\right\\rbrace }{P\\left\\lbrace F\\right\\rbrace }\\\\ =P\\left\\lbrace E|F\\right\\rbrace +P\\left\\lbrace G|F\\right\\rbrace -P\\left\\lbrace E\\cap F|F\\right\\rbrace \\end{array}\nif E\\subseteq G then P\\left\\lbrace \\left(G-E\\right)|F\\right\\rbrace =P\\left\\lbrace G|F\\right\\rbrace -P\\left\\lbrace E|F\\right\\rbrace proof: \\begin{array}{l} P\\left\\lbrace G|F\\right\\rbrace -P\\left\\lbrace E|F\\right\\rbrace =\\frac{\\;P\\left\\lbrace G\\cap F\\right\\rbrace }{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }-\\frac{\\;P\\left\\lbrace E\\cap F\\right\\rbrace }{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }\\\\ =\\frac{P\\left\\lbrace \\left(G\\cap F\\right)-\\left(E\\cap F\\right)\\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }=\\frac{P\\left\\lbrace \\left(G\\cap F\\right)\\cap {\\left(E\\cap F\\right)}^c \\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }\\\\ =\\frac{P\\left\\lbrace \\left(G\\cap F\\right)\\cap {\\left(E^{c\\;} \\cup F^{c\\;} \\right)}^{\\;} \\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }=\\frac{P\\left\\lbrace G\\cap \\left(F\\cap {\\left(E^{c\\;} \\cup F^{c\\;} \\right)}^{\\;} \\right)\\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }\\\\ =\\frac{P\\left\\lbrace G\\cap \\left({\\left({F\\cap \\;E}^{c\\;} \\right)\\cup \\left({F\\cap \\;F}^{c\\;} \\right)}^{\\;} \\right)\\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }=\\frac{P\\left\\lbrace G\\cap {F\\cap \\;E}^{c\\;} \\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }\\\\ =\\frac{P\\left\\lbrace G\\cap {\\;E}^{c\\;} \\cap F\\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }=\\frac{P\\left\\lbrace \\left(G-{\\;E}^{\\;} \\right)\\cap F\\right\\rbrace \\;}{P\\left\\lbrace \\mathrm{F}\\right\\rbrace }=P\\left\\lbrace \\left(G-E\\right)|F\\right\\rbrace \\end{array} if A\\subseteq B then P\\left(B\\right)-P\\left(A\\right)=P\\left(B_{\\;} -A\\right) Here as E\\subseteq G so \\left(E\\cap F\\right)\\subseteq \\left(G\\cap F\\right) so we can write P\\left\\lbrace G\\cap F\\right\\rbrace -\\;P\\left\\lbrace E\\cap F\\right\\rbrace=P\\left\\lbrace \\left(G\\cap F\\right)-\\left(E\\cap F\\right)\\right\\rbrace\n\n\n\nif E\\subseteq G then P\\left\\lbrace E|F\\right\\rbrace \\le P\\left\\lbrace G|F\\right\\rbrace\n\n\n\n\nFor E_1 ,E_2 ,\\ldotp \\ldotp \\ldotp E_n events: P\\left\\lbrace E_1 \\cap E_2 \\cap \\ldotp \\ldotp \\ldotp \\cap E_n \\right\\rbrace =P\\left\\lbrace E_1 \\right\\rbrace \\ldotp P\\left\\lbrace E_2 |E_1 \\right\\rbrace \\ldotp P\\left\\lbrace E_3 |E_1 \\cap E_2 \\right\\rbrace \\ldotp \\ldotp \\ldotp \\ldotp P\\left\\lbrace E_n |E_1 \\cap E_2 \\cap \\ldotp \\ldotp \\ldotp \\cap E_{n-1} \\right\\rbrace\n\n\n\nThis is also known as partition theorem For any events E and F  P\\left\\lbrace E\\right\\rbrace =P\\left\\lbrace E|F\\right\\rbrace \\ldotp P\\left\\lbrace E\\right\\rbrace +P\\left\\lbrace E|F^c \\right\\rbrace \\ldotp P\\left\\lbrace F^c \\right\\rbrace P\\left\\lbrace E\\right\\rbrace =\\sum_i P\\left\\lbrace E|F_i \\right\\rbrace \\ldotp P\\left\\lbrace F_i \\right\\rbrace\n\n\n\nFor any events E and F  P\\left\\lbrace F|E\\right\\rbrace =\\frac{P\\left\\lbrace E|F\\right\\rbrace \\ldotp P\\left\\lbrace F\\right\\rbrace }{P\\left\\lbrace E|F\\right\\rbrace \\ldotp P\\left\\lbrace F\\right\\rbrace +P\\left\\lbrace E|F^c \\right\\rbrace \\ldotp P\\left\\lbrace F^c \\right\\rbrace }\n\n\n\n\n\n\nImportant\n\n\n\nif {\\left\\lbrace F_i \\right\\rbrace }_i is a complete system of events, then P\\left\\lbrace F_i |E\\right\\rbrace =\\frac{\\;P\\left\\lbrace E|F_i \\right\\rbrace \\ldotp P\\left\\lbrace F_i \\right\\rbrace }{\\sum_j \\;P\\left\\lbrace E|F_j \\right\\rbrace \\ldotp P\\left\\lbrace F_j \\right\\rbrace }\n\n\n\n\n\nEvent E and F are independent if P\\left\\lbrace E|F\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace or P\\left\\lbrace E\\cap F\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace \\cdot P\\left\\lbrace F\\right\\rbrace\n\n\n\n\n\n\nImportant\n\n\n\nMutually exclusive events are necessarily also dependent events because one’s existence depends on the other’s non-existence.Dependent events are not necessarily mutually exclusive\n\n\n\n\nIf A and B are independent then A^c and B are also also independent Proof: P\\left(A^c |B\\right)=\\frac{P\\left(A^c \\cap B\\right)}{P\\left(B\\right)}=\\frac{P\\left(B\\right)-P\\left(A^{\\;} \\cap \\;\\;B\\right)}{P\\left(B\\right)}=1-P\\left(A|B\\right)=1-P\\left(A\\right)=P\\left(A^c \\right) \n\nThree events E, F and G are (mutually) independent if - P\\left\\lbrace E\\cap F\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace \\ldotp P\\left\\lbrace F\\right\\rbrace - P\\left\\lbrace E\\cap G\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace \\ldotp P\\left\\lbrace G\\right\\rbrace - P\\left\\lbrace F\\cap G\\right\\rbrace =P\\left\\lbrace F\\right\\rbrace \\ldotp P\\left\\lbrace G\\right\\rbrace - P\\left\\lbrace E\\cap F\\cap G\\right\\rbrace =P\\left\\lbrace E\\right\\rbrace \\ldotp P\\left\\lbrace F\\right\\rbrace \\ldotp P\\left\\lbrace G\\right\\rbrace"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IITH-Data-Science",
    "section": "",
    "text": "Mathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 6\n\n\n\n\n\n\nOct 1, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 5\n\n\n\n\n\n\nSep 24, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFoundations of Machine Learning\n\n\n\n\nFoundations of Machine Learning CS5590 week 5\n\n\n\n\n\n\nSep 24, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 4_2\n\n\n\n\n\n\nSep 17, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 4_1\n\n\n\n\n\n\nSep 17, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFoundations of Machine Learning\n\n\n\n\nFoundations of Machine Learning CS5590 week 4\n\n\n\n\n\n\nSep 10, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 3\n\n\n\n\n\n\nSep 3, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFoundations of Machine Learning\n\n\n\n\nFoundations of Machine Learning CS5590 week 3\n\n\n\n\n\n\nAug 27, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFoundations of Machine Learning\n\n\n\n\nFoundations of Machine Learning CS5590 week 2\n\n\n\n\n\n\nAug 20, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 2\n\n\n\n\n\n\nAug 13, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMathematical Foundations of Data Science\n\n\n\n\nMathematical Foundations of Data Science CS6660 week 1\n\n\n\n\n\n\nAug 6, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFoundations of Machine Learning\n\n\n\n\nFoundations of Machine Learning CS5590 week 1\n\n\n\n\n\n\nAug 6, 2022\n\n\nAbhishek Kumar Dubey\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Download Resume"
  },
  {
    "objectID": "posts/CS6660/2022-08-13-CS6660-week2.html",
    "href": "posts/CS6660/2022-08-13-CS6660-week2.html",
    "title": "Probability Theory CS6660 week 2",
    "section": "",
    "text": "A random variable is a function from a sample space \\Omega to the real numbers \\mathbb{R} A random variable X that can take on finitely or countably infinitely many possible values is called discrete."
  },
  {
    "objectID": "posts/CS6660/2022-08-13-CS6660-week2.html#indicator-random-variable",
    "href": "posts/CS6660/2022-08-13-CS6660-week2.html#indicator-random-variable",
    "title": "Probability Theory CS6660 week 2",
    "section": "Indicator random variable",
    "text": "Indicator random variable\nX=\\left\\lbrace \\begin{array}{ll} 1, & \\mathrm{if}\\;\\mathrm{event}\\;E\\;\\mathrm{occurs}\\\\ 0, & \\mathrm{if}\\;\\mathrm{event}\\;E^c \\;\\mathrm{occurs} \\end{array}\\right. \\mathrm{EX}=0\\cdot p\\left(0\\right)+1\\cdot p\\left(1\\right)=P\\left\\lbrace E\\right\\rbrace \\mathrm{VarX}={\\mathrm{EX}}^2 -{\\left(\\mathrm{EX}\\right)}^2 =\\left(1^2 \\cdot P\\left\\lbrace E\\right\\rbrace +0^2 \\cdot P\\left\\lbrace E^c \\right\\rbrace \\right)-{\\left(P\\left\\lbrace E\\right\\rbrace \\right)}^2 =P\\left\\lbrace E\\right\\rbrace \\cdot \\left(1-P\\left\\lbrace E\\right\\rbrace \\right) \\mathrm{SD}\\;X=\\sqrt{P\\left\\lbrace E\\right\\rbrace \\cdot \\left(1-P\\left\\lbrace E\\right\\rbrace \\right)}"
  },
  {
    "objectID": "posts/CS6660/2022-08-13-CS6660-week2.html#mass-function",
    "href": "posts/CS6660/2022-08-13-CS6660-week2.html#mass-function",
    "title": "Probability Theory CS6660 week 2",
    "section": "Mass function",
    "text": "Mass function\nLet X be a discrete random variable with possible values X_1 ,X_2 ,\\ldotp \\ldotp \\ldotp The probability mass function (pmf), or distribution of a random variable tells us the probabilities of these possible values:  p_X \\left(x_i \\right)=P\\left\\lbrace X=x_i \\right\\rbrace For any discrete random variable X  p\\left(X_i \\right)\\ge 0, and \\sum_i p\\left(X_i \\right)=1"
  },
  {
    "objectID": "posts/CS6660/2022-08-13-CS6660-week2.html#expectation",
    "href": "posts/CS6660/2022-08-13-CS6660-week2.html#expectation",
    "title": "Probability Theory CS6660 week 2",
    "section": "Expectation",
    "text": "Expectation\n\nThe expection, or mean, or expected value of a discrete random variable X is defined as EX=\\sum_i X_i \\cdot p\\left(X_i \\right), provided that this sum exists\nExpected value is not necessarily a possible value\nExpected value can be infinity\nExpected value many not exist\nE\\left(\\mathrm{aX}+b\\right)=a\\cdot \\mathrm{EX}+b\n\nproof: E\\left(\\mathrm{aX}+b\\right)=\\sum_i \\left(\\mathrm{aX}+b\\right)\\cdot p\\left(i\\right)=a\\sum_i X\\cdot p\\left(i\\right)+b\\sum_i p\\left(i\\right)=a\\cdot \\mathrm{EX}+b\n\n{\\mathrm{EX}}^n =E\\left(X^n \\right)\\not= {\\left(\\mathrm{EX}\\right)}^n"
  },
  {
    "objectID": "posts/CS6660/2022-08-13-CS6660-week2.html#variance",
    "href": "posts/CS6660/2022-08-13-CS6660-week2.html#variance",
    "title": "Probability Theory CS6660 week 2",
    "section": "Variance",
    "text": "Variance\nThe variance and the standard deviation of a random variable are defined as \\mathrm{VarX}:={E\\left(X-\\mathrm{EX}\\right)}^2 and \\mathrm{SDX}:=\\sqrt{\\;\\mathrm{VarX}}\n\nProperties of the Variance\n\n\\mathrm{VarX}={\\mathrm{EX}}^2 -{\\left(\\mathrm{EX}\\right)}^2\n\nproof : \\begin{array}{l}  \\mathrm{VarX}:={E\\left(X-\\mathrm{EX}\\right)}^2 =E\\left(\\left(X^2 -2\\cdot X\\cdot \\mathrm{EX}+{\\left(\\mathrm{EX}\\right)}^2 \\right)\\right)\\\\  =E\\left(X^2 \\right)-E\\left(2\\cdot X\\cdot \\mathrm{EX}\\right)+{E\\left({\\left(\\mathrm{EX}\\right)}^2 \\right)}^{\\;} =E\\left(X^2 \\right)-2\\cdot \\mathrm{EX}\\cdot \\mathrm{EX}+{\\left(\\mathrm{EX}\\right)}^2 ={E\\left({\\mathrm{X}}^2 \\right)}^{\\;} -{\\left(\\mathrm{EX}\\right)}^2  \\end{array} Here EX is a constant so can come out of E\\left(2\\cdot X\\cdot \\mathrm{EX}\\right) and it becomes 2\\cdot \\mathrm{EX}\\cdot \\mathrm{EX} also expectation has no effect on {E\\left({\\left(\\mathrm{EX}\\right)}^2 \\right)}^{\\;} for the same reason so it becomes {\\left(\\mathrm{EX}\\right)}^2\ncorollary: for any X,{\\mathrm{EX}}^2 \\ge {\\left(\\mathrm{EX}\\right)}^2 here equality hold only if X=constant a.s. (almost always means probability one)\n\n\\mathrm{Var}\\left(\\mathrm{aX}+b\\right)=a^2 \\cdot \\mathrm{VarX}\n\nproof \\begin{array}{l}  \\mathrm{Var}\\left(\\mathrm{aX}+b\\right)={E\\left(\\mathrm{aX}+b\\right)}^2 -{\\left(E\\left(\\mathrm{aX}+b\\right)\\right)}^2 \\\\  =E\\left(a^2 X^2 +2\\mathrm{abX}+b^2 \\right)-{\\left(\\mathrm{aEX}+b\\right)}^2 \\\\  =a^2 {\\cdot \\mathrm{EX}}^2 +2\\mathrm{ab}\\cdot \\mathrm{EX}+b^2 -a^2 \\cdot {\\left(\\mathrm{EX}\\right)}^2 -2\\mathrm{ab}\\cdot \\mathrm{EX}-b^2 \\\\  =a^2 \\left({\\mathrm{EX}}^2 -{\\left(\\mathrm{EX}\\right)}^2 \\right)=a^2 \\mathrm{VarX}  \\end{array}\n\n\\mathrm{Var}\\left(X+b\\right)=\\mathrm{VarX}=\\mathrm{Var}\\left(-X\\right)\n\n\n\n\n\n\n\nTip\n\n\n\n\\mathrm{VarX}={\\mathrm{EX}}^2 -{\\left(\\mathrm{EX}\\right)}^2\\mathrm{Var}\\left(\\mathrm{aX}+b\\right)=a^2 \\cdot \\mathrm{VarX}\\mathrm{Var}\\left(X+b\\right)=\\mathrm{VarX}=\\mathrm{Var}\\left(-X\\right)"
  },
  {
    "objectID": "posts/CS6660/2022-08-13-CS6660-week2.html#bernoulli-binomial",
    "href": "posts/CS6660/2022-08-13-CS6660-week2.html#bernoulli-binomial",
    "title": "Probability Theory CS6660 week 2",
    "section": "Bernoulli, Binomial",
    "text": "Bernoulli, Binomial\nSuppose that n independent trails are performed, each succeeding with probability p. Let X count the number of success within the n trails. Then X has the Binomial distribution with parameters n and p of, in short X~\\mathrm{Binom}\\left(n,p\\right)\n\nBinomial Function\np\\left(i\\right)=P\\left\\lbrace X=i\\right\\rbrace = {n \\choose i} p^i {\\left(1-p\\right)}^{n-i} ,\\;\\;\\;\\;i=0,1,\\ldotp \\ldotp \\ldotp \\ldotp ,n \\mathrm{EX}=\\mathrm{np}, and \\mathrm{VarX}=\\mathrm{np}\\left(1-p\\right)"
  },
  {
    "objectID": "posts/CS6660/2022-10-01-CS6660-week6.html",
    "href": "posts/CS6660/2022-10-01-CS6660-week6.html",
    "title": "Linear Algebra CS6660 week 6",
    "section": "",
    "text": "How to find if vectors are linearly independent\n\nwrite all the vectors as a column of the the matrix.\nPerform Gaussian elimination until the matrix is in row echelon form\nThe reduced row echelon form is not necessary here.\nThe pivot columns indicate the vectors, which are linearly independent of the vectors on the left, Note that there is an ordering of vectors when the matrix is built.\nThe non pivot columns can be expressed as linear combinations of the pivot columns on their left.\n\nIf we have a matrix B of all independent column vectors b_i, and we multiply it with with j independent column vectors \\lambda_j, \\;\\;j=1,\\dots ,j then we get new set of independent columns vectors x_j, \\;\\;j=1, \\dots ,j\nExample  consider a set of linearly independent vectors b_1,b_2,b_3,b_4 \\in \\mathbb{R}^n \\begin{array}{l l l l l l}  x_1 & = & +b_1 & -2b_2 & + b_3 & -b_4 \\\\  x_2 & = & -4b_1 & -2b_2 & & +4b_4 \\\\  x_3 & = & +2b_1 & +3b_2 & - b_3 & -3b_4 \\\\  x_4 & = & +17b_1 &-102b_2 & + 11b_3 &+b_4 \\\\  \\end{array} Are vectors x_1, \\dots , x_4 \\in \\mathbb{R}^n linearly independent?  As the matrix B has all independent vectors, x_1, \\dots , x_4 will be independent if the vectors formed by coefficients of equation are independent, so we create the coefficient matrix A and perform the gaussian elimination, if we find no non-pivot column we can say x_1, \\dots , x_4 are independent. \\left\\{ \\left[ \\begin{array}{r}1\\\\-2\\\\1\\\\-1\\end{array}\\right],  \\left[ \\begin{array}{r}4\\\\-2\\\\0\\\\4\\end{array}\\right],  \\left[ \\begin{array}{r}2\\\\3\\\\-1\\\\-3\\end{array}\\right],  \\left[ \\begin{array}{r}17\\\\-10\\\\11\\\\1\\end{array}\\right] \\right\\} A = \\left[ \\begin{array}{r r r r }  1 & 4 & 2 & 17 \\\\  -2 & -2 & 3 & -10 \\\\  1 & 0 & -1 & 11 \\\\  -1 & 4 & -3 & 1 \\end{array}\\right] After performing gaussian elimination we get row echelon form  A = \\left[ \\begin{array}{r r r r }  1 & 0 & 0 & -7 \\\\  0 & 1 & 0 & -15 \\\\  0 & 0 & 1 & -18 \\\\  0 & 0 & 0 & 0 \\end{array}\\right] Here we got last column as non pivot column, hence we can say that x_1, \\dots , x_4 are not linearly independent."
  },
  {
    "objectID": "posts/CS6660/2022-10-01-CS6660-week6.html#how-to-find-basis",
    "href": "posts/CS6660/2022-10-01-CS6660-week6.html#how-to-find-basis",
    "title": "Linear Algebra CS6660 week 6",
    "section": "How to find Basis",
    "text": "How to find Basis\n\nA basis of a subspace U = \\text{span}[x_1, \\dots , x_m] \\subseteq \\mathbb{R}^n can be found by executing the following steps:\n\nWrite the spanning vectors as columns of a matrix A\nDetermine the row echelon form of A.\nThe spanning vectors associated with the pivot columns are basis of U.\n\nRemarks : The dimension of a vector space is not necessarily the number of elements in a vector, For instance, the vector space V = \\text{span}\\left[ \\begin{array}{c} 0\\\\1 \\end{array}\\right] is one dimensional, although the basis vector possesses two elements."
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html",
    "title": "Probability Theory CS6660 week 5",
    "section": "",
    "text": "The cumulative distribution function (CDF) of a random variable X is given by  F : \\mathbb{R} \\rightarrow [0,1], \\;\\;\\;\\; x \\rightarrow F(x) = p\\{ X \\le x\\}  Notice that the function is well defined for any random variable. CDF is defined as capital F or sometimes as capital F_X\nRemark: Ther distribution function contains all relevant information about the distribution of our random variable. E.g., for any fixed a<b  \\mathsf{P}\\{a<X\\leq b\\}=\\mathsf{P}\\{X\\leq b\\}-\\mathsf{P}\\{X\\leq a\\}=F(b)-\\mathsf{P}(a) \\mathsf{P}\\{a\\leq X<b\\}=\\mathsf{P}\\{a<X\\leq b\\} -\\mathsf{P}\\{X\\leq b\\} +\\mathsf{P}\\{X\\leq a\\}\nProbability at jump is given by difference between jump points, e.g.   p(X = 2) = \\frac{7}{8} - \\frac{4}{8} =\\frac{3}{8}\nA random variable with piecewise constant distribution function is called discrete. It’s mass function values equal to the jump size in the distribution function.\nProposition  A cumulative distribution function F \n\nIs non-decreasing\nhas limit \\lim_{x \\rightarrow - \\infty} F(X) =0 on the left;\nhas limit \\lim_{x \\rightarrow + \\infty} F(X) =1 on the right;\nIs continuous form the right.\n\nAny function F with the above properties is a cumulative distribution function. There is a sample space and a random variable on it that realizes this distribution function.\nOne Use case of CDF  Suppose we have a tool that can generate only uniform random variable. But we want to generate the data which follows a specific probability distribution f whose CDF is F_X.  To achieve thais we generate random number using uniform distribution in range [0,1], say a. Now look at CDF F_X and find A such that F_X(S)=a  Output A. The output will be distributed as per f"
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#properties-of-the-density-function",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#properties-of-the-density-function",
    "title": "Probability Theory CS6660 week 5",
    "section": "Properties of the density function",
    "text": "Properties of the density function\n\nProposition  For any subset B \\subseteq \\mathbb{R},  \\displaystyle P\\{X \\in B \\} = \\int _B f(x) dx\nCorollary  Indeed, for a continuous random variable X, \\displaystyle P\\{X \\in a \\} = \\int _{\\{a\\}} f(x) dx = 0 \\;\\;\\;\\;\\; \\forall a \\in \\mathbb{R}\nCorollary  For a small \\varepsilon ,  \\displaystyle P\\{X \\in (a,a+\\varepsilon] \\} = \\int _a ^{a + \\varepsilon} f(x) dx \\simeq f(a) \\cdot \\varepsilon\nThere is no particular value that X can take on with positive chance. We can only talk about intervals, and density tells us the likelihood that X is around a point a.\nTo get to the density from an absolutely continuous distribution function,  \\displaystyle f(a) = \\frac{dF(a)}{da}\\;\\;\\;\\; a \\in \\mathbb{R}"
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#expectation-variance-of-uniform",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#expectation-variance-of-uniform",
    "title": "Probability Theory CS6660 week 5",
    "section": "Expectation, Variance of uniform",
    "text": "Expectation, Variance of uniform\n\nFor X \\sim U(\\alpha , \\beta ),  \\boxed{ \\displaystyle EX =\\frac{\\alpha + \\beta }{2}, \\;\\;\\;\\; \\text{Var}X = \\frac{(\\beta - \\alpha)^2}{12}}\nproof of EX  \\displaystyle EX= \\int_{- \\infty}^{\\infty} Xf(X)dX= \\int_{\\alpha}^{\\beta} \\frac{X}{\\beta - \\alpha}dX=\\frac{\\frac{\\beta ^2}{2} - \\frac{\\alpha ^2}{2}}{\\beta - \\alpha}=\\frac{\\alpha + \\beta}{2}\nproof of \\text{Var}X  First find EX^2 \\displaystyle EX^2= \\int_{- \\infty}^{\\infty} X^2f(X)dX= \\int_{\\alpha}^{\\beta} \\frac{X^2}{\\beta - \\alpha}dX=\\frac{\\frac{\\beta ^3}{3} - \\frac{\\alpha ^3}{3}}{3(\\beta - \\alpha)}=\\frac{\\alpha^2+\\alpha \\beta + \\beta^2}{3} \\displaystyle \\text{Var}X = EX^2-(EX)^2 = \\frac{\\alpha^2+\\alpha \\beta + \\beta^2}{3}- \\frac{(\\alpha + \\beta)^2}{4}=\\frac{ \\beta^2 -2\\alpha \\beta + \\alpha^2}{12} \\displaystyle \\text{Var}X = EX^2-(EX)^2 = \\frac{(\\beta-\\alpha )^2}{12}"
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#expectation-variance-of-exponential",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#expectation-variance-of-exponential",
    "title": "Probability Theory CS6660 week 5",
    "section": "Expectation, Variance of Exponential",
    "text": "Expectation, Variance of Exponential\n\nFor X \\sim \\text{Exp}(\\alpha , \\beta ),  \\boxed{ \\displaystyle EX =\\frac{1 }{\\lambda}, \\;\\;\\;\\; \\text{Var}X = \\frac{1}{\\lambda^2}}\nProof of EX  \\displaystyle EX = \\int _0 ^\\infty X \\lambda e^{-\\lambda X}dX Tips integration by parts:  d(uv) = udv+vdu  udv = d(uv) - vdu  \\int udv = uv - \\int vdu  In our case u=X \\;\\;\\; v=-e^{-\\lambda X} \\Rightarrow dv= \\lambda e^{-\\lambda X} \\displaystyle \\int _0 ^\\infty udv = -\\left(X\\cdot e^{-\\lambda X} \\right)\\big| _0 ^\\infty - \\int _0 ^\\infty \\left( -e^{-\\lambda X}\\right) dX \\displaystyle \\int _0 ^\\infty udv = 0- \\frac{e^{-\\lambda X}}{\\lambda} \\Bigg|_0 ^\\infty = \\frac{1}{\\lambda} \\displaystyle EX = \\frac{1}{\\lambda}\nProof of \\text{Var}X First we find E(X^2) \\displaystyle E(X^2) = \\int _0 ^\\infty X^2 \\lambda e^{-\\lambda X}dX In this case u=X^2 \\;\\;\\; v=-e^{-\\lambda X} \\Rightarrow dv= \\lambda e^{-\\lambda X} \\displaystyle \\int _0 ^\\infty udv = -\\left(X^2\\cdot e^{-\\lambda X} \\right)\\big| _0 ^\\infty - 2\\int _0 ^\\infty \\left( -e^{-\\lambda X}\\right) XdX \\displaystyle \\int _0 ^\\infty udv = 0+ 2\\int _0 ^\\infty \\left( e^{-\\lambda X}\\right) XdX \\displaystyle \\int _0 ^\\infty udv = 0+ 2\\frac{1}{\\lambda} \\int _0 ^\\infty \\lambda\\left( e^{-\\lambda X}\\right) XdX \\displaystyle \\int _0 ^\\infty udv = 0+ \\frac{2}{\\lambda}\\underbrace{\\int _0 ^\\infty \\lambda \\left( e^{-\\lambda X}\\right) XdX}_{\\text{This is same as }EX=\\frac{1}{\\lambda}} \\displaystyle \\int _0 ^\\infty udv =\\frac{2}{\\lambda^2}=E(X^2) Now, \\displaystyle \\text{Var}X = E(X^2)-(EX)^2=\\frac{2}{\\lambda^2} - \\left(\\frac{1}{\\lambda}\\right)^2=\\frac{1}{\\lambda^2}\nThinking about X as a waiting time, we now see that \\lambda describes how fast the event we wait for, happens. Therefore \\lambda is also called the rate of the exponential waiting time."
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#the-memoryless-property",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#the-memoryless-property",
    "title": "Probability Theory CS6660 week 5",
    "section": "The memoryless property",
    "text": "The memoryless property\n\nThe exponential is the only continuous non-negative memory less distribution. That is, the only distribution with X \\ge 0 and P\\{X > t + s \\mid X > t\\} = P\\{X > s\\} \\;\\;\\;\\;\\;(\\forall\\; t,\\;\\; s \\ge 0)\n\nSuppose we have waited for time t. The chance of waiting an additional time s is the same as if we would start waiting anew. The distribution does not remember its past.\n\nProof  \\displaystyle P \\left\\{ X > t + s \\mid X>t \\right\\}= \\frac {P\\left\\{ X > t + s \\right\\} \\cap P\\left\\{X>t \\right\\}}{P\\left\\{X>t \\right\\}} if X > t+s then X is also greater than t  \\displaystyle P \\left\\{ X \\ge t + s \\mid X>t \\right\\}= \\frac {P\\left\\{ X \\ge t + s \\right\\} }{P\\left\\{X>t \\right\\}} \\displaystyle P \\left\\{ X \\ge t + s \\mid X>t \\right\\}= \\frac {\\lambda e^{-\\lambda (t+s)} }{\\lambda e^{-\\lambda t}}= e^{-\\lambda s}=P \\left\\{ X>s \\right\\}"
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#symmetry",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#symmetry",
    "title": "Probability Theory CS6660 week 5",
    "section": "Symmetry ",
    "text": "Symmetry \n\nFor any z \\in \\mathbb{R}, \\;\\;\\Phi (-Z ) = 1- \\Phi(Z) Proof:  The standard normal distribution is symmetric: if X \\sim \\mathcal{N}(0,1) and also -X \\sim \\mathcal{N}(0,1), Therefore  \\Phi(-Z)=P\\{ X<-Z\\} = P\\{-X > Z \\} = P\\{ X >Z\\} = 1 - \\Phi(Z)"
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#linear-transformations",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#linear-transformations",
    "title": "Probability Theory CS6660 week 5",
    "section": "Linear transformations",
    "text": "Linear transformations\n\nLet X \\sim \\mathcal{N}(\\mu,\\sigma ^2) and \\alpha , \\beta \\in \\mathbb{R}, Then \\alpha X + \\beta \\sim \\mathcal{N}(\\alpha \\mu + \\beta , \\alpha^2 \\sigma^2) proof: we prove for positive \\alpha, for negative it’s similar. Start with the distribution function Y = \\alpha X +\\beta \\displaystyle F_Y(y)=P\\{ Y <y\\} = P\\{ \\alpha X + \\beta <y\\} = P\\left\\{ X < \\frac{y-\\beta}{\\alpha}\\right\\} \\displaystyle F_Y(y)= P\\left\\{ X < \\frac{y-\\beta}{\\alpha}\\right\\}=F_X\\left(\\frac{y-\\beta}{\\alpha}\\right) \\displaystyle f_y \\left(y\\right)=\\frac{d}{\\textrm{d}y}F_y \\left(y\\right)=\\frac{d}{\\textrm{d}y}F_X \\left(\\frac{y-\\beta }{\\alpha }\\right)=f_X \\left(\\frac{y-\\beta }{\\alpha }\\right)\\frac{1}{\\alpha } \\displaystyle f_y \\left(y\\right)=\\frac{1}{\\sqrt{2\\pi }\\sigma }\\mathrm{Exp}\\left(-\\frac{1}{2}{\\left(\\frac{\\left(\\frac{y-\\beta }{\\alpha }\\right)-\\mu }{\\sigma }\\right)}^2 \\right)\\frac{1}{\\alpha } \\displaystyle f_y \\left(y\\right)=\\frac{1}{\\sqrt{2\\pi }\\sigma }\\mathrm{Exp}\\left(-\\frac{1}{2}{\\left(\\frac{y-\\beta -\\mu \\alpha }{\\sigma \\alpha \\;}\\right)}^2 \\right)\\frac{1}{\\alpha } \\displaystyle f_y \\left(y\\right)=\\frac{1}{\\sqrt{2\\pi }\\sigma }\\mathrm{Exp}\\left(-\\frac{\\left(y-\\beta -\\mu \\alpha \\right)^2 }{2{\\left(\\sigma \\alpha \\right)}^2 \\;}\\right)\\frac{1}{\\alpha } \\displaystyle f_y \\left(y\\right)=\\frac{1}{\\sqrt{2\\pi }\\sigma \\alpha }\\mathrm{Exp}\\left(-\\frac{\\left(y-\\left(\\mu \\alpha +\\beta \\right)\\right)^2 }{2{\\left(\\sigma \\alpha \\right)}^2 \\;}\\right) which implies the statement Y \\sim \\mathcal{N}(\\alpha \\mu + \\beta , \\alpha^2 \\sigma^2)\nIf X \\sim \\mathcal{N}(\\mu, \\sigma ^2), then its standardized version \\frac{X-\\mu}{\\sigma} \\sim \\mathcal{N}(0, 1)  Just use \\alpha = \\frac{1}{\\sigma} and \\beta = -\\frac{\\mu}{\\sigma}\nIf X \\sim \\mathcal{N}(0, 1) is standard normal, then its mean is 0 and its variance is 1. Proof:  That the mean is zero follows from symmetry. For the variance we need to calculate  \\displaystyle EX^{2}=\\int_{-\\infty}^{\\infty}\\frac{x^{2}}{\\sqrt{2\\pi}}\\cdot\\mathrm{e}^{-x^{2}/2}\\,\\mathrm{d}x using intergration by parts. TODO : complete the integration\nIf X \\sim \\mathcal{N}(\\mu,\\sigma ^2) then its mean is \\mu and its variance is \\sigma ^2 Proof:  \\displaystyle \\mathrm{EX}=\\sigma \\cdot E\\left(\\frac{X-\\mu }{\\sigma }\\right)+\\mu =0+\\mu =\\mu  \\displaystyle \\mathrm{VarX}=\\sigma^2 \\mathrm{Var}\\left(\\frac{X-\\mu }{\\sigma }\\right)=\\sigma^2 \\cdot 1=\\sigma^2  X \\sim \\mathcal{N}(\\mu,\\sigma ^2) is also said to be normal distribution with mean \\mu and variance \\sigma^2"
  },
  {
    "objectID": "posts/CS6660/2022-09-24-CS6660-week5.html#why-normal",
    "href": "posts/CS6660/2022-09-24-CS6660-week5.html#why-normal",
    "title": "Probability Theory CS6660 week 5",
    "section": "Why normal",
    "text": "Why normal\n\nTheorem (DeMoivre-Laplace) Fix p and let X_n \\sim \\text{Binom}(n,p). Then for every fixed a<b reals, \\displaystyle \\lim_{n\\to \\infty } P\\left\\lbrace a<\\frac{X_n -\\mathrm{np}}{\\sqrt{\\mathrm{np}\\left(1-\\mathrm{np}\\right)}}\\le b\\right\\rbrace =\\Phi \\left(b\\right)-\\Phi \\left(a\\right)  That is, take X_n \\sim \\text{Binom}(n,p) with large n, fixed (not small) p. then \\frac{X_n -\\mathrm{np}}{\\sqrt{\\mathrm{np}\\left(1-\\mathrm{np}\\right)}} is approximately \\mathcal{N}(0,1) distributed. This will be a special case in the Central Limit Theorem, In fact, Normal will appear in many similar scenarios. Measured quantities, heights or people, length of these lectures, etc."
  },
  {
    "objectID": "posts/CS6660/2022-09-17-CS6660-week4_2.html",
    "href": "posts/CS6660/2022-09-17-CS6660-week4_2.html",
    "title": "Linear Algebra CS6660 week 4_2",
    "section": "",
    "text": "Row-Echelon Form\n\nExample matrix  \\left[ \\begin{array}{r r r r r | r}  \\boxed 1 &-2 & 1 & -1 & 1 & 0 \\\\  0 & 0 & \\boxed 1 & -1 & 3 & -2 \\\\  0 & 0 & 0 & \\boxed 1 & -2 & 1 \\\\  0 & 0 & 0 & 0 & 0 & a+1 \\\\ \\end{array}\\right] \nDefinition  A matrix is in row-echelon form if\n\nAll rows that contains only zeros are at the bottom ot the matrix; correspondingly, all rows that contains at least one nonzero element are on top of rows that contain only zeros.\nLooking at nonzero rows only, the first nonzero number from the left ( also called the pivot or the leading coefficient ) is always strictly to the right of the pivot of the row above it.\n\nBasic and free variables : The variables corresponding to the pivots in the row-echelon form are called basic variables and the other variables are free variables. For example, x_1; x_3; x_4 are basic variables, whereas x_2;x_5 are free variables in above example matrix.\n\n\n\nReduced row Echelon Forms\n\nDefinition  An equation system is in reduced row echelon form ( also: rwo reduced echelon form or row canonical from ) if\n\nIt is in row echelon from.\nEvery pivot is 1.\nThe pivot is the only nonzero entry in its column.\n\n\n\n\nSolving AX=0 (Minus 1 Trick)\n\nExample Matrix  \\left[ \\begin{array}{r r r r r} 1 & 3 & 0 & 0 & 3 \\\\ 0 & 0 & 1 & 0 & 9 \\\\ 0 & 0 & 0 & 1 & -4 \\\\ \\end{array}\\right] For finding the solutions of AX=0 is to look at the non-pivot columns, which we will need to express as a (linear) combination of the pivot columns.  \\left\\{x\\in\\mathbb{R}^{5}:x= \\lambda_{1}{\\left[\\begin{array}{r}3\\\\ -1\\\\ 0\\\\ 0 \\\\0 \\end{array}\\right]} + \\lambda_{2}{\\left[\\begin{array}{r}3\\\\ 0\\\\ 9\\\\ -4 \\\\ -1\\end{array}\\right]},\\;\\;\\ \\lambda_{1},\\lambda_{2}\\in\\mathbb{R}\\right\\}  Insert row in place of free variable ( 2^{\\text{nd}} and 5^{\\text{th}}) with -1 value in place of dependent variable as shown below  \\tilde{A} = \\left[ \\begin{array}{r r r r r} 1 & 3 & 0 & 0 & 3 \\\\ \\boxed 0 & \\boxed { \\mathbf {-1}} & \\boxed 0 & \\boxed 0 & \\boxed 0 \\\\ 0 & 0 & 1 & 0 & 9 \\\\ 0 & 0 & 0 & 1 & -4 \\\\ \\boxed 0 & \\boxed 0 & \\boxed 0 & \\boxed 0 & \\boxed {\\mathbf {-1}} \\\\ \\end{array}\\right] Now the solution for AX=0 can be found by the columns of the the free variable which is 2^{\\text{nd}} and 5^{\\text{th}} column.\n\n\n\nSolving a System of Liner Equation\n\nInversion of matrices which are not square and non-invertible. Ax=b is given as x=A^{-1}b  Ax=b \\Longleftrightarrow A^TAx=A^Tb \\Longleftrightarrow x= (A^TA)^{-1}A^Tb This is called Moore-Penrose pseudo-inverse  The disadvantage of this method is that it requires a lot of computation.\nGaussian Elimination plays a key role in\n\nComputing determinants\nChecking whether a set of vectors is linearly independent\nComputing the rank of the matrix\nDetermining a basis of the vector space.\n\n\n\n\nVector Space\n\nA vector space V is a set that is closed under finite vector addition and scalar multiplication.\n\nwe two vectors are added or multiplied it should stay in the same vector space.\n\nVector space properties  In order for V to be a vector space, the following condition must hold for all elements X,Y,Z \\in V and any scalars r,s \\in F:\n\nCommutativity: X+Y=Y+X\nAssociativity of vector addition: (X+Y)+Z = X+(Y+Z)\nAdditive Identity: For all X, \\;\\; 0+X = X+0=X\nExistence of additive inverse: For any X, there exists a -X such that X+(-X) =0\nAssociativity of vector multiplication: r(sX) = (rs)X\nDistributivity of scalar sums: (r+s)X = rX+sX\nScalar multiplication identity: 1X=X\n\n\n\n\nSubspace\n\nLet V be a vector space, and let W be the subspace of V, if W is a vector space with respect to the operation in V, then W is called a subspace of V\nLet V be the vector space, with operations + and \\;\\cdot \\; and let W be subset of V. Then W is subspace of V if and only if the following conditions hold.\n\nW is non-empty: The zero vector belongs to W.\nClosure under +: If u and v are any vectors in W, the u+v is in W.\nClosure under \\cdot \\;:if v is any vector in W, and c is nay real number, then c \\cdot v si in W.\n\n\n\n\nLiner Combination\n\nConsider a vector space V and a finite number of vectors  x_1, \\dots , x_k \\in V, then every v \\in V of the form  \\displaystyle v=\\lambda_1 x_1+ \\dots + \\lambda_kx_k = \\sum_{i=1}^k \\lambda_i x_i \\in V  \\lambda_1,\\dots , \\lambda_k \\in \\mathbb{R} is a linear combination fo the vectors x_1, \\dots ,x_k \\displaystyle 0=\\sum_{i=1}^k 0 x_i\n\n\n\nLinear Independence\n\nLet us consider a vector space V with k \\in \\mathbb{N} and x_1, \\dots ,x_k \\in V. If there is a non trivial linear combination, such that 0=\\sum_{i=1}^k \\lambda_i x_i with at least one \\lambda _i \\ne 0, the vectors x_1, \\dots , x_k are linearly independent. If only the trivial solution exists, i.e., \\lambda_1 =\\dots=\\lambda_k=0 the vectors x_1, \\dots , x_k are linearly independent.\nIf at-least one of the vectors x_1, \\dots , x_k is 0 then they are linearly dependent. The same holds if two vectors are identical.\nTo find if a system is linear independent, perform gaussian elimination, if there is no non-pivot column then the vectors are independent."
  },
  {
    "objectID": "posts/CS6660/2022-09-17-CS6660-week4_1.html",
    "href": "posts/CS6660/2022-09-17-CS6660-week4_1.html",
    "title": "Probability Theory CS6660 week 4_1",
    "section": "",
    "text": "Definition:  Suppose that n independent trails are performed, each succeeding with probability p. Let X count the number of success within the n trails. Then X has the Binomial distribution with parameters n and p of, in short X~\\mathrm{Binom}\\left(n,p\\right) \\displaystyle p\\left(i\\right)=P\\left\\lbrace X=i\\right\\rbrace = {n \\choose i} \\times p^i \\times {\\left(1-p\\right)}^{n-i} ,\\;\\;\\;\\;i=0,1,\\ldotp \\ldotp \\ldotp \\ldotp ,n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport math\ndef get_Binom(n,p):\n    P=[]\n    for i in range(n+1):\n        P.append( math.comb(n,i) * math.pow(p,i) * math.pow(1-p,n-i))  \n    return P\ndef plot_dist(n,p):\n    P =get_Binom(n=n,p=p)  \n    plt.plot(range(len(P)),P,linestyle='--', marker='o',label=\"p={:.2f}\".format(p))     \n\nplot_dist(n=30,p=0.5)\nplot_dist(n=30,p=0.3)\nplot_dist(n=30,p=0.7)\nplt.title(\"Binomial Distribution\")\nplt.xlabel(\"$i$\")\nplt.ylabel(\"$p(x=i)$\");\nplt.legend();\n\n\n\n\n\n\nBinomial :  \\boxed{\\displaystyle p\\left(i\\right)=P\\left\\lbrace X=i\\right\\rbrace = {n \\choose i} \\times p^i \\times {\\left(1-p\\right)}^{n-i}} \\;\\;\\;\\;i=0,1,\\ldotp \\ldotp \\ldotp \\ldotp ,n  \\displaystyle \\mathrm{EX}=\\mathrm{np}, and \\mathrm{VarX}=\\mathrm{np}\\left(1-p\\right)\nBinomial mass function : \\displaystyle \\sum_{i=0}^n p\\left(i\\right)=\\sum_{i=0}^n P\\left\\lbrace X=i\\right\\rbrace = \\sum_{i=0}^n {n \\choose i} \\times p^i \\times {\\left(1-p\\right)}^{n-i}\nIf we consider just one trail (event), it is called bernoulli, if we consider more trails (events) it is called binomial.\nIn particular, the Bernoulli (\\rho) variable can take on values 0 or 1, with respective probabilities.  \\rho(1) = p and \\rho(0) = 1-p\nRemarks :  \\displaystyle \\sum_{i=0}^n p\\left(i\\right)=\\sum_{i=0}^n P\\left\\lbrace X=i\\right\\rbrace = \\sum_{i=0}^n {n \\choose i} \\times p^i \\times {\\left(1-p\\right)}^{n-i} =[p+(1-p)]^n=1\n\n\n\n\n\\boxed {EX = np}\n\nproof (using trick):  Trick : \\displaystyle i=\\frac{d}{dt}{{t}}^{i}{\\Big|}_{t=1}\\,  \\displaystyle EX =\\sum_{i=0}^n {n \\choose i} \\times i \\times p^i \\times (1-p)^{n-i}  using the trick we get  \\displaystyle EX =\\frac{d}{dt} \\left( \\sum_{i=0}^n {n \\choose i} \\times t^{i} \\times p^i \\times (1-p)^{n-i} \\right) {\\Big|}_{t=1}  \\displaystyle EX =\\frac{d}{dt} \\left( \\sum_{i=0}^n {n \\choose i} \\times {(tp)}^{i} \\times (1-p)^{n-i} \\right) {\\Big|}_{t=1}  \\displaystyle EX =\\frac{d}{dt} \\left( tp+1-p \\right)^n {\\Big|}_{t=1}  \\displaystyle EX =n \\left( tp+1-p \\right)^{n-1}\\cdot p {\\Big|}_{t=1}  \\displaystyle EX =n p  \n\nProof (normal way) :  \\displaystyle EX =\\sum_{i=0}^n {n \\choose i} \\times i \\times p^i \\times (1-p)^{n-i}  we can start the sum from 1 as 0^{\\text{th}} term will become zero  \\displaystyle EX =\\sum_{i=1}^n {n \\choose i} \\times i \\times p^i \\times (1-p)^{n-i}  we know that  \\displaystyle i \\cdot {n \\choose i} = n \\cdot {n-1 \\choose i-1} so we get  \\displaystyle EX =\\sum_{i=1}^n n \\times {n-1 \\choose i-1} \\times p^i \\times (1-p)^{n-i}  \\displaystyle EX =np \\sum_{i=1}^n {n-1 \\choose i-1} \\times p^{i-1} \\times (1-p)^{n-i}  \\displaystyle EX =np \\sum_{i=1}^n {n-1 \\choose i-1} \\times p^{i-1} \\times (1-p)^{(n-1)-(i-1)}  Consider n-1=m and i-1=j, we get  \\displaystyle EX =np \\sum_{j=0}^n {m \\choose j} \\times p^{j} \\times (1-p)^{m-j}  \\displaystyle EX =np \\underbrace{\\sum_{j=0}^n {m \\choose j} \\times p^{j} \\times (1-p)^{m-j}}_{=1}  \\displaystyle EX =np\n\n\n\n\n\n\n\\boxed {\\mathrm{Var} X = np(1-p)} \n\nproof (using trick):  Trick : \\displaystyle i(i-1)=\\frac{d}{dt^2}{{t}}^{i}{\\Big|}_{t=1}\\,  First find E[X(X-1)] \\displaystyle E[X(X-1)] =\\sum_{i=0}^n {n \\choose i} \\times i\\times(i-1) \\times p^i \\times (1-p)^{n-i}  \\displaystyle E[X(X-1)] =\\sum_{i=0}^n {n \\choose i} \\times \\frac{d}{dt^2}{{t}}^{i}{\\Big|}_{t=1} \\times p^i \\times (1-p)^{n-i} \\;\\;\\; We got this using the trick  \\displaystyle E[X(X-1)] =\\frac{d}{dt^2} \\left( \\sum_{i=0}^n {n \\choose i} \\times {{t}}^{i} \\times p^i \\times (1-p)^{n-i} \\right) {\\Big|}_{t=1}  \\displaystyle E[X(X-1)] =\\frac{d}{dt^2} \\left( tp + (1-p) \\right)^n {\\Big|}_{t=1}  \\displaystyle E[X(X-1)] = n(n-1) \\left( tp + 1-p \\right)^{n-2}p\\cdot p {\\Big|}_{t=1}  \\displaystyle E[X(X-1)] = n(n-1)p^2 \nNow,  \\displaystyle \\mathrm{Var} X = E(X^2)-(EX)^2  \\displaystyle \\mathrm{Var} X = \\left( E(X^2)-E(X) \\right)+ \\left(E(X)- (EX)^2 \\right)  \\displaystyle \\mathrm{Var} X = E\\left[X^2-X\\right] + \\left(E(X)- (EX)^2 \\right)  \\displaystyle \\mathrm{Var} X = E\\left[ X(X-1) \\right] + \\left(E(X)- (EX)^2 \\right)  \\displaystyle \\mathrm{Var} X = n(n-1)p^2 + np- (np)^2  \\displaystyle \\mathrm{Var} X = (np)^2-np^2 + np- (np)^2  \\displaystyle \\mathrm{Var} X = -np^2 + np  \\displaystyle \\mathrm{Var} X = np(1-p) \nProof (normal way) :  \\displaystyle \\mathrm{Var} X = E(X^2)-(EX)^2  First we find E(X^2) \\displaystyle E(X^2) =\\sum_{i=0}^n {n \\choose i} \\times i^2 \\times p^i \\times (1-p)^{n-i}  we can start the sum from 1 as 0^{\\text{th}} term will become zero  \\displaystyle E(X^2) =\\sum_{i=1}^n {n \\choose i} \\times i^2 \\times p^i \\times (1-p)^{n-i}  we know that  \\displaystyle i \\cdot i \\cdot {n \\choose i} = n \\cdot i \\cdot{n-1 \\choose i-1}\nso we get  \\displaystyle E(X^2) =\\sum_{i=1}^n n \\cdot i \\cdot{n-1 \\choose i-1} \\times p^i \\times (1-p)^{n-i}  \\displaystyle E(X^2) =n \\cdot p \\sum_{i=1}^n i \\cdot{n-1 \\choose i-1} \\times p^{i-1} \\times (1-p)^{n-i}  \\displaystyle E(X^2) =n \\cdot p \\sum_{i=1}^n i \\cdot{n-1 \\choose i-1} \\times p^{i-1} \\times (1-p)^{(n-1)-(i-1)}  Consider n-1=m and i-1=j, we get  \\displaystyle E(X^2) =n \\cdot p \\sum_{j=0}^n \\left( j+1 \\right) \\cdot{m \\choose j} \\times p^{j} \\times (1-p)^{m-j}  \\displaystyle E(X^2) =n \\cdot p \\underbrace{ \\sum_{j=0}^n j \\cdot{m \\choose j} \\times p^{j} \\times (1-p)^{m-j} }_{\\text{same as we did in expectation,so it's }mp} \\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; +n \\cdot p \\underbrace{\\sum_{j=0}^n {m \\choose j} \\times p^{j} \\times (1-p)^{m-j}}_{\\text{sum of all probability  }=1}  \\displaystyle E(X^2) =n \\cdot p \\times m\\cdot p+n \\cdot p \\displaystyle E(X^2) =n \\cdot p \\times (n-1)\\cdot p+ n \\cdot p \\displaystyle E(X^2) =(np)^2-np^2+np \\displaystyle E(X^2) =(np)^2+np(1-p)\nNow,  \\displaystyle \\mathrm{Var} X = E(X^2) - (EX)^2 \\displaystyle \\mathrm{Var} X = (np)^2+np(1-p) -(np)^2  \\displaystyle \\mathrm{Var} X = np(1-p) \nProof (yet another way, considering events are independent): if Y is just a Bernoulli trail,  Y=\\left\\lbrace \\begin{array}{ll} 1, & \\mathrm{with}\\;\\mathrm{probability}\\;P\\\\ 0, & \\mathrm{with}\\;\\mathrm{probability}\\;1-P \\end{array}\\right.\n\\mathrm{VarY}={\\mathrm{EY}}^2 -{\\left(\\mathrm{EY}\\right)}^2 =\\left(1^2 \\cdot P +0^2 \\cdot (1-P) \\right)-P^2 \\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=P \\cdot \\left(1-P \\right)\nLet X be multiple copies of independent Y If all Y are independent the we can say  \\displaystyle \\mathrm{Var}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathrm{Var}\\left( Y_i \\right) Proof of above statement: Consider only 2 Events Y_1 and Y_2 for simplicity \\displaystyle \\mathrm{Var}(Y_1+Y_2) = E\\left[(Y_1+Y_2)^2 \\right] - \\left(E[Y_1+Y_2]\\right)^2 \\displaystyle = E\\left[Y_1^2 + 2Y_1Y_2 + Y_2^2 \\right] - \\left((EY_1)^2+2(EY_1)(EY_2)+(EY_2)^2\\right) \\displaystyle = E(Y_1^2) + 2E(Y_1Y_2) + E(Y_2^2) -(EY_1)^2-2(EY_1)(EY_2)-(EY_2)^2 \\displaystyle = E(Y_1^2) -(EY_1)^2 + E(Y_2^2)-(EY_2)^2 + 2(EY_1)(EY_2) -2(EY_1)(EY_2) \\displaystyle =\\mathrm{Var}Y_1+\\mathrm{Var}Y_2 In Above proof we used 2E(Y_1Y_2)=2(EY_1)(EY_2) We can do that if the 2 events are independent Proof of the same: \\displaystyle E(Y_1Y_2)= \\sum_{Y_1}\\sum_{Y_2} Y_1 Y_2 P(Y_1=y_1,Y_2=y_2) \\displaystyle E(Y_1Y_2)= \\sum_{Y_1}\\sum_{Y_2} Y_1 Y_2 P(Y_1=y_1)P(Y_2=y_2)\\;\\; as Y_1 and Y2 are independent  \\displaystyle E(Y_1Y_2)= \\sum_{Y_1}Y_1 P(Y_1=y_1) \\sum_{Y_2} Y_2 P(Y_2=y_2)  \\displaystyle E(Y_1Y_2)= E(Y_1) E(Y_2)  Hence we can say, \\displaystyle \\mathrm{Var}X = \\mathrm{Var}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathrm{Var}\\left( Y_i \\right) = np(1-p) \\;\\;\\; Considering all Y_i has variance of p(1-p)"
  },
  {
    "objectID": "posts/CS6660/2022-09-17-CS6660-week4_1.html#expectation-displaystyle-ex-lambda",
    "href": "posts/CS6660/2022-09-17-CS6660-week4_1.html#expectation-displaystyle-ex-lambda",
    "title": "Probability Theory CS6660 week 4_1",
    "section": "Expectation \\displaystyle EX =\\lambda",
    "text": "Expectation \\displaystyle EX =\\lambda\n\n\\boxed {EX = \\lambda} EX = \\displaystyle \\sum_{i=0}^\\infty i \\times \\rho(i) = \\sum_{i=0}^\\infty i \\times \\frac{\\lambda^i}{i!} e^{-\\lambda} EX = \\displaystyle \\sum_{i=1}^\\infty i \\times \\frac{\\lambda^i}{i!} e^{-\\lambda} EX = \\displaystyle \\lambda \\sum_{i=1}^\\infty i \\times \\frac{\\lambda^{i-1}}{i!} e^{-\\lambda} EX = \\displaystyle \\lambda \\sum_{i=1}^\\infty \\frac{\\lambda^{i-1}}{(i-1)!} e^{-\\lambda} consider i-1=j  EX = \\displaystyle \\lambda \\underbrace{\\sum_{j=0}^\\infty \\frac{\\lambda^{j}}{j!} e^{-\\lambda}}_{=1}\nEX = \\displaystyle \\lambda"
  },
  {
    "objectID": "posts/CS6660/2022-09-17-CS6660-week4_1.html#variance-displaystyle-mathrmvar-x-lambda",
    "href": "posts/CS6660/2022-09-17-CS6660-week4_1.html#variance-displaystyle-mathrmvar-x-lambda",
    "title": "Probability Theory CS6660 week 4_1",
    "section": "Variance \\displaystyle \\mathrm{Var} X = \\lambda",
    "text": "Variance \\displaystyle \\mathrm{Var} X = \\lambda\n\n\\boxed {\\mathrm{Var} X = \\lambda}  \\displaystyle E\\left[X(X-1)\\right]=\\sum_{i=0}^n i(i-1)\\rho(i)  \\displaystyle E\\left[X(X-1)\\right]=\\sum_{i=0}^n i(i-1) \\frac{\\lambda ^i}{i!}e^{-\\lambda}  \\displaystyle E\\left[X(X-1)\\right]=\\sum_{i=2}^n i(i-1) \\frac{\\lambda ^i}{i!}e^{-\\lambda}  \\displaystyle E\\left[X(X-1)\\right]=\\sum_{i=2}^n \\frac{\\lambda ^i}{(i-2)!}e^{-\\lambda}  \\displaystyle E\\left[X(X-1)\\right]= \\lambda ^2\\sum_{i=2}^n \\frac{\\lambda ^{i-2}}{(i-2)!}e^{-\\lambda}  Consder i-2=j  \\displaystyle E\\left[X(X-1)\\right]= \\lambda ^2\\underbrace{\\sum_{j=0}^n \\frac{\\lambda ^{j}}{j!}e^{-\\lambda}}_{=1}  \\displaystyle E\\left[X(X-1)\\right]= \\lambda ^2  Now,  \\displaystyle \\mathrm{Var}X = E(X^2)-(EX)^2 \\displaystyle \\mathrm{Var}X = E\\left[X(X-1)\\right] +EX-(EX)^2 \\displaystyle \\mathrm{Var}X = \\lambda^2 +\\lambda-\\lambda^2 \\displaystyle \\mathrm{Var}X = \\lambda"
  },
  {
    "objectID": "posts/CS6660/2022-09-17-CS6660-week4_1.html#expectation-displaystyle-ex-frac1p",
    "href": "posts/CS6660/2022-09-17-CS6660-week4_1.html#expectation-displaystyle-ex-frac1p",
    "title": "Probability Theory CS6660 week 4_1",
    "section": "Expectation \\displaystyle EX =\\frac{1}{p}",
    "text": "Expectation \\displaystyle EX =\\frac{1}{p}\n\n\\boxed {EX = \\frac{1}{p}}\n\nproof (using trick):  Trick : \\displaystyle i=\\frac{d}{dt}{{t}}^{i}{\\Big|}_{t=1}\\,  \\displaystyle EX = \\sum_{i=1}^\\infty i \\cdot (1-p)^{i-1} \\cdot p  \\displaystyle EX = \\sum_{i=0}^\\infty \\frac{d}{dt}{t}^{i}{\\Big|}_{t=1} (1-p)^{i-1} \\cdot p  \\displaystyle EX = \\frac{d}{dt} \\left( \\sum_{i=0}^\\infty {t}^{i} (1-p)^{i-1} \\cdot p \\right) {\\Bigg|}_{t=1} \\displaystyle EX = \\frac{d}{dt} \\left( \\frac{p}{1-p}\\sum_{i=0}^\\infty {t}^{i} (1-p)^{i} \\right) {\\Bigg|}_{t=1} \\displaystyle EX = \\frac{p}{1-p} \\cdot \\frac{d}{dt} \\left( \\frac{1}{1-t(1-p)} \\right) {\\Bigg|}_{t=1} \\displaystyle EX = \\frac{p}{1-p} \\cdot \\left( \\frac{1-p}{\\left(1-t(1-p)\\right)^2} \\right) {\\Bigg|}_{t=1} \\displaystyle EX = \\frac{1}{p}\nProof (normal way): \\displaystyle EX = \\sum_{i=1}^\\infty i \\cdot (1-p)^{i-1} \\cdot p \n\\begin{align*}{}\nEX &=  p + 2 \\cdot (1-p)\\cdot p + 3 \\cdot (1-p)^2 \\cdot p+\\cdots  &  \\qquad (1) \\\\\nEX(1-p) &= \\qquad\\;\\;\\; (1-p)\\cdot p + 2 \\cdot (1-p)^2\\cdot p + 3 \\cdot (1-p)^3 \\cdot p +\\cdots & \\qquad (2)\n\\end{align*}\nSubtracting equation (1) from (2) we get  \\displaystyle p \\cdot EX = p + (1-p)\\cdot p + (1-p)^2 \\cdot p +\\cdots \\displaystyle EX = 1 + (1-p) + (1-p)^2 +\\cdots \\displaystyle EX = \\frac{1}{1-(1-p)} \\displaystyle EX = \\frac{1}{p}"
  },
  {
    "objectID": "posts/CS6660/2022-09-17-CS6660-week4_1.html#variance-displaystyle-mathrmvar-x-frac1-pp2",
    "href": "posts/CS6660/2022-09-17-CS6660-week4_1.html#variance-displaystyle-mathrmvar-x-frac1-pp2",
    "title": "Probability Theory CS6660 week 4_1",
    "section": "Variance \\displaystyle \\mathrm{Var} X = \\frac{1-p}{p^2}",
    "text": "Variance \\displaystyle \\mathrm{Var} X = \\frac{1-p}{p^2}\n\n\\boxed {\\mathrm{Var} X = \\frac{1-p}{p^2}} \n\nProof (using trick); Trick : \\displaystyle i(i-1)=\\frac{d}{dt^2}{{t}}^{i}{\\Big|}_{t=1}\\,  First find E[X(X-1)] \\displaystyle E[X(X-1)] =\\sum_{i=1}^\\infty i\\times(i-1) \\times (1-p)^{i-1} \\times p \n\\displaystyle E[X(X-1)] =\\sum_{i=1}^\\infty \\frac{d}{dt^2}{t}^{i}{\\Big|}_{t=1} \\times (1-p)^{i-1} \\times p \n\\displaystyle E[X(X-1)] =p \\frac{d}{dt^2} \\left( \\sum_{i=1}^\\infty{t}^{i}(1-p)^{i-1} \\right) {\\Bigg|}_{t=1} \n\\displaystyle E[X(X-1)] = \\frac{p}{1-p} \\cdot \\frac{d}{dt^2} \\left( \\sum_{i=1}^\\infty{t}^{i}(1-p)^{i} \\right) {\\Bigg|}_{t=1} \n\\displaystyle E[X(X-1)] = \\frac{p}{1-p} \\cdot \\frac{d}{dt^2} \\left( \\frac{1}{1-t(1-p)} \\right) {\\Bigg|}_{t=1}  \\displaystyle E[X(X-1)] = \\frac{p}{1-p} \\cdot \\left( \\frac{2(1-p)(1-p)}{(\\left( 1-t(1-p) \\right)^3 } \\right) {\\Bigg|}_{t=1}  \\displaystyle E[X(X-1)] = \\frac{p}{1-p} \\cdot \\left( \\frac{2(1-p)(1-p)}{p^3 } \\right)  \\displaystyle E[X(X-1)] = \\left( \\frac{2(1-p)}{p^2 } \\right)  Now,  \\displaystyle \\mathrm{Var}X = E(X^2)-(EX)^2 \\displaystyle \\mathrm{Var}X = E\\left[X(X-1)\\right] +EX-(EX)^2\n\\displaystyle \\mathrm{Var}X = \\left( \\frac{2(1-p)}{p^2 } \\right) + \\frac{1}{p} -\\left( \\frac{1}{p} \\right)^2\n\\displaystyle \\mathrm{Var}X = \\left( \\frac{2-2p}{p^2 } \\right) + \\frac{1}{p} -\\left( \\frac{1}{p} \\right)^2 \\displaystyle \\mathrm{Var}X = \\frac{2-2p+p-1}{p^2} \\displaystyle \\mathrm{Var}X = \\frac{1-p}{p^2}\nproof (normal way): we first solve for E(X^2) \\displaystyle E(X^2) = \\left( \\sum_{i=1}^\\infty i^2 \\times (1-p)^{i-1} \\times p \\right) \n\\begin{align*}{}\nE(X^2) &= p + 4 \\cdot (1-p) \\cdot p + 9 \\cdot (1-p)^2 \\cdot p + \\cdots  &  \\qquad (3) \\\\\n(1-p) E(X^2) &= \\qquad\\;\\;\\; \\;(1-p) \\cdot p + 4 \\cdot (1-p)^2 \\cdot p + 9 \\cdot (1-p)^3 \\cdot p + \\cdots  & \\qquad (4)\n\\end{align*}  subtracting eqution (4) from equation (3) \n\\displaystyle E(X^2) = p+3 \\cdot (1-p) + 5 \\cdot (1-p)^2 + 7 \\cdot (1-p)^3 + \\cdots This is AGP, the sum is given by s_{\\infty}=\\frac{a}{1-r}+\\frac{dr}{(1-r)^2}, \\;\\;\\;\\; for r<1 In our case r=(1-p),\\;a=1,\\;d=2\\; so we get,  \\displaystyle E(X^2) =\\frac{1}{1-(1-p)}+\\frac{2\\cdot (1-p)}{(1-(1-p))^2} \\displaystyle E(X^2) =\\frac{1}{p}+\\frac{2-2p}{p^2} \\displaystyle E(X^2) =\\frac{p+2-2p}{p^2} \\displaystyle E(X^2) =\\frac{2-p}{p^2} \\displaystyle \\mathrm{Var}X = E(X^2) - (EX)^2  \\displaystyle \\mathrm{Var}X = \\frac{2-p}{p^2} - \\left(\\frac{1}{p}\\right)^2  \\displaystyle \\mathrm{Var}X = \\frac{1-p}{p^2}"
  },
  {
    "objectID": "posts/CS6660/2022-09-03-CS6660-week3.html",
    "href": "posts/CS6660/2022-09-03-CS6660-week3.html",
    "title": "Linear Algebra CS6660 week 3",
    "section": "",
    "text": "Let us see some Systems of linear equations\n\nA company produce products N_1, \\dots ,N_n for which resources R_1, \\dots ,R_m are required. To produce a unit of porduct N_j, a_{ij} units of resources R_i are needed, where i=1,\\dots ,m and j=1, \\dots ,n.  The objective is to find an optimal production plan, i.e., a plan of how many units x_j of product N_j should be produced if a total of b_i units of resource R_i are available and (ideally) no resources are left over. write system of equation of the same \\left\\lbrace \\begin{array}{c}\n  a_{11}x_1 + \\dots +a_{1n}x_n =b_1\\\\\n  \\vdots \\\\\n  a_{m1}x_1+\\dots +a_{mn}x_n=b_n\n  \\end{array}\\right.\nJohn received an inheritance of \\$12000 that he divided in three parts and invested in three ways: in a money market fund paying 3\\% annual interest; in municipal bonds paying 4\\% of annual interest; and in mutual fund paying 7\\% of interest, john invested \\$4,000 more in mutual funds than in municipal bonds. He earned \\$670 in interest the first year.How much did john invest in each type of found \\left\\lbrace \\begin{array}{c}\n  x+y+z=12000\\\\\n  0.03x+0.04y+0.07z=670 \\\\\n  -x+z=4000\n  \\end{array}\\right.\\\\\n   \nsolution of above question: x=3500,y=1000,z=7500\n\n\n\n\nIf there are more variables than equations than there might be infinitely many solutions.\nIf AX=b has infinitely many solutions then to find other solutions we find Y such that AY=b, then we can write A(X+Y)=b as A(X+Y)=AX+AY=AX because AY=0 here, X+Y is another solution here. If AX=b and AY=0 then A(X+Y)=b\nParticular and general solutions\n\n1. Find a particular solution to AX=b\n2. Find all the solutions to AX=0\n3. Combine the solution from step 1 and 2 to get the general solution\n\nFor Example, consider  {\\left[\\begin{array}{l l l}{1}&{0}&{8}&{-4}\\\\ {0}&{1}&{2}&{12}\\end{array}\\right]} {\\left[\\begin{array}{l}{x_1}\\\\ {x_2}\\end{array}\\right]}={\\left[\\begin{array}{l}{42}\\\\ {8}\\end{array}\\right]} solution for AX=b (particular solution)  {\\left[\\begin{array}{l l l}{1}&{0}&{8}&{-4}\\\\ {0}&{1}&{2}&{12}\\end{array}\\right]} {\\left[\\begin{array}{l}{x_1}\\\\ {x_2}\\end{array}\\right]}={\\left[\\begin{array}{l}{48}\\\\ {8}\\end{array}\\right]} is given by  {\\left[\\begin{array}{l}{x_1}\\\\ {x_2}\\end{array}\\right]}={\\left[\\begin{array}{l}{42}\\\\ {8}\\end{array}\\right]} Now we find solution for AX=0 (general solution ) {\\left[\\begin{array}{l l l}{1}&{0}&{8}&{-4}\\\\ {0}&{1}&{2}&{12}\\end{array}\\right]} {\\left[\\begin{array}{l}{x_1}\\\\ {x_2}\\end{array}\\right]}={\\left[\\begin{array}{l}{0}\\\\ {0}\\end{array}\\right]} We can find that there are two vectors which satisfy it  {\\left[\\begin{array}{l}{x_1}\\\\ {x_2}\\\\ {x_3}\\\\ {x_4} \\end{array}\\right]}={\\left[\\begin{array}{l}{8}\\\\ {2}\\\\ {-1}\\\\ {0}\\end{array}\\right]} {\\left[\\begin{array}{l}{x_1}\\\\ {x_2}\\\\ {x_3}\\\\ {x_4} \\end{array}\\right]}={\\left[\\begin{array}{l}{-4}\\\\ {12}\\\\ {0}\\\\ {-1}\\end{array}\\right]} We can represent the final solution by combining particular and general solution \\left\\{x\\in\\mathbb{R}^{4}:x= {\\left[\\begin{array}{r}{42}\\\\ {8}\\\\ {0}\\\\ {0} \\end{array}\\right]} + \\lambda_{1}{\\left[\\begin{array}{r}{8}\\\\ {2}\\\\ {-1}\\\\ {0} \\end{array}\\right]} + \\lambda_{2}{\\left[\\begin{array}{r}{-4}\\\\ {12}\\\\ {0}\\\\ {-1} \\end{array}\\right]},\\;\\;\\ \\lambda_{1},\\lambda_{2}\\in\\mathbb{R}\\right\\}"
  },
  {
    "objectID": "posts/CS5590/2022-08-06-CS5590-week1.html",
    "href": "posts/CS5590/2022-08-06-CS5590-week1.html",
    "title": "Machine Learning Introduction CS5590 week 1",
    "section": "",
    "text": "Supervised Learning\n\nclassification, regression\n\nUnsupervised learning\nOther settings of ML\n\nReinforcement learning\nSemi-supervised learning\nActive learning,Transfer learning,Structured learning\n\nDimensionality Reduction (unsupervised Learning)\n\nLarge sample size is required for high dimensional data\nQuery accuracy and efficiency degrade rapidly as the dimension increases\nstrategies:\n\nFeature reduction, Feature selection, Manifold learning, Kernel learning"
  },
  {
    "objectID": "posts/CS5590/2022-08-06-CS5590-week1.html#iid-assumption",
    "href": "posts/CS5590/2022-08-06-CS5590-week1.html#iid-assumption",
    "title": "Machine Learning Introduction CS5590 week 1",
    "section": "IID Assumption",
    "text": "IID Assumption\n\nIdentically independently distributed : This is the assumption that the training data and testing data comes from the same distribution"
  },
  {
    "objectID": "posts/CS5590/2022-08-06-CS5590-week1.html#types-of-models",
    "href": "posts/CS5590/2022-08-06-CS5590-week1.html#types-of-models",
    "title": "Machine Learning Introduction CS5590 week 1",
    "section": "Types of Models",
    "text": "Types of Models\n\nInduction : Model Learns by Induction, ( creating it’s own rules for example, if we do extensive research while buying mobile, we create set rules, it is called induction).\nTransductions: Model learns from references ( for example, if we ask our friends about mobile and we buy according to their suggestion, it is called Transduction).\nOnline : data could be a stream, data keeps coming over time.\nOffline: data is already acquired and trained offline.\nGenerative: Learns the distribution, the model learns joint probability distribution.\nDiscriminative:Learns to discriminate without learning distribution.\nParametric : The model have parameters like \\mu and \\sigma\nNon parametric: The model doesn’t have parameters, as in K nearest neighbor (KNN)"
  },
  {
    "objectID": "posts/CS5590/2022-08-06-CS5590-week1.html#classifier-evaluation",
    "href": "posts/CS5590/2022-08-06-CS5590-week1.html#classifier-evaluation",
    "title": "Machine Learning Introduction CS5590 week 1",
    "section": "Classifier evaluation",
    "text": "Classifier evaluation\n\n\nTraining Error\n\nNot very useful\nRelatively easy to obtain low error\nE_{\\mathrm{train}} =\\frac{1}{n}\\sum_{i=1}^n \\mathrm{error}\\left(f_D \\left(X_i \\right),y_i \\right)\n\nGeneralization Error\n\nMeasure of how well do we do on unseen data\nE_{\\mathrm{gen}} =\\int \\mathrm{error}\\left(f_D \\left(X\\right),y\\right)p\\left(y,X\\right)\\mathrm{dX}"
  },
  {
    "objectID": "posts/CS5590/2022-08-06-CS5590-week1.html#stratified-sampling",
    "href": "posts/CS5590/2022-08-06-CS5590-week1.html#stratified-sampling",
    "title": "Machine Learning Introduction CS5590 week 1",
    "section": "Stratified sampling",
    "text": "Stratified sampling\n\nFirst stratify instances by class, then randomly select instances from each class proportionally\nIt ensures that the proportion of each class remains same in training and validation set."
  },
  {
    "objectID": "posts/CS5590/2022-08-06-CS5590-week1.html#model-selection",
    "href": "posts/CS5590/2022-08-06-CS5590-week1.html#model-selection",
    "title": "Machine Learning Introduction CS5590 week 1",
    "section": "Model Selection",
    "text": "Model Selection\n\nRe-Substitution : not useful as it suggests to re- substitute the train data for validation as well\nK - Fold cross-validation : Divide the data in K fold using stratified sampling, and the select some set for training and some for validation in each iteration.\nLeave-one-out\n\nN-fold cross-validation"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "",
    "text": "Classification\n\nIt is a measure of being right/wrong,0-1, eg: hinge loss, cross entropy loss\n\nRegression loss\n\nIt is a measure if how close we are to target, eg: MEA, MES\n\nRanking/search\n\nIt is a measure of top K search\n\nClustering\n\nHow well we have described the data ( not straight forward)"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#is-accuracy-adequate",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#is-accuracy-adequate",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Is accuracy adequate",
    "text": "Is accuracy adequate\nAccuracy may not not be useful in cases where: - There is a large class skew. - There are differential misclassification cost, say getting a positive wrong costs more than getting a negative wrong. - we are most interested in a subset of high confidence predictions."
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#classification-error",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#classification-error",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Classification Error",
    "text": "Classification Error\n\n\n\n\n\n\n\nTip\n\n\n\nPrecision = How many retrieved items are relevant?  Recall = How many relevant items are retrieved?\n\n\n\n\n\n\n\n\nTip\n\n\n\nsensitivity = Probability of positive test given a patient has a disease. Specificity = Probability of a negative test given a patient is well.Specificity = 1 - False Alarm"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#utility-and-cost",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#utility-and-cost",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Utility and cost",
    "text": "Utility and cost\n\nDetection Cost:\n\ncost = C_{\\mathrm{FP}} \\times \\mathrm{FP}+C_{\\mathrm{FN}} \\times \\mathrm{FN}\n\nFmeasure\n\nF1=\\frac{2\\times \\left(\\mathrm{Recall}\\times \\mathrm{Precision}\\right)}{\\mathrm{Recall}+\\mathrm{Precision}}"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#roc-curve",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#roc-curve",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "ROC curve",
    "text": "ROC curve\n\nReceiver Operative Curve\nPlot between True positive rate on y axis and False positive rate on x axis\nAUC : Area under the curve, higher the area, better the performance\n\nA Receiver Operating Characteristic (ROC) curve plots the TP rate vs. the FP rate as a threshold on the confidence of an instance being positive is varied :"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#basic-idea",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#basic-idea",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "basic idea",
    "text": "basic idea\n\nIf it walks like a duck, quacks like a duck , then it’s probably a duck.\nIf data points are represented well then KNN works well.\nchoosing K is important, if K is too small then it becomes sensitive to noise point. If k is too large, neighborhood may incudes points from other class.\nEuclidean distance between two instance d\\left(X_i ,X_j \\right)=\\sqrt{\\sum_{r=1}^n {\\left(a_r \\left(X_i \\right)-a_r{\\left(X_j \\right)} \\right)}^2 } here a_i \\left(X\\right)\\; denotes features.\nIn case of continuous valued target function, Mean value of K nearest training examples is taken"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#how-to-determinke-k",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#how-to-determinke-k",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "How to determinke K",
    "text": "How to determinke K\n\nexperiment with different value of K starting form 1 on test set to validate the error, in case of binary classification use odd number for k to avoid ties.\n\nKNN is a transductive method, there is no training involved , it is refereed as Lazy learning, Learning is just storing all the training instances  Similar Keywords: KNN, Memory Based Reasoning, Example Based Reasoning, Instance Based Learning, Case Based Reasoning, Lazy Learning Voronoi Diagram: Decision surface formed by the training Examples for 1 nearest neighbors classifier"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#improvements",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#improvements",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Improvements",
    "text": "Improvements\n\nDistance weighted Nearest Neighbors\nScaling (normalization) attributes for fair computation fo distances\nMeasure “closeness” differently\nFinding “close” example in large training set quickly , eg Efficient memory indexing using kd-tree"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#pros",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#pros",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Pros",
    "text": "Pros\n\nHighly effective transductive inference method for noisy training data and complex target functions.\nTarget function for a whole space may be described as a combinations of less complex local approximations\nTrains very fast (Lazy Learner)"
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#cons",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#cons",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Cons",
    "text": "Cons\n\nCurse of dimensionality\nStorage: all training example are saved in memory\nslow at query time, can be overcome by pre sorting and indexing training samples."
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#convergence-of-1-nn",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#convergence-of-1-nn",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Convergence of 1-NN",
    "text": "Convergence of 1-NN\nP\\left(\\mathrm{KNNError}\\right)=2\\left(\\mathrm{Bayes}\\;\\mathrm{Optimal}\\;\\mathrm{Error}\\;\\mathrm{Rate}\\right) Probability of K NN error is at most twice the bayes optimal error, bayes optimal error is best(least) error we can get using machine learning  It is Possible to show that: as the size of training data set approaches infinity, the one nearest neighbor classifier guarantees an error rate of no worse than twice the bayes error rate ( the minimum achievable error rate given the distribution of the data)."
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#density-estimation-using-knn",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#density-estimation-using-knn",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "Density Estimation using KNN",
    "text": "Density Estimation using KNN\nNon parametric Density Estimation using KNN.  nstead of fixing bin width h and counting the mumber of instances, fix the instances(neighbors) k and check bin width \\hat{p} \\left(X\\right)=\\frac{k}{2{\\mathrm{Nd}}_k \\left(X\\right)} here d_k \\left(X\\right) is the k_{\\mathrm{th}} closest distance to to X , This is also known as Parzen density estimation."
  },
  {
    "objectID": "posts/CS5590/2022-08-20-CS5590-week2.html#knn-example-using-sklearn",
    "href": "posts/CS5590/2022-08-20-CS5590-week2.html#knn-example-using-sklearn",
    "title": "Machine Learning Model Evaluation Measures and KNN CS5590 week 2",
    "section": "KNN example using sklearn",
    "text": "KNN example using sklearn\nImport libraries\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn import neighbors, datasets\niris = datasets.load_iris()\n\nPrint shapes and class information\n\nprint('features: ',iris.feature_names)\nprint('target: ',iris.target)\nprint('classess: ',iris.target_names)\nX = iris.data\ny = iris.target\nprint('input  data shape:',X.shape)\nprint('target shape: ',y.shape)\n\nfeatures:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\ntarget:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\nclassess:  ['setosa' 'versicolor' 'virginica']\ninput  data shape: (150, 4)\ntarget shape:  (150,)\n\n\nPlot the data\n\nplt.scatter(iris.data[:,1],iris.data[:,2],c=iris.target, cmap=plt.cm.Paired)\nplt.xlabel(iris.feature_names[1])\nplt.ylabel(iris.feature_names[2])\nplt.show()\n\nplt.scatter(iris.data[:,0],iris.data[:,3],c=iris.target, cmap=plt.cm.Paired)\nplt.xlabel(iris.feature_names[0])\nplt.ylabel(iris.feature_names[3])\nplt.show()\n\n\n\n\n\n\n\nsplit the dataset into test set and train set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n\nFit the classifier with different values of k\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nk_range = range(1,26)\nscores = {}\nscores_list = []\nfor k in k_range:\n        knn = KNeighborsClassifier(n_neighbors=k)\n        knn.fit(X_train,y_train)\n        y_pred=knn.predict(X_test)\n        scores[k] = metrics.accuracy_score(y_test,y_pred)\n        scores_list.append(metrics.accuracy_score(y_test,y_pred))\n\nPlot the scores:\n\n#plot the relationship between K and the testing accuracy\nplt.plot(k_range,scores_list)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Testing Accuracy');\n\n\n\n\nchose the best value of K for final model.\n\n\n\n\n\n\nTip\n\n\n\nIn KNN, finding the value of k is not easy. A small value of k means that noise will have a higher influence on the result and a large value make it computationally expensive. Data scientists usually choose as an odd number if the number of classes is 2 and another simple approach to select k is set k=sqrt(n). There is one more widely used method called Elbow Method which is also used to find the value of K, here we plot error rate vs k value and chose k value at elbow point.\n\n\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train,y_train);\n\n\n# Confusion metrics\nfrom sklearn.metrics import confusion_matrix\nprint('confusion matrix on test data: ')\nprint(confusion_matrix(y_test, y_pred))\n\nconfusion matrix on test data: \n[[11  0  0]\n [ 0 13  0]\n [ 0  0  6]]\n\n\n\nfrom sklearn.metrics import classification_report\nprint('classification report on test data:')\nprint(classification_report(y_test, y_pred, target_names=iris.target_names))\n\nclassification report on test data:\n              precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00        11\n  versicolor       1.00      1.00      1.00        13\n   virginica       1.00      1.00      1.00         6\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30"
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "",
    "text": "It is a discriminative classifier.\nInspired by Statistical Learning.\nDeveloped in 1992 by Vapnik, Guyon, Boser\nWas one of the go-to methods in ML since mid 1990s (only recently displaced by deep learning.)"
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#basics-of-lagrange-multipliers",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#basics-of-lagrange-multipliers",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "Basics of Lagrange Multipliers",
    "text": "Basics of Lagrange Multipliers\n\nOptimization problem: Minimize : \\displaystyle f\\left( \\overrightarrow{x} \\right)  Such that for all i, \\displaystyle g_i\\left( \\overrightarrow{x} \\right)\\le 0 \nTo solve the above problem we create augmented Lagrange function: \\displaystyle L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right):=f\\left( \\overrightarrow{x} \\right)+\\sum_{i=1}^{n}\\lambda_ig_i\\left( \\overrightarrow{x} \\right)  \\displaystyle \\underbrace{L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right)}_{\\text{lagrange function}} :=f\\left( \\overrightarrow{x} \\right)+\\sum_{i=1}^{n}\\underbrace{\\lambda_i}_{\\text{lagrange variable  or dual varialbe }}g_i \\left( \\overrightarrow{x} \\right) \nObservation: For any feasible x and all \\lambda_i \\ge 0,  \\displaystyle L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right):=f\\left( \\overrightarrow{x} \\right)+\\overbrace{\\sum_{i=1}^{n}\\overbrace{\\lambda_i}^{\\text{this is positve}} \\underbrace{g_i\\left( \\overrightarrow{x} \\right)}_{\\text{this is negative}}}^{\\text{This is negative}}  Hence , \\displaystyle L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right) \\le f\\left( \\overrightarrow{x} \\right)  \\displaystyle \\Longrightarrow \\max_{\\lambda_i \\ge 0} L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right) \\le f\\left( \\overrightarrow{x} \\right) \nSo, the optimal value to the constrained optimization: \\displaystyle p^*:=\\min_{\\overrightarrow{x} } \\max_{\\lambda_i \\ge 0} L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right)  We can see that now problem becomes unconstrained in x  Also p^* is called The primal problem\nObservation: consider a function: \\displaystyle \\min_{\\overrightarrow{x} } L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right) Since p^* is solution for maximum possible \\lambda so for any feasible x and all \\lambda_i \\ge 0 \\displaystyle p^* \\ge \\min_{\\overrightarrow{x} } L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right)  Thus: \\displaystyle d^*:= \\max_{\\lambda_i \\ge 0} \\min_{\\overrightarrow{x} } L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right) \\le p^*  Also d^* is called The dual problem\n\nIn short:\n\n\n\n\n\n\nNote\n\n\n\nOptimization problem:Minimize : \\displaystyle f\\left( \\overrightarrow{x} \\right) Such that for all i, \\displaystyle g_i\\left( \\overrightarrow{x} \\right)\\le 0 Lagrange Function : \\displaystyle L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right):=f\\left( \\overrightarrow{x} \\right)+\\sum_{i=1}^{n}\\lambda_ig_i\\left( \\overrightarrow{x} \\right)  Primal: \\displaystyle p^*:=\\min_{\\overrightarrow{x} } \\max_{\\lambda_i \\ge 0} L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right) Dual: \\displaystyle d^*:= \\max_{\\lambda_i \\ge 0} \\min_{\\overrightarrow{x} } L\\left( \\overrightarrow{x},\\overrightarrow{\\lambda} \\right) \n\n\n\nTheorem (weak Lagrangian duality): d^* \\le p^* This is also called as minimax inequality p^*-d^* is called duality gap\nThere are certain condition when duality gap becomes zero, for that we need to understand convexity\n\nA function f:\\mathbb{R}^d \\rightarrow \\mathbb{R} is called convex iff for any two point x and x' and \\beta \\in \\left[ 0,1 \\right] f\\left( \\beta\\overrightarrow{x}+\\left( 1-\\beta \\right)\\overrightarrow{x} \\right) \\le \\beta f\\left( \\overrightarrow{x} \\right)+\\left( 1-\\beta \\right)f\\left( \\overrightarrow{x} \\right) \nA set S \\subset\\mathbb{R}^d is called conved iff for any tow points x, x' \\in S and any \\beta \\in \\left[ 0,1 \\right] \\beta \\overrightarrow{x}+\\left( 1-\\beta \\right)\\overrightarrow{x} \\in S \nConvex Optimization problem  \\displaystyle \\min_{\\overrightarrow{x} \\in \\mathbb{R}^d } f\\left( \\overrightarrow{x} \\right)  subject to: \\displaystyle g_i\\left( \\overrightarrow{x} \\right)\\le 0 for 1 \\le i \\le n is called convex optimization problem if:\n\nThe objective function f\\left( \\overrightarrow{x} \\right) is convex function, and\nthe feasible set induced by the constraints g_i is a convex set.\n\n\nTheorem (strong Lagrangian duality): if f is convex and for a feasible point x^* g_i\\left( \\overrightarrow{x^*} \\right)<0, or  g_i\\left( \\overrightarrow{x^*} \\right) \\le 0 when g is affine Then d^*=p^* This is called Slater’s condition."
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#svm-standard-primal-form",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#svm-standard-primal-form",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "SVM standard (primal) form",
    "text": "SVM standard (primal) form\n\\displaystyle \\min_{w,b}\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2  such that: \\forall i, y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) \\ge 1\n\nObservations :\n\nObjective function is convex\nthe constraints are affine, inducing a polytope constraint set.\n\nSo SVM is a convex optimization problem (in fact a quadratic program)\nMoreover, strong duality holds.\nLagrangian for SVM\n\nFor Lagrangian the constraint should always written as less than 0 format:  y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) -1 \\ge 0  - y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) +1 \\le 0  1 - y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) \\le 0 \nNow the Lagrangian for SVM can be written as: \\displaystyle L\\left( \\overrightarrow{w},b,\\overrightarrow{\\alpha} \\right)=\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 + \\underbrace{\\sum_{i = 1}^{n}\\alpha_i\\left( 1-y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b \\right) \\right)}_{\\text{appears like a hinge loss}}"
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#svm-dual",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#svm-dual",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "SVM Dual",
    "text": "SVM Dual\n\nPrimal \\displaystyle \\min_{\\overrightarrow{w},b }\\max_{\\overrightarrow{\\alpha } \\ge 0 }\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 + \\sum_{i = 1}^{n}\\alpha_i\\left( 1-y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b   \\right) \\right) \nDual \\displaystyle\\max_{\\overrightarrow{\\alpha } \\ge 0 } \\min_{\\overrightarrow{w},b }\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 + \\sum_{i = 1}^{n}\\alpha_i\\left( 1-y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b   \\right) \\right) \nSlater’s condition from convex optimization guarantees that these two optimization problems are equivalent!"
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#solving-using-kkt-condition",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#solving-using-kkt-condition",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "Solving using KKT condition",
    "text": "Solving using KKT condition\nKKT stands for Karush-Kuhn-Tucker Condition - We solve Dual problem: \\displaystyle\\max_{\\overrightarrow{\\alpha } \\ge 0 } \\min_{\\overrightarrow{w},b }\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 + \\sum_{i = 1}^{n}\\alpha_i\\left( 1-y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b \\right) \\right)\n\nWe can solve for optimal w, b as function of \\alpha \\displaystyle \\frac{\\partial L }{\\partial \\overrightarrow{w}}= w - \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i=0 \\Rightarrow w = \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i \\displaystyle \\frac{\\partial L }{\\partial b}= \\sum_{i}\\alpha_iy_i=0 \\Rightarrow \\sum_{i}\\alpha_iy_i =0\nsubstituting these values back in Dual we get:  \\displaystyle \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\frac{1}{2} \\left( \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i \\right) \\cdot \\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\right) + \\sum_{i = 1}^{n}\\alpha_i\\left( 1-y_i\\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\cdot\\overrightarrow{x_i}+b \\right) \\right) \\displaystyle \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\frac{1}{2} \\sum_{i,j}\\alpha_i\\alpha_jy_iy_j\\overrightarrow{x}_i\\cdot\\overrightarrow{x} _j + \\sum_{i = 1}^{n}\\alpha_i-\\sum_{i = 1}^{n} \\left( \\alpha_iy_i\\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x} _j\\cdot\\overrightarrow{x_i}+b\\right) \\right) \\displaystyle \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\frac{1}{2} \\sum_{i,j}\\alpha_i\\alpha_jy_iy_j\\overrightarrow{x}_i\\cdot\\overrightarrow{x} _j + \\sum_{i = 1}^{n}\\alpha_i- \\sum_{i = 1}^{n}\\alpha_iy_i\\sum_{j}\\alpha_jy_j\\overrightarrow{x} _j\\cdot\\overrightarrow{x_i}+ \\sum_{i = 1}^{n}\\alpha_iy_ib \\displaystyle \\max_{\\overrightarrow{\\alpha } \\ge 0 } -\\frac{1}{2} \\sum_{i,j}\\alpha_i\\alpha_jy_iy_j\\overrightarrow{x}_i\\cdot\\overrightarrow{x} _j + \\sum_{i = 1}^{n}\\alpha_i + \\sum_{i = 1}^{n}\\alpha_iy_ib \\displaystyle \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\sum_{i = 1}^{n}\\alpha_i -\\frac{1}{2} \\sum_{i,j}\\alpha_i\\alpha_jy_iy_j\\overrightarrow{x}_i\\cdot\\overrightarrow{x} _j\nThe above equation can also be written as:  \\displaystyle \\max \\sum_{k = 1}^{R}\\alpha_k - \\frac{1}{2}\\sum_{k=1}^{R}\\sum_{l = 1}^{R}\\alpha_k \\alpha_l Q_{kl}, where \\displaystyle Q_{kl} =y_ky_l\\left( \\mathbf{X_k}\\cdot \\mathbf{X_l} \\right) subject to constrains:\\alpha_k \\ge 0, and \\forall k , \\displaystyle \\sum_{k=1}^{R}\\alpha_ky_k=0\nAbove problem can be solved using SMO (Sequential minimal optimization) or any other quadratic programming or gradient descent.\nOnce we solve we get optimum \\alpha^*\nUsing \\alpha^* we can get w^* as below: \\displaystyle w^* = \\sum_{i}\\alpha_i^*y_i\\overrightarrow{x}_i\nb^* can be calculated as follows: y_i\\left( \\overrightarrow{w}^* \\cdot \\overrightarrow{x_i} +b \\right) = 1  y_i\\left( \\overrightarrow{w}^* \\cdot \\overrightarrow{x_i} \\right) + y_ib = 1  Multiplying y_i both the sides:  y_i y_i\\left( \\overrightarrow{w}^* \\cdot \\overrightarrow{x_i} \\right) + y_i y_ib = y_i  y_i y_ib = y_i -y_i y_i\\left( \\overrightarrow{w}^* \\cdot \\overrightarrow{x_i} \\right)  y_i y_i b can be written as b because y_i can be only \\pm 1 so in either case y_i y_i =1 b = y_i \\left( 1- y_i\\left( \\overrightarrow{w}^* \\cdot \\overrightarrow{x_i} \\right) \\right)  b^* = - y_i \\left( y_i\\left( \\overrightarrow{w}^* \\cdot \\overrightarrow{x_i} \\right)- 1 \\right) \nNow we can classify with: f(\\mathbf{X},\\mathbf{W}^*,b^*)=\\mathrm{sign} (\\mathbf{W}^* \\cdot \\mathbf{X}+b^*)"
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#lagrangian-for-soft-margin-svm",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#lagrangian-for-soft-margin-svm",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "Lagrangian for Soft Margin SVM",
    "text": "Lagrangian for Soft Margin SVM\n\nWe need to Solve: \\displaystyle \\min_{w,b,\\varepsilon}\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 + c \\sum_{i=1}\\varepsilon_i  such that: \\forall i, y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) \\ge 1-\\varepsilon _i, and \\varepsilon _i\\ge0 \nFor Lagrangian the constraint should always written as less than 0 condition:  y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) \\ge 1-\\varepsilon _i, and \\varepsilon _i\\ge0  y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) - 1 + \\varepsilon _i \\ge 0, and -\\varepsilon _i \\le 0  1 - \\varepsilon _i -y_i\\left( \\overrightarrow{w}\\cdot \\overrightarrow{x_i} +b \\right) \\le 0, and -\\varepsilon _i \\le 0 \nLagrangian formulation of above problem: \\displaystyle L\\left( \\overrightarrow{w},b,\\overrightarrow{\\alpha},\\overrightarrow{\\beta},\\overrightarrow{\\varepsilon } \\right)= \\\\ \\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 +c\\sum_{i}\\varepsilon_i + \\sum_{i = 1}^{n}\\alpha_i\\left( 1- \\varepsilon _i - y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b \\right) \\right) -\\sum_{i}\\beta_i \\varepsilon_i\nPrimal \\displaystyle  \\min_{ \\left(  \\overrightarrow{w},b,\\overrightarrow{\\varepsilon } \\right)}\\max_{\\left(  \\overrightarrow{\\alpha } \\ge 0 ,\\overrightarrow{\\beta} \\ge 0  \\right)}\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 +c\\sum_{i}\\varepsilon_i + \\sum_{i = 1}^{n}\\alpha_i\\left( 1- \\varepsilon _i - y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b   \\right) \\right) -\\sum_{i}\\beta_i \\varepsilon_i   \nDual \\displaystyle  \\max_{\\left( \\overrightarrow{\\alpha } \\ge 0 , \\overrightarrow{\\beta} \\ge 0  \\right)} \\min_{\\left( \\overrightarrow{w},b,\\overrightarrow{\\varepsilon }  \\right)}\\frac{1}{2}\\left\\lVert \\overrightarrow{w} \\right\\rVert^2 +c\\sum_{i}\\varepsilon_i + \\sum_{i = 1}^{n}\\alpha_i\\left( 1- \\varepsilon _i - y_i\\left( \\overrightarrow{w}\\cdot\\overrightarrow{x_i}+b   \\right) \\right) -\\sum_{i}\\beta_i \\varepsilon_i   \nSame as Hard margin SVM we use KKT condition and solve minimization of dual: \\displaystyle \\frac{\\partial L }{\\partial \\overrightarrow{w}}= w - \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i=0 \\Rightarrow w = \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i \\displaystyle \\frac{\\partial L }{\\partial b}= \\sum_{i}\\alpha_iy_i=0 \\Rightarrow \\sum_{i}\\alpha_iy_i =0 \\displaystyle \\frac{\\partial L }{\\partial \\varepsilon _i}= c -\\alpha_i - \\beta_i = 0\\Rightarrow c=\\beta_i+\\alpha_i\n\nObservation: \\overbrace{c}^{\\text{Upper bound of }\\alpha \\text{ and }\\beta} =\\underbrace{\\beta_i}_{\\text{always +ve}} +\\underbrace{\\alpha_i}_{\\text{always +ve}} so we can say: 0 \\le \\alpha_i \\le c \\forall i\n\nsubstituting these values back in Dual we get:  \\displaystyle \\Rightarrow \\max_{\\overrightarrow{\\alpha } \\ge 0 , \\overrightarrow{\\beta} \\ge 0} \\frac{1}{2}\\left( \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i \\right) \\cdot \\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\right) +\\sum_{i}\\varepsilon_i\\left( \\beta_i+\\alpha_i \\right) + \\sum_{i = 1}^{n}\\alpha_i\\left( 1- \\varepsilon _i - y_i\\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\cdot\\overrightarrow{x_i}+b\\right) \\right) -\\sum_{i}\\beta_i \\varepsilon_i \\displaystyle \\Rightarrow \\max_{\\overrightarrow{\\alpha } \\ge 0 , \\overrightarrow{\\beta} \\ge 0} \\frac{1}{2}\\left( \\sum_{i}\\alpha_iy_i\\overrightarrow{x}_i \\right) \\cdot \\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\right) +\\sum_{i}\\varepsilon_i \\beta_i+\\sum_{i}\\varepsilon_i \\alpha_i + \\sum_{i = 1}^{n}\\alpha_i - \\sum_{i = 1}^{n}\\alpha_i \\varepsilon _i - \\sum_{i = 1}^{n}\\alpha_i y_i\\left( \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\cdot\\overrightarrow{x_i}+b \\right) -\\sum_{i}\\beta_i \\varepsilon_i \\displaystyle \\Rightarrow \\max_{\\overrightarrow{\\alpha } \\ge 0 , \\overrightarrow{\\beta} \\ge 0} \\frac{1}{2} \\sum_{i}\\alpha_i \\alpha_j y_i y_j \\overrightarrow{x}_i \\overrightarrow{x}_j +\\sum_{i}\\varepsilon_i \\beta_i+\\sum_{i}\\varepsilon_i \\alpha_i + \\sum_{i = 1}^{n}\\alpha_i - \\sum_{i = 1}^{n}\\alpha_i \\varepsilon _i - \\sum_{i = 1}^{n}\\alpha_i y_i \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\cdot\\overrightarrow{x_i}+ \\sum_{i = 1}^{n}\\alpha_i y_ib -\\sum_{i}\\beta_i \\varepsilon_i \\displaystyle \\Rightarrow \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\frac{1}{2} \\sum_{i}\\alpha_i \\alpha_j y_i y_j \\overrightarrow{x}_i \\overrightarrow{x}_j + \\sum_{i = 1}^{n}\\alpha_i - \\sum_{i = 1}^{n}\\alpha_i y_i \\sum_{j}\\alpha_jy_j\\overrightarrow{x}_j \\cdot\\overrightarrow{x_i}+ \\sum_{i = 1}^{n}\\alpha_i y_ib \\displaystyle \\Rightarrow \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\frac{1}{2} \\sum_{i}\\alpha_i \\alpha_j y_i y_j \\overrightarrow{x}_i \\overrightarrow{x}_j + \\sum_{i = 1}^{n}\\alpha_i - \\sum_{i=1,j=1}^{n}\\alpha_i \\alpha_j y_i y_j \\overrightarrow{x_i} \\cdot \\overrightarrow{x_j}+ \\sum_{i = 1}^{n}\\alpha_i y_ib \\displaystyle \\Rightarrow \\max_{\\overrightarrow{\\alpha } \\ge 0 } \\sum_{i = 1}^{n}\\alpha_i -\\frac{1}{2} \\sum_{i}\\alpha_i \\alpha_j y_i y_j \\overrightarrow{x}_i \\overrightarrow{x}_j\nNotice neither \\overrightarrow{\\beta} nor \\overrightarrow{\\varepsilon } appears in the above equation.\nThe above equation can also be written as:  \\displaystyle \\max \\sum_{k = 1}^{R}\\alpha_k - \\frac{1}{2}\\sum_{k=1}^{R}\\sum_{l = 1}^{R}\\alpha_k \\alpha_l Q_{kl}, where \\displaystyle Q_{kl} =y_ky_l\\left( \\mathbf{X_k}\\cdot \\mathbf{X_l} \\right) subject to constrains:0 \\le \\alpha_k \\le c, and \\forall k , \\displaystyle \\sum_{k=1}^{R}\\alpha_ky_k=0\n\n\n\n\n\n\n\nNote\n\n\n\nOne of the constraint of soft margin SVM is 0 \\le \\alpha_k \\le c which is different for hard margin SVM constraint \\alpha_k \\ge 0"
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#why-do-we-require-the-kernel-trick",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#why-do-we-require-the-kernel-trick",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "Why do we require the Kernel Trick",
    "text": "Why do we require the Kernel Trick\n\nWe found that after solving minimization problem of dual of SVM we get following:  \\displaystyle \\max \\sum_{k = 1}^{R}\\alpha_k - \\frac{1}{2}\\sum_{k=1}^{R}\\sum_{l = 1}^{R}\\alpha_k \\alpha_l Q_{kl}, where \\displaystyle Q_{kl} =y_ky_l\\left( \\mathbf{X_k}\\cdot \\mathbf{X_l} \\right) subject to constrains:0 \\le \\alpha_k \\le c, and \\forall k , \\displaystyle \\sum_{k=1}^{R}\\alpha_ky_k=0\nBut if the data can’t be separated linearly we transform the data to higher dimension space using the transformation \\phi. So that the data can be separated using a hyper-plane in higher dimension space. In that case the above equation changes as below :  \\displaystyle \\max \\sum_{k = 1}^{R}\\alpha_k - \\frac{1}{2}\\sum_{k=1}^{R}\\sum_{l = 1}^{R}\\alpha_k \\alpha_l Q_{kl}, where \\displaystyle Q_{kl} =y_ky_l \\underbrace{\\left(\\mathbf{\\Phi} \\left( \\mathbf{X}_k \\right)\\cdot \\mathbf{\\Phi} \\left( \\mathbf{X}_l \\right)\\right)}_{\\text{Notice the term } \\Phi } subject to constrains:0 \\le \\alpha_k \\le c, and \\forall k , \\displaystyle \\sum_{k=1}^{R}\\alpha_ky_k=0\nThen compute :  \\displaystyle \\mathbf{W} = \\sum_{\\text{k s.t } \\alpha_k >0 }\\alpha_k^*y_k \\mathbf{\\Phi} \\left( \\mathbf{X}_k \\right)\nThen classify with  \\displaystyle f(\\mathbf{X},w,b)=\\mathrm{sign}\\left( \\mathbf{W} \\cdot \\mathbf{\\Phi}(\\mathbf{X})+b \\right)\nMost important change :  \\mathbf{X} \\rightarrow \\mathbf{\\Phi}(\\mathbf{X})\nNotice that in the term \\displaystyle Q_{kl} =y_ky_l \\left(\\mathbf{\\Phi} \\left( \\mathbf{X}_k \\right)\\cdot \\mathbf{\\Phi} \\left( \\mathbf{X}_l \\right)\\right) we must do \\frac{R^2}{2} dot products to get this matrix ready. Assuming a quadratic polynomial kernel, each dot product requires \\frac{m^2}{2} addition and multiplication ( where m is the dimension of X)  The whole thing costs \\frac{R^2m^2}{4} This is the reason we require a trick so that we need not do this large computation."
  },
  {
    "objectID": "posts/CS5590/2022-09-10-CS5590-week4.html#how-do-we-do-the-kernel-trick",
    "href": "posts/CS5590/2022-09-10-CS5590-week4.html#how-do-we-do-the-kernel-trick",
    "title": "Support Vector Machines CS5590 week 4",
    "section": "How do we do the kernel Trick",
    "text": "How do we do the kernel Trick\nTo understand we create a data in circular fashion as shown below:\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport math\ndef get_points(rl,rh):\n    npoints = 1000 # points to chose from\n    r =  np.random.uniform(low=rl, high=rh, size=npoints)\n    t = np.linspace(0, 2*np.pi, npoints, endpoint=False)\n    x = r * np.cos(t)\n    y = r * np.sin(t)\n    return x,y\n\nfig = plt.figure(figsize=(4,4))\nx11,x21=get_points(2,4)\nplt.scatter(x11,x21);\nx12,x22=get_points(6,8)\nplt.scatter(x12,x22);\nplt.xlabel('x1')\nplt.ylabel('x2');\n\n\n\n\n\n\nThe two circle can’t be separated by a line.\nNow we transform the data to 3 dimension using below function. \\phi\\left( \\mathbf{X}\\right) = \\phi\\left( \\left( \\begin{array}{c}  x_1\\\\  x_2 \\end{array} \\right) \\right) = \\left( \\begin{array}{c} x_1^2 \\\\ \\sqrt{2}x_1x_2 \\\\ x_2^2 \\end{array} \\right)\nPython implementation of the same is shown below:\n\n\ndef transform(x1,x2):\n    return np.square(x1),np.sqrt(2)*x1*x2,np.square(x2)\n\n\nWe can see in below pic that how data becomes sparable in 3 dimensional space.\n\n\n\nCode\nfrom mpl_toolkits import mplot3d\nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,8))\nax = plt.axes(projection='3d')\nx11,x21,x31 = transform(x11,x21)\nx12,x22,x32 = transform(x12,x22)\nax.scatter3D(x11,x21,x31);\nax.scatter3D(x12,x22,x32);\nax.set_xlabel('x1')\nax.set_ylabel('x2')\nax.set_zlabel('x3');\nax.view_init(10, 80);\n\n\n\n\n\n\nIn case of SVM we need the dot product of the transformed data, not the transformed data itself.\nConsider two vectors \\mathbf{a} and \\mathbf{b}, we will apply following transformation on it : \\phi\\left( \\mathbf{X}\\right) = \\phi\\left( \\left( \\begin{array}{c}  x_1\\\\  x_2 \\end{array} \\right) \\right) = \\left( \\begin{array}{c} x_1^2 \\\\ \\sqrt{2}x_1x_2 \\\\ x_2^2 \\end{array} \\right)  We get below result:  \\phi\\left( \\mathbf{a}\\right)^T\\phi\\left( \\mathbf{b}\\right)= \\left( \\begin{array}{c} a_1^2 \\\\ \\sqrt{2}a_1a_2 \\\\ a_2^2 \\end{array} \\right)^T \\cdot \\left( \\begin{array}{c} b_1^2 \\\\ \\sqrt{2}b_1b_2 \\\\ b_2^2 \\end{array} \\right)= a_1^2 b_1^2 + 2 a_1 b_1 a_2 b_2 +a_2^2 b_2^2= \\left( a_1b_1+a_2b_2\\right)^2= \\left( \\left( \\begin{array}{c}  a_1\\\\  a_2 \\end{array} \\right)^T \\cdot \\left( \\begin{array}{c}  b_1\\\\  b_2 \\end{array} \\right) \\right)^2 = \\left( \\mathbf{a}^T \\cdot \\mathbf{b} \\right)^2\nThe kernel function here is polynomial function.\nwe can see that we don’t even need to use \\phi we can get the result just from \\left( \\mathbf{a}^T \\cdot \\mathbf{b} \\right)^2\nSo we never need to transformed the data to higher domain still we get the same benefit at the less computation cost.\nThe same is explained below:\n\n\n\nCode\nfig = plt.figure(figsize=(16,16))\nx11,x21=get_points(2,4)\nx12,x22=get_points(6,8)\nsame_domain_result = np.square(x11*x12+x21*x22)\nax = fig.add_subplot(2, 2, 1)\nax.scatter(x11,x21);\nax.scatter(x12,x22);\nax.set_xlabel('x1')\nax.set_ylabel('x2');\nax.set_title(' Original domain')\n\nx11,x21,x31 = transform(x11,x21)\nx12,x22,x32 = transform(x12,x22)\ntransformed_domain_result = x11*x12+x21*x22+x31*x32\nax = fig.add_subplot(2, 2, 2, projection='3d')\nax.scatter3D(x11,x21,x31);\nax.scatter3D(x12,x22,x32);\nax.set_xlabel('x1')\nax.set_ylabel('x2')\nax.set_zlabel('x3');\nax.view_init(10, 80);\nax.set_title('Transformed domain ')\n\nax = fig.add_subplot(2, 2, 3)\nax.scatter(range(len(same_domain_result)),same_domain_result)\nax.set_title('Result in original domain $( \\mathbf{a}^T \\cdot \\mathbf{b} )^2$')\n\nax = fig.add_subplot(2, 2, 4)\nax.scatter(range(len(transformed_domain_result)),transformed_domain_result)\nax.set_title('Result in transformed domain $\\phi( \\mathbf{a})^T\\phi( \\mathbf{b})$ ');\n\n\n\n\n\n\n\nFrom above figure we can see that we get exact same result in original domain without transforming data to the higher dimensional space\nNot all functions are kernel functions.\n\nNeed to be decomposable: K(a,b)=\\phi(a)\\cdot \\phi(b)\n\nMercer’s condition : To expand kernel function K(X,Y) into a dot product, i.e. K(x,y)=\\Phi(x).\\Phi(y), K(x,y) has to be positive semi-definite function, i.e., for any function f(X) whose \\displaystyle \\int f^2(x)dx is finite, the following inequality holds: \\displaystyle \\int dx dy f(x) K(x,y) f(y) \\ge 0\nIt is not easy to select the kernel function which will work best for the given data.\nRBF kernels are considered good in general, especially for images (and other smooth functions/data).\nFor discrete data, chi-square kernel is preferred.\nwe can also do Multiple Kernel learning.\nIf still it doesn’t work we can use cross-validation to select a kernel function from some basic options.\nSame kernel trick can also be applied to other methods including:\n\nKernel k-NN\nKernel Perceptron\nKernelized Linear Regression\netc."
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "",
    "text": "An efficient nonparametric method.\nA hierarchical model.\nDivide and conquer strategy.\nInternal decision nodes\n\nUnivariate : It uses a single attribute X_i\n\nNumeric X_i:\n\nIf numeric data perform Binary split:X_i>w_m\n\nDiscrete X_i:\n\nFor discrete data perform n- way split for n possible values\n\n\nMultivariate: It uses more than one attributes, X\n\nLeaves\n\nClassification : Class labels, or proportions\nRegression : Numeric, r average, or local fit\n\nLearning is greedy; find the best split recursively.\nFor node m, N_m instances reach m, N_m^i belong to C_i  \\hat P(C_i|X,m)\\equiv p_m^i = \\frac{N_m^i}{N_m}\nNode m is pure if p_m^i is 0 or 1\nMeasure if impurity is entropy \\displaystyle I_m=-\\sum_{i=1}^kp_m^i \\log_2p_m^i\n\ncompare probability distributions vs entropy\n\n\nCode\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\nimport numpy as np\n# calculate entropy\ndef entropy(events, ets=1e-15):\n    return -sum([p * np.log2(p + ets) for p in events])\n\n# define probabilities\nprobs = np.arange(0.0001,1,0.001) \n# create probability distribution\ndists = [[p, 1.0 - p] for p in probs]\n# calculate entropy for each distribution\nents = [entropy(d) for d in dists]\n# plot probability distribution vs entropy\nplt.plot(probs, ents)\nplt.title('Probability Distribution vs Entropy for 2 class problem')\nplt.xlabel('Probability Distribution')\nplt.ylabel('Entropy (bits)')\nplt.show()\n\n\n\n\n\nEntropy in information theory specifies the average (expected) amount of information derived from observing an event .\n\n\n\nSelect a root not which divides the data best based on impurity measures.\nIf node is pure, generate a leaf and stop, otherwise split and continue recursively.\nImpurity after split:\n\nIt is probability weighted entropy given by:\n\n\\displaystyle I_m^{\\prime }=-\\sum_{j=1}^{n}\\frac{N_{mj}}{N_m}\\sum_{i=1}^kp_{mj}^i\\log_2p_{mj}^i, here, N_{mj} is j^{th} branch of N_m and N_{mj}^i belongs to i^{th} class.\n\n\nInformation gain: Expected reduction in impurity measure after split. Chose the attribute with maximum information gain.\nOther impurity measure method - Gini impurity/index : \\displaystyle 1- \\sum_{j=1}^cp_j^2\n\n\n\n\n\nNoisy training example or if only small number of samples are associated leaf nodes can cause overfitting.\nUsing Pruning for better generalization\n\nPruning is the process of removing subtree.\n\nPre-pruning: Early stopping, after a predetermined performance.\nPost-pruning: Grow the whole then prune the subtree which overfit on the pruning set\n\nPre-pruning is faster, post-pruning is more accurate.\n\n\n\n\n\nWhen multiple hypotheses can solve the problem chose the simplest one\n\n\n\n\nMeasure performance over training and separate validation data set\nMinimum Description Length : Minimize size(tree)+size(miscalssifications(tree))\n\n\n\n\n\nConvert tree to equivalent set of rules.(“if else” condition for example).\nPrune each rules independently of others, by removing any pre-conditions that result in improving its estimates accuracy.\nSort final rules into desired sequence for use.\n\n\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\nimport matplotlib.pyplot as plt\niris = load_iris()\nX, y = iris.data, iris.target\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X, y)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\ntree = tree.plot_tree(clf,ax=ax)"
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html#formulation",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html#formulation",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "Formulation",
    "text": "Formulation\n\nconsider a record with attributes A_1,A_2,\\dots ,A_n\nGoal is to predict class C\nSpecifically, we want to find the value of C that maximizes P(C|A_1,A_2,\\dots,A_n)\n\n\n\nwhat is Naive about Naive Bayes?\n\nThe attributes are considered independent of each other, this is Naive in Naive Bayes.\n\nAS we assume independence among attributes A_i so we can write: P(A_1,A_2,\\dots ,A_n|C_j)=P(A_i|C_j)P(A_2|C_j)\\dots P(A_n|C_j)\nNew point is classified to C_j if  P(C_j)\\prod_{j}P(A_i|C_j)=P(C_j)P(A_i|C_j)(A_2|C_j)\\dots P(A_n|C_j) is maximal .\nAssume that all hypotheses (classes) are equally probable a priori, i.e., P(C_i)=P(C_j) for all i,j\nThis is called assuming a uniform prior. It simplifies computing the posterior: \\displaystyle C_{ML}=\\arg \\max_c P(A_1,A_2,\\dots A_n|C)\nThis hypothesis is called the maximum likelihood hypothesis ."
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html#example",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html#example",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "Example",
    "text": "Example\nGiven a data as shown in as shown in below data frame, Find if tennis will be played for a scenario given by X: X=( \\mathrm{ Outlook = Sunny, Temperature= Cool, Humidity =High, Wind= Strong})\n\nimport pandas as pd\nAttributes =['Day',    'Outlook',  'Temperature',      'Humidity',     'Wind',     'Play Tennis']\ndata      =[['D1',     'Sunny',    'Hot',              'High',         'Weak',       'No'         ],\n            ['D2',     'Sunny',    'Hot',              'High',         'Strong',     'No'         ],\n            ['D3',     'Overcast',  'Hot',              'High',        'Weak',       'Yes'        ],\n            ['D4',     'Rain',    'Mild',              'High',         'Weak',       'Yes'        ],\n            ['D5',     'Rain',    'Cool',              'Normal',       'Weak',       'Yes'        ],\n            ['D6',     'Rain',    'Cool',              'Normal',       'Strong',     'No'         ],\n            ['D7',     'Overcast', 'Cool',             'Normal',       'Strong',     'Yes'        ],\n            ['D8',     'Sunny',    'Mild',              'High',        'Weak',       'No'         ],\n            ['D9',     'Sunny',    'Cool',             'Normal',       'Weak',       'Yes'        ],\n            ['D10',    'Rain',    'Mild',              'Normal',       'Weak',       'Yes'        ],\n            ['D11',    'Sunny',    'Mild',             'Normal',       'Strong',     'Yes'        ],\n            ['D12',    'Overcast', 'Mild',              'High',        'Strong',     'Yes'        ],\n            ['D13',    'Overcast',  'Hot',             'Normal',       'Weak',       'Yes'        ],\n            ['D14',    'Rain',    'Mild',              'High',         'Strong',     'No'         ]]\ndf = pd.DataFrame(columns=Attributes,data=data)\ndf\n\n\n\n\n\n  \n    \n      \n      Day\n      Outlook\n      Temperature\n      Humidity\n      Wind\n      Play Tennis\n    \n  \n  \n    \n      0\n      D1\n      Sunny\n      Hot\n      High\n      Weak\n      No\n    \n    \n      1\n      D2\n      Sunny\n      Hot\n      High\n      Strong\n      No\n    \n    \n      2\n      D3\n      Overcast\n      Hot\n      High\n      Weak\n      Yes\n    \n    \n      3\n      D4\n      Rain\n      Mild\n      High\n      Weak\n      Yes\n    \n    \n      4\n      D5\n      Rain\n      Cool\n      Normal\n      Weak\n      Yes\n    \n    \n      5\n      D6\n      Rain\n      Cool\n      Normal\n      Strong\n      No\n    \n    \n      6\n      D7\n      Overcast\n      Cool\n      Normal\n      Strong\n      Yes\n    \n    \n      7\n      D8\n      Sunny\n      Mild\n      High\n      Weak\n      No\n    \n    \n      8\n      D9\n      Sunny\n      Cool\n      Normal\n      Weak\n      Yes\n    \n    \n      9\n      D10\n      Rain\n      Mild\n      Normal\n      Weak\n      Yes\n    \n    \n      10\n      D11\n      Sunny\n      Mild\n      Normal\n      Strong\n      Yes\n    \n    \n      11\n      D12\n      Overcast\n      Mild\n      High\n      Strong\n      Yes\n    \n    \n      12\n      D13\n      Overcast\n      Hot\n      Normal\n      Weak\n      Yes\n    \n    \n      13\n      D14\n      Rain\n      Mild\n      High\n      Strong\n      No\n    \n  \n\n\n\n\n\nfrom IPython.display import display_html \nall_tables=\"\"\nfor col in df.columns[1:-1]:\n    table=pd.DataFrame()\n    for c in df['Play Tennis'].unique():\n        for r in df[col].unique():\n            n = df.loc[(df[col]==r) & (df['Play Tennis']==c) ,[col]].count().to_numpy()[0]\n            d = df.loc[(df['Play Tennis']==c) ,[col]].count().to_numpy()[0]\n            table.loc[col+'_'+str(r),'Play_Tennis'+'_'+c]=\"{}/{}\".format(n,d)\n            table_styler = table.style.set_table_attributes(\"style='display:inline'\").set_caption(col)\n    all_tables=all_tables+table_styler._repr_html_()\ndisplay_html (all_tables,raw=True)\n\n\n\n\n  Outlook\n  \n    \n       \n      Play_Tennis_No\n      Play_Tennis_Yes\n    \n  \n  \n    \n      Outlook_Sunny\n      3/5\n      2/9\n    \n    \n      Outlook_Overcast\n      0/5\n      4/9\n    \n    \n      Outlook_Rain\n      2/5\n      3/9\n    \n  \n\n\n\n  Temperature\n  \n    \n       \n      Play_Tennis_No\n      Play_Tennis_Yes\n    \n  \n  \n    \n      Temperature_Hot\n      2/5\n      2/9\n    \n    \n      Temperature_Mild\n      2/5\n      4/9\n    \n    \n      Temperature_Cool\n      1/5\n      3/9\n    \n  \n\n\n\n  Humidity\n  \n    \n       \n      Play_Tennis_No\n      Play_Tennis_Yes\n    \n  \n  \n    \n      Humidity_High\n      4/5\n      3/9\n    \n    \n      Humidity_Normal\n      1/5\n      6/9\n    \n  \n\n\n\n  Wind\n  \n    \n       \n      Play_Tennis_No\n      Play_Tennis_Yes\n    \n  \n  \n    \n      Wind_Weak\n      2/5\n      6/9\n    \n    \n      Wind_Strong\n      3/5\n      3/9\n    \n  \n\n\n\n Above table shows conditional probabilities For example p(\\mathrm{outlook}=\\mathrm{sunny} \\mid \\mathrm{play Tennis} = \\mathrm{no}) is given by row outlook_Sunny and column Play_Tennis_No of table Outlook and  p(\\mathrm{Temperature}=\\mathrm{Cool} \\mid \\mathrm{play Tennis} = \\mathrm{Yes}) is given by row Temperature_Cool and column Play_Tennis_Yes of table Temperature  Also we can calculate below 2 probabilities of the two classes:  P(\\mathrm{Play}=\\mathrm{Yes})=\\frac{9}{14} P(\\mathrm{Play}=\\mathrm{No})=\\frac{5}{14}\n\nForm look up table:  P\\left(\\mathrm{Outlook}=\\mathrm{Sunny} \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) = \\frac{2}{9}  P\\left(\\mathrm{Outlook}=\\mathrm{Sunny} \\mid \\mathrm{Play} = \\mathrm{No} \\right) = \\frac{3}{5}  P\\left(\\mathrm{Temperature}=\\mathrm{Cool} \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) = \\frac{3}{9}  P\\left(\\mathrm{Temperature}=\\mathrm{Cool} \\mid \\mathrm{Play} = \\mathrm{No} \\right) = \\frac{1}{5} P\\left(\\mathrm{Humidity}=\\mathrm{High } \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) = \\frac{3}{9}  P\\left(\\mathrm{Humidity}=\\mathrm{High } \\mid \\mathrm{Play} = \\mathrm{No} \\right) = \\frac{4}{5} P\\left(\\mathrm{Wind}=\\mathrm{Strong } \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) = \\frac{3}{9}  P\\left(\\mathrm{Wind}=\\mathrm{Strong } \\mid \\mathrm{Play} = \\mathrm{No} \\right) = \\frac{3}{5}\nMAP Rule: P\\left(\\mathrm{Yes} \\mid X\\right)=\\\\  P\\left(\\mathrm{Outlook}=\\mathrm{Sunny} \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) \\times \\\\  P\\left(\\mathrm{Temperature}=\\mathrm{Cool} \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) \\times \\\\  P\\left(\\mathrm{Humidity}=\\mathrm{High } \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) \\times \\\\  P\\left(\\mathrm{Wind}=\\mathrm{Strong } \\mid \\mathrm{Play} = \\mathrm{Yes} \\right) \\times \\\\  P(\\mathrm{Play}=\\mathrm{Yes})\\\\  =0.0053 P\\left(\\mathrm{No} \\mid X\\right)= \\\\  P\\left(\\mathrm{Outlook}=\\mathrm{Sunny} \\mid \\mathrm{Play} = \\mathrm{No} \\right) \\times \\\\  P\\left(\\mathrm{Temperature}=\\mathrm{Cool} \\mid \\mathrm{Play} = \\mathrm{No} \\right) \\times \\\\  P\\left(\\mathrm{Humidity}=\\mathrm{High } \\mid \\mathrm{Play} = \\mathrm{No} \\right) \\times \\\\  P\\left(\\mathrm{Wind}=\\mathrm{Strong } \\mid \\mathrm{Play} = \\mathrm{No} \\right) \\times \\\\  P(\\mathrm{Play}=\\mathrm{No}) \\\\  = 0.0206   Since P(\\mathrm{Play}=\\mathrm{Yes}) < P(\\mathrm{Play}=\\mathrm{No}) so X shall be labeled to be “No”, i.e. Given scenario X tennis will not be played."
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html#pros-and-cons",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html#pros-and-cons",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "Pros and Cons",
    "text": "Pros and Cons\n\nCombines prior knowledge and observed data\nOutput is not only a classification but a probability distribution over all classes\nRobust to isolated noise points.\nHandle missing values by ignoring instance during probability estimate calculation.\nRobust to irrelevant attributes.\nwith each training example, the prior and the likelihood can be updated dynamically\nIndependence assumption may not hold always."
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html#practical-issues",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html#practical-issues",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "Practical Issues",
    "text": "Practical Issues\n\nDiscretize the range into bins\n\nOne ordinal attribute per bin\nViolates independence assumption\n\nTwo way split : (A < v) or (A < v)\n\nchoose only one of the two splits as new attribute.\n\nProbability density estimation:\n\nAssume attribute follows a parametrized distribution, e.g. normal distribution.\nUse data to estimate parameters of distribution, e.g. mean and standard deviation using maximum likelihood estimation.\nOnce probability distribution is known, can use it to estimate the conditional probability, P(A_i \\mid c)"
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html#bayesian-belief-network-bayesian-net",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html#bayesian-belief-network-bayesian-net",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "Bayesian Belief network ( Bayesian net )",
    "text": "Bayesian Belief network ( Bayesian net )\nDescribe conditional independence among subset of variables (attributes) : combining prior knowledge about dependencies among variables with observed training data. For example consider below graph:\n\nHere Age, Occupation and Income determine if customer will byt this product, Given that customer buys product, whether there is interest in insurance is now independent of Age, Occupation, Income. P\\left(\\mathrm{Age,Occ,Inc,Buy,Ins}\\right)=P(\\mathrm{Age})P(\\mathrm{Occ})P\\left(\\mathrm{Inc}\\right)P\\left(\\mathrm{Buy} \\mid \\mathrm{Age, Occ, Inc}\\right)P\\left(\\mathrm{Int} \\mid \\mathrm{Buy}\\right)"
  },
  {
    "objectID": "posts/CS5590/2022-08-27-CS5590-week3.html#naive-bayes-classifier-category",
    "href": "posts/CS5590/2022-08-27-CS5590-week3.html#naive-bayes-classifier-category",
    "title": "Decision Trees, Naive Bayes CS5590 week 3",
    "section": "Naive Bayes Classifier category",
    "text": "Naive Bayes Classifier category\n\nIt is an Inductive Learning.\nIt is a generative Modeling.\nIt can be Parametric or Non-parametric Models.\nIt can be online or offline Models."
  },
  {
    "objectID": "posts/CS5590/2022-09-24-CS5590-week5.html",
    "href": "posts/CS5590/2022-09-24-CS5590-week5.html",
    "title": "Neural Networks CS5590 week 5",
    "section": "",
    "text": "Deep learning : A sub area of machine learning, that is today understood as representation learning.\nInspired by the human brain.\nHow do Neural Networks learn:\n\nWe initialize the weights with random value.\nThen present a trining patter to the network.\nFeed it through tho get output. (feed forward)\ncompare with target output.\nAdjust weights based on the error.\nAnd so on …\n\nDeep learning models can learn complex decision boundaries."
  },
  {
    "objectID": "posts/CS5590/2022-09-24-CS5590-week5.html#mlp-from-prml-book",
    "href": "posts/CS5590/2022-09-24-CS5590-week5.html#mlp-from-prml-book",
    "title": "Neural Networks CS5590 week 5",
    "section": "MLP From PRML book",
    "text": "MLP From PRML book\n\nNetwork with inputs, one hidden unit and outputs: \nThe output of the above network can be given as follows:   \\displaystyle y_{k}({\\bf x},{\\bf w})=\\sigma\\left(\\sum_{j=1}^{M}w_{k j}^{(2)}h\\left(\\sum_{i=1}^{D}w_{j i}^{(1)}x_{i}+w_{j0}^{(1)}\\right)+w_{k0}^{(2)}\\right)  This equation is also interpreted as forward propagation fo information through the newwork. It should be emphasized that these diagrams do not represent probabilistic graphical models, because the internal nodes represent deterministic variables rather than stochastic ones.\nThe above equation can be written as below if bias is absorbed into the set of weight by defining additional input variable x_0 whose value is clamped at x_0=1  \\displaystyle y_{k}({\\bf x},{\\bf w})=\\sigma\\left(\\sum_{j=0}^{M}w_{k j}^{(2)}h\\left(\\sum_{i=0}^{D}w_{j i}^{(1)}x_{i}\\right)\\right)\nA key difference among neural network and perceptron, is that the neural network uses continuous sigmoidal non-linearities in the hidden units, whereas the perceptron uses step-function non-linearities.\nIf the activation functions of all the hidden units in a network are taken to be linear, then for any such network we can always find an equivalent network without hidden units.\nIn principle, a network with sigmoidal hidden units can always mimic skip layer connections by using a sufficiently small first-layer weight that, over its operating range.\nIn practice, however, it may be advantageous to include skip-layer connections explicitly."
  },
  {
    "objectID": "posts/CS5590/2022-09-24-CS5590-week5.html#mlp-form-lecture-pdf",
    "href": "posts/CS5590/2022-09-24-CS5590-week5.html#mlp-form-lecture-pdf",
    "title": "Neural Networks CS5590 week 5",
    "section": "MLP Form lecture PDF",
    "text": "MLP Form lecture PDF\n\nExtension of perceptrons to multiple layers\n\nInitialize network with random weights\nFor all training cases ( called examples):\n\npresent training inputs to network and calculate output\nfor all layers (starting with output layer, back to input layer):\n\ncompare network output with correct putput\nAdapt weight in current layer\n\n\n\nMethod for Learning Weights in feed forward nets\n\nCan’t use Perceptron Rule\n\nNo teacher values (loss) are possible for hidden units.\n\nUse Gradient decent to minimize the error\n\nPropagate the deltas to adjust for errors\nBackward from outputs to hidden layers to inputs\nThe algorithm can be summarized as follows:\n\nComputes the error term for the output units using the observed error.\nFrom output layer , repeat\n\nPropagating the error term back to the previous layer and updating the weights between the two layers until the earliest layer is reached.\n\n\n\n\nAlgorithm in detail:\n\nInitialize weights (typically random)\nKeep doing epoch\n\nFor each example e in the training set do\n\nForward Pass to compute\n\ny = neural new output (network , e)\nmiss = (T-y) at each output unit\n\nbackward pass to calculate deltas to weights\nupdate all weights\n\nend\n\nuntil tuning set error stops improving"
  },
  {
    "objectID": "posts/CS5590/2022-09-24-CS5590-week5.html#backpropagation-from-prml-book",
    "href": "posts/CS5590/2022-09-24-CS5590-week5.html#backpropagation-from-prml-book",
    "title": "Neural Networks CS5590 week 5",
    "section": "Backpropagation From PRML book",
    "text": "Backpropagation From PRML book\n\nThink of the N weights as a point in an N-dimensional space \nMany error functions fo practical interest, comprise a sum of terms, onw for each data point in training set, so that  \\displaystyle E(\\mathbf{w})=\\sum_{n=1}^{N}E_{n}(\\mathbf{w})\nError function for one particular input patter n takes the form  \\displaystyle E_{n}={\\frac{1}{2}}\\sum_{k}(y_{n k}-t_{n k})^{2} where y_{n k}=y_{k}(\\mathbf{x}_{n},\\mathbf{w})\nThe gradient of this error with respect to a weight w_{ji} is given by  \\displaystyle {\\frac{\\partial E_{n}}{\\partial w_{j i}}}=(y_{n j}-t_{n j})x_{n i}\nIn a general feed-forward network, each unit computes a weighted sum of its inputs of the form:  \\displaystyle a_{j}=\\sum_{i}w_{j i}z_{i} where z_i is the activation of a unit, or input, that sends a connection to unit j, and w_{ji} is the weight associated with that connection\nA non-linear activation function h(.) transforms a_j to produce z_j of unit j in the form  z_{j}=h(a_{j}) Note z_i in equation a_{j}=\\sum_{i}w_{j i}z_{i} could be an input, and the unit j in equation z_{j}=h(a_{j}) could be an output\nNow we consider to evaluate derivative of E_n with respect to w_{ji}, E_n depends on the weight w_{ji} only via the summed input a_j to unit j. Applying chain rule for partial derivatives we get  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}=\\frac{\\partial E_{n}}{\\partial a_{j}}\\frac{\\partial a_{j}}{\\partial w_{j i}}\nConsider a useful notation  \\displaystyle \\delta_{j}\\equiv\\frac{\\partial{ E}_{n}}{\\partial a_{j}}\nwe can find derivative of a_j with respect to w_{ji} using a_{j}=\\sum_{i}w_{j i}z_{i}, we get  \\displaystyle {\\frac{\\partial a_{j}}{\\partial w_{j i}}}=z_{i}\nUsing above three bullet points we get  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}=\\delta_{j}z_{i} This tells us required derivative is obtained simply by multiplying the value of \\delta for the unit at the output end of the weight by the value of z for the unit at the input end of the weight.\nFor output unit we have  \\delta_k = y_k - t_k \nFor hidden units, we again make use of chain rule for partial derivatives  \\displaystyle \\delta_{j}\\equiv\\frac{\\partial E_{n}}{\\partial a_{j}}=\\sum_{k}\\frac{\\partial E_{n}}{\\partial a_{k}}\\frac{\\partial a_{k}}{\\partial a_{j}}\nNow we know that  \\displaystyle \\frac{\\partial E_{n}}{\\partial a_{k}} = \\delta _k also, a_{k}=\\sum_{j}w_{k j}z_{j} and z_{j}=h(a_{j})  so \\displaystyle \\frac{\\partial a_{k}}{\\partial a_{j}} = \\frac{\\partial \\sum_{j}w_{k j}h(a_{j})}{\\partial a_{j}} = w_{k j} h^\\prime(a_{j})  putting value of \\frac{\\partial E_{n}}{\\partial a_{k}} and \\frac{\\partial a_{k}}{\\partial a_{j}} in the equation of above bullet point we get  \\displaystyle \\delta_{j}=h^{\\prime}(a_{j})\\sum_{k}w_{k j}\\delta_{k}\nIn short what we discussed till now  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}=\\frac{\\partial E_{n}}{\\partial a_{j}}\\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k}{\\frac{\\partial E_{n}}{\\partial a_{k}}}{\\frac{\\partial a_{k}}{\\partial a_{j}}} \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k}{\\frac{\\partial E_{n}}{\\partial a_{k}}}\\left( w_{k j}h^{\\prime}(a_{j}) \\right) \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= h^{\\prime}(a_{j})\\left( \\sum_{k}{\\frac{\\partial E_{n}}{\\partial a_{k}}}w_{k j} \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= h^{\\prime}(a_{j})\\left( \\sum_{k}{\\frac{\\partial E_{n}}{\\partial a_{k}}}w_{k j} \\right) z_i \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= h^{\\prime}(a_{j}) z_i \\left( \\sum_{k}{\\frac{\\partial E_{n}}{\\partial a_{k}}}w_{k j} \\right)\nIn sort what we discussed till now with little more elaboration  \\displaystyle y_{k}({\\bf x},{\\bf w})= \\overbrace{\\sigma \\left( \\underbrace{ \\sum_{j=0}^{M}w_{k j}^{(2)} \\times \\overbrace{h\\left(\\underbrace{\\sum_{i=0}^{D}w_{j i}^{(1)} \\times z_{i}}_{a_j} \\right)}^{z_j}}_{a_k} \\right)}^{z_k} \\displaystyle y_{k}({\\bf x},{\\bf w})= \\overbrace{ \\underbrace{\\sigma}_{\\text{activation fucntion at output }} \\left( \\underbrace{ \\sum_{j=0}^{M}w_{k j}^{(2)} \\times \\overbrace{ \\underbrace{h}_{\\text{activation fucntion at hidden}} \\left(\\underbrace{\\sum_{i=0}^{D}w_{j i}^{(1)} \\times \\overbrace{z_{i}}^{\\text{from last layer or input }x_i} }_{a_j} \\right)}^{z_j}}_{a_k} \\right)}^{z_k} \\displaystyle E_{n}={\\frac{1}{2}}\\sum_{k}(y_{k}-t_{k})^{2} Till now we had below expression :  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial a_{k}} {\\frac{\\partial a_{k}}{\\partial a_{j}}} \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} But if we consider activation function \\sigma at out layer and y_k = z_k = \\sigma (a_k) we get :  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left(\\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} {\\frac{\\partial a_{k}}{\\partial a_{j}}}\\right)\\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} {\\frac{\\partial \\sum_{j}w_{k j}z_{j}}{\\partial a_{j}}} \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} {\\frac{\\partial \\sum_{j}w_{k j}z_{j}}{\\partial a_{j}}} \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} {\\frac{\\partial \\sum_{j}w_{k j}h(a_{j})}{\\partial a_{j}}} \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} w_{kj}h^\\prime(a_j) \\right) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} w_{kj} \\right) h^\\prime(a_j) \\frac{\\partial a_{j}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} \\frac{\\partial E_{n}}{\\partial z_{k}} {\\frac{\\partial z_{k}}{\\partial a_{k}}} w_{kj} \\right) h^\\prime(a_j) \\frac{\\partial \\sum_{i}w_{j i}z_{i}}{\\partial w_{j i}} \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left(\\sum_{k}\\frac{\\partial E_{n}}{\\partial z_{k}}{\\frac{\\partial z_{k}}{\\partial a_{k}}} w_{kj} \\right) h^\\prime(a_j) z_i\nSince z_k is same as y_k, we can replace z_k with y_k in above equation   \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} {\\frac{\\partial E_{n}}{\\partial y_{k}}} {\\frac{\\partial y_{k}}{\\partial a_{k}}} w_{kj} \\right) h^\\prime(a_j) z_i we know y_k=z_k=\\sigma (a_k) so we get  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} {\\frac{\\partial E_{n}}{\\partial y_{k}}} {\\frac{\\partial \\sigma (a_k)}{\\partial a_{k}}} w_{kj} \\right) h^\\prime(a_j) z_i \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} {\\frac{\\partial E_{n}}{\\partial y_{k}}} {\\frac{\\partial \\sigma (a_k)}{\\partial a_{k}}} w_{kj} \\right) h^\\prime(a_j) z_i \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\underbrace{\\left( \\sum_{k} \\underbrace{\\frac{\\partial E_{n}}{\\partial y_{k}}}_{(y_k-t_k)} \\times \\overbrace{ \\frac{\\partial \\sigma (a_k)}{\\partial a_{k}}}^{z_k(1-z_k) \\text{ or }y_k(1-y_k)} \\times w_{kj} \\right)}_{\\text{miss}} \\underbrace{h^\\prime(a_j) }_{ z_j(1-z_j)} z_i \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} (y_k-t_k) y_k (1-y_k)w_{kj} \\right) z_j(1-z_j)z_i \n\n\n\n\n\n\n\nNote\n\n\n\n\\displaystyle  y_{k}({\\bf x},{\\bf w})= \\overbrace{ \\underbrace{\\sigma}_{\\text{activation fucntion at output }}  \\left(  \\underbrace{ \\sum_{j=0}^{M}w_{k j}^{(2)} \\times  \\overbrace{ \\underbrace{h}_{\\text{activation fucntion at hidden}}  \\left(\\underbrace{\\sum_{i=0}^{D}w_{j i}^{(1)} \\times \\overbrace{z_{i}}^{\\text{from last layer or input }x_i} }_{a_j} \\right)}^{z_j}}_{a_k} \\right)}^{z_k}  \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}= \\left( \\sum_{k} (y_k-t_k) y_k (1-y_k)w_{kj} \\right) z_j(1-z_j)z_i\n\n\n\n\nError Backpropagation summery :\n\nApply an input vector x_n to the network and forward propagate through the network using below two equations to find the activations of all the hidden and output units.  \\displaystyle a_{j}=\\sum_{i}w_{j i}z_{i}  z_j = h(a_j)\nEvaluate the \\delta _k for all the output units using \\delta_K = y_k - t_k\nBackpropagete all the \\delta using below equation to find \\delta _j for each hidden unit in the network  \\displaystyle \\delta_{j}=h^{\\prime}(a_{j})\\sum_{k}w_{k j}\\delta_{k}\nUse below equation to evaluate the required derivatives \\displaystyle \\frac{\\partial E_{n}}{\\partial w_{j i}}=\\delta_{j}z_{i}\n\nFor batch methods, the derivative of the total error E can then be obtained by repeating the above steps for each pattern in the training set and then summing over all patterns: \\displaystyle \\frac{\\partial E}{\\partial w_{j i}}=\\sum_{n}\\frac{\\partial E_{n}}{\\partial w_{j i}}"
  },
  {
    "objectID": "posts/CS5590/2022-09-24-CS5590-week5.html#backpropagation-form-lecture-pdf",
    "href": "posts/CS5590/2022-09-24-CS5590-week5.html#backpropagation-form-lecture-pdf",
    "title": "Neural Networks CS5590 week 5",
    "section": "Backpropagation Form lecture PDF",
    "text": "Backpropagation Form lecture PDF\nIt also has same points as per PRML but from different angle. But DIFFERENT TERMINOLOGY IS USED HERE SO BE CAREFUL\n\n  \n\\mathbf{\\text{Alert !!!}}\n\n\nSOME NOTATION IS WRONG IN THIS SECTION. DO NOT READ THIS SECTION, ALL CONCEPTS ARE ALREADY EXPLAINED \n\nTerminology  g is activation function  y=g(z)  E = (t_i-y_i)^2  z_i = a_j\\times w_{ij}\nAdd a dimension for the observed error\nTry to minimize your position on the “error surface”\nCompute :  \\text{Grad}_E = \\left[ \\frac{dE}{dW_1},\\frac{dE}{dW_2},\\dots , \\frac{dE}{dW_n} \\right]\nChange i_{th} weight by  \\Delta W_i = -\\alpha \\frac{dE}{dW_i}\nWe also use activation function at the end of every node.\nconsider g(z)=y where g is sigmoid activation function.\ng'(z)=g(z)\\times (1-g(z))=y(1-y)\nActivation function must be continuous, differential, non-decreasing, and easy to compute.\nWe want activation function to be non-decreasing because, so that it should not increase value in some reason and decrease it in some other reason.\n\n\nUpdating Hidden-to-Output\n\nUpdating Hidden-to-Output \\frac{\\partial E}{\\partial W_ij}= \\frac{\\partial E}{\\partial y} \\times \\frac{\\partial y}{\\partial z} \\times \\frac{\\partial z}{\\partial W_ij} \\Delta W_{ij} = \\alpha \\times \\underbrace{(t_i -y_i)}_{\\frac{\\partial E}{\\partial y} } \\times \\underbrace{g'(z_i)}_{\\frac{\\partial y}{\\partial z} } \\times \\underbrace{a_j}_{\\frac{\\partial z}{\\partial W_ij}} \\Delta W_{ij} = \\overbrace{\\alpha}^{\\text{learning rate}} \\times \\underbrace{(\\overbrace{t_i}^{\\text{Teacher supplied}} -y_i)}_{\\text{miss}} \\times \\overbrace{g'(z_i)}^{\\text{derivatve of acitvation function}} \\times \\underbrace{a_j}_{\\text{previous layer output}} \\Delta W_{ij} = \\alpha \\times (t_i -y_i) \\times y_i \\times (1-y_i)\\times a_j \n\n\n\nUpdating interior weights\n\nUpdating interior weights Layer k units provide values to all layers k+1 units. “miss” is sum of the misses from all units on k+1 \\displaystyle \\text{miss}_j = \\sum \\left[ a_j(1-a_j)(t_i-a_j)w_{ji} \\right] \\displaystyle \\frac{\\partial E}{\\partial W_kj}= \\left( \\sum \\frac{\\partial E}{\\partial y_i} \\times \\frac{\\partial y_i}{\\partial z_i} \\times \\frac{\\partial z_i}{\\partial a_j} \\right) \\times \\frac{\\partial a_j}{\\partial l_j} \\times \\frac{\\partial l_j}{\\partial W_ij} \\displaystyle \\frac{\\partial E}{\\partial W_kj}= \\left( \\sum \\underbrace{\\frac{\\partial E}{\\partial y_i}}_{t_i-y_i} \\times \\overbrace{\\frac{\\partial y_i}{\\partial z_i}}^{y_i(1-y_i)} \\times \\underbrace{\\frac{\\partial z_i}{\\partial a_j}}_{w_ji} \\right) \\times \\underbrace{\\frac{\\partial a_j}{\\partial l_j}}_{a_j(1-a_j)} \\times \\overbrace{\\frac{\\partial l_j}{\\partial W_ij}}^{l_k} \\displaystyle \\frac{\\partial E}{\\partial W_kj} = \\left( \\sum y_i \\times (1-y_i) \\times (t_i-y_i) \\times w_{ji}\\right) \\times l_k \\times a_j \\times (1-a_j)"
  }
]